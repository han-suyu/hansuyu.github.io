<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>YOLO v2学习总结 | 明天又是周六了</title><meta name="keywords" content="目标检测,YOLO"><meta name="author" content="Seven"><meta name="copyright" content="Seven"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="原论文：《You Only Look Once Unified，Real-Time Object Detection》                   原论文：https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1612.08242 下载好的：https:&#x2F;&#x2F;wwa.lanzous.com&#x2F;ihv6Geja7qb            写在前面 YOLO的升级版">
<meta property="og:type" content="article">
<meta property="og:title" content="YOLO v2学习总结">
<meta property="og:url" content="https://hansy.tech/2020/07/2054167626.html">
<meta property="og:site_name" content="明天又是周六了">
<meta property="og:description" content="原论文：《You Only Look Once Unified，Real-Time Object Detection》                   原论文：https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1612.08242 下载好的：https:&#x2F;&#x2F;wwa.lanzous.com&#x2F;ihv6Geja7qb            写在前面 YOLO的升级版">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/han-suyu/cover/22.png">
<meta property="article:published_time" content="2020-07-10T15:16:45.000Z">
<meta property="article:modified_time" content="2020-07-10T15:16:45.000Z">
<meta property="article:author" content="Seven">
<meta property="article:tag" content="目标检测">
<meta property="article:tag" content="YOLO">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/han-suyu/cover/22.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://hansy.tech/2020/07/2054167626"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="u9AaJlYHNmU4dpUtiWPMA9_vQRU4zjcERKUymU8aEao"/><meta name="baidu-site-verification" content="m7BzC4y6nU"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: true
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: true,
  isanchor: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2020-07-10 23:16:45'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/my.css"><link rel="stylesheet" href="https://at.alicdn.com/t/font_2107761_ythu35kdfcq.css"><meta name="generator" content="Hexo 5.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style><link rel="alternate" href="/atom.xml" title="明天又是周六了" type="application/atom+xml">
</head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" data-lazy-src="/img/avatar.jpg" onerror="onerror=null;src='/img/wechat.jpg'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">179</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">38</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">26</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-calendar"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tag"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/photos/"><i class="fa-fw fa fa-camera"></i><span> 相册</span></a></div><div class="menus_item"><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></div><div class="menus_item"><a class="site-page" href="/toolbox/"><i class="fa-fw fa fa-leaf"></i><span> 小工具</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-institution"></i><span> 实验室</span><i class="fas fa-chevron-down expand hide"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/color/"><i class="fa-fw fa fa-tachometer"></i><span> RGB颜色</span></a></li><li><a class="site-page" href="/colorPick/"><i class="fa-fw fa fa-magic"></i><span> 颜色提取</span></a></li><li><a class="site-page" href="/hexconvert/"><i class="fa-fw fa fa-calculator"></i><span> 进制转换</span></a></li><li><a class="site-page" href="/diff/"><i class="fa-fw fa fa-clone"></i><span> 文本对比</span></a></li><li><a class="site-page" href="/map/"><i class="fa-fw fa fa-globe"></i><span> 地球图层</span></a></li><li><a class="site-page" href="/dog/"><i class="fa-fw fa fa-heartbeat"></i><span> 舔狗日记</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-game"></i><span> 小游戏</span><i class="fas fa-chevron-down expand hide"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/Sudoku/"><span> 数独</span></a></li><li><a class="site-page" href="/puzzleNumber/"><span> 数字拼图</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/han-suyu/cover/22.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">明天又是周六了</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-calendar"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tag"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/photos/"><i class="fa-fw fa fa-camera"></i><span> 相册</span></a></div><div class="menus_item"><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></div><div class="menus_item"><a class="site-page" href="/toolbox/"><i class="fa-fw fa fa-leaf"></i><span> 小工具</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-institution"></i><span> 实验室</span><i class="fas fa-chevron-down expand hide"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/color/"><i class="fa-fw fa fa-tachometer"></i><span> RGB颜色</span></a></li><li><a class="site-page" href="/colorPick/"><i class="fa-fw fa fa-magic"></i><span> 颜色提取</span></a></li><li><a class="site-page" href="/hexconvert/"><i class="fa-fw fa fa-calculator"></i><span> 进制转换</span></a></li><li><a class="site-page" href="/diff/"><i class="fa-fw fa fa-clone"></i><span> 文本对比</span></a></li><li><a class="site-page" href="/map/"><i class="fa-fw fa fa-globe"></i><span> 地球图层</span></a></li><li><a class="site-page" href="/dog/"><i class="fa-fw fa fa-heartbeat"></i><span> 舔狗日记</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-game"></i><span> 小游戏</span><i class="fas fa-chevron-down expand hide"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/Sudoku/"><span> 数独</span></a></li><li><a class="site-page" href="/puzzleNumber/"><span> 数字拼图</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">YOLO v2学习总结<a class="post-edit-link" href="https://github.com/han-suyu/hansy.tech/edit/main/source/_posts/YOLO v2学习总结.md" title="编辑" target="_blank"><i class="fas fa-pencil-alt"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-07-10T15:16:45.000Z" title="发表于 2020-07-10 23:16:45">2020-07-10</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2020-07-10T15:16:45.000Z" title="更新于 2020-07-10 23:16:45">2020-07-10</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">目标检测</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">13k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>55分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2020/07/2054167626.html#post-comment"><span id="twikoo-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><div class="spoiler collapsed">
    <div class="spoiler-title">
        原论文：《You Only Look Once Unified，Real-Time Object Detection》
    </div>
    <div class="spoiler-content">
        <p><strong>原论文</strong>：https://arxiv.org/abs/1612.08242</p>
<p><strong>下载好的</strong>：https://wwa.lanzous.com/ihv6Geja7qb</p>

    </div>
</div>
<p> </p>
<p> </p>
<h1 id="写在前面">写在前面</h1>
<p>YOLO的升级版有两种：YOLOv2和YOLO9000。作者采用了一系列的方法优化了YOLO的模型结构，产生了YOLOv2，在快速的同时准确率达到目前最好的结果（state of the art）。然后，作者提出了一种目标分类与检测的联合训练方法，通过WordTree来混合检测数据集与识别数据集之中的数据，同时在COCO和ImageNet数据集中进行训练得到YOLO9000，实现9000多种物体的实时检测。</p>
<p> </p>
<p>YOLO V2是原作者在V1基础上做出改进后提出的，论文的名称就已经表达了作者的工作内容：</p>
<ul>
<li>Better 指的是和YOLO相比，YOLO V2有更好的精度</li>
<li>Faster 指的是修改了网络结构，其检测更快</li>
<li>Stronger 指的就是YOLO 9000,使用联合训练的方法，同时使用目标检测和图像分类的数据集，训练YOLO V2，训练出来的模型能够实时的识别多达9000种目标，所以也称为YOLO9000。</li>
</ul>
<p> </p>
<p>遵循原论文的结构，本文将从Better，Faster和Stronger三个方面对YOLO V2进行解读。</p>
<p> </p>
<p> </p>
<p> </p>
<h1 id="一better">一、Better</h1>
<p>在YOLO V1的基础上，作者提出了不少的改进来进一步提升算法的性能（mAP），主要改进措施包括网络结构的改进（第1，3，5，6条）和Anchor Box的引进（第3，4，5条）以及训练方法（第2，7条）。</p>
<p> </p>
<h2 id="引入bn层batch-normalization">1.1 引入BN层（Batch Normalization）</h2>
<p>Batch Normalization能够加快模型收敛，并提供一定的正则化。作者在每个conv层都加上了了BN层，同时去掉了原来模型中的drop out部分，实验证明可以提高2%的mAP。</p>
<p>BN层进行如下变换：①对该批样本的各特征量（对于中间层来说，就是每一个神经元）分别进行归一化处理，分别使每个特征的数据分布变换为均值0，方差1。从而使得每一批训练样本在每一层都有类似的分布。这一变换不需要引入额外的参数。②对上一步的输出再做一次线性变换，假设上一步的输出为Z，则Z1=γZ + β。这里γ、β是可以训练的参数。增加这一变换是因为上一步骤中强制改变了特征数据的分布，可能影响了原有数据的信息表达能力。增加的线性变换使其有机会恢复其原本的信息。</p>
<p>关于批规一化的更多信息可以参考 <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/34879333">Batch Normalization原理与实战</a>。</p>
<p> </p>
<p> </p>
<h2 id="高分辨率分类器high-resolution-classifier">1.2 高分辨率分类器（High Resolution Classifier）</h2>
<p>这里要先清楚相比图像的分类任务，目标检测需要更高的图像分辨率。另外，训练网络时一般都不会从随机初始化所有的参数来开始的，一般都是用预训练好的网络来fine-tuning自己的网络，预训练的网络一般是在ImageNet上训练好的分类网络。</p>
<ul>
<li>YOLOV1预训练的时候使用224x224的输入，检测的时候采用的是448x448的输入，这会导致分类切换到检测的时候，模型需要适应图像分辨率的改变。</li>
<li>YOLOV2中将预训练分成两步：①：先用224x224的输入来训练大概160个epoch，然后再把输入调整到448x448再训练10个epoch，然后再与训练好的模型上进行fine-tuning，检测的时候用448x448就可以顺利过渡了。</li>
</ul>
<p>这个方法提高了3.7%的mAP.</p>
<p> </p>
<p> </p>
<h2 id="引入先验框anchor-box">1.3 引入先验框（Anchor Box）</h2>
<p>在YOLO中在最后网络的全连接层直接预测目标边框的坐标，在YOLO V2中借鉴 Fast R-CNN中的Anchor的思想。</p>
<ul>
<li>去掉了YOLO网络的全连接层和最后的池化层，使提取特征的网络能够得到更高分辨率的特征。</li>
<li>使用416×416代替448×448作为网络的输入。这是因为希望得到的特征图的尺寸为奇数。奇数大小的宽和高会使得每个特征图在划分cell的时候就只有一个center cell（比如可以划分成7x7或9x9个cell，center cell只有一个，如果划分成8x8或10x10的，center cell就有4个）。为什么希望只有一个center cell呢？因为大的object一般会占据图像的中心，所以希望用一个center cell去预测，而不是4个center cell去预测。网络最终将416x416的输入变成13x13大小的feature map输出，也就是缩小比例为32。（5个池化层，每个池化层将输入的尺寸缩小1/2）。</li>
<li><strong>Anchor Boxes</strong> 在YOLO中，每个grid cell只预测两个bbox，最终只能预测98个bbox（7×7×2=98），而在Faster RCNN在输入大小为1000×600时的boxes数量大概是6000，在SSD300中boxes数量是8732。显然增加box数量是为了提高object的定位准确率。 过少的bbox显然影响了YOLO的定位的精度，在YOLO V2中引入了Anchor Boxes的思想，其预测的bbox则会超过千个（以输出的feature map为13×13为例，每个grid cell有9个anchor box的话，其预测的bbox数量为13×13×9=1521个）。</li>
</ul>
<p>引入anchor box之后，相对YOLO1的81%的召回率，YOLO2的召回率大幅提升到88%。同时mAP有0.2%的轻微下降。</p>
<p> </p>
<p> </p>
<h2 id="引入聚类提取先验框尺度dimension-cluster">1.4 引入聚类提取先验框尺度（Dimension Cluster）</h2>
<p>在引入anchor box后，一个问题就是如何确定anchor的位置和大小？Faster RCNN中是手工选定的，每隔stride设定一个anchor，并根据不同的面积比例和长宽比例产生9个(3种大小，3种形状共9种)anchor box。设想能否一开始就选择了更好的、更有代表性的先验Boxes维度，那么网络就应该更容易学到准确的预测位置。作者的解决办法就是统计学习中的K-means聚类方法，通过对数据集中的Ground True Box做聚类，找到Ground True Box的统计规律。以聚类个数k为Anchor Boxs个数，以k个聚类中心Box的宽高维度为Anchor Box的维度。</p>
<p> </p>
<p>如果按照标准K-means使用欧式距离函数，大Boxes比小Boxes产生更多Error。但是，我们真正想要的是产生好的IOU得分的Boxes（与Box的大小无关）。因此采用了如下距离度量：</p>
<p><span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex" xmlns="http://www.w3.org/2000/svg" width="40.885ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 18071.3 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(520, 0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(909, 0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mi" transform="translate(1338, 0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(1823, 0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(2395, 0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(2839.7, 0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(3272.7, 0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(3738.7, 0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(4338.7, 0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(4699.7, 0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(5150.7, 0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(5635.7, 0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(5980.7, 0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(6500.7, 0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(7167.4, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(8223.2, 0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(8945.4, 0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(9945.7, 0)"><path data-c="1D43C" d="M43 1Q26 1 26 10Q26 12 29 24Q34 43 39 45Q42 46 54 46H60Q120 46 136 53Q137 53 138 54Q143 56 149 77T198 273Q210 318 216 344Q286 624 286 626Q284 630 284 631Q274 637 213 637H193Q184 643 189 662Q193 677 195 680T209 683H213Q285 681 359 681Q481 681 487 683H497Q504 676 504 672T501 655T494 639Q491 637 471 637Q440 637 407 634Q393 631 388 623Q381 609 337 432Q326 385 315 341Q245 65 245 59Q245 52 255 50T307 46H339Q345 38 345 37T342 19Q338 6 332 0H316Q279 2 179 2Q143 2 113 2T65 2T43 1Z"></path></g><g data-mml-node="mi" transform="translate(10449.7, 0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(10934.7, 0)"><path data-c="1D448" d="M107 637Q73 637 71 641Q70 643 70 649Q70 673 81 682Q83 683 98 683Q139 681 234 681Q268 681 297 681T342 682T362 682Q378 682 378 672Q378 670 376 658Q371 641 366 638H364Q362 638 359 638T352 638T343 637T334 637Q295 636 284 634T266 623Q265 621 238 518T184 302T154 169Q152 155 152 140Q152 86 183 55T269 24Q336 24 403 69T501 205L552 406Q599 598 599 606Q599 633 535 637Q511 637 511 648Q511 650 513 660Q517 676 519 679T529 683Q532 683 561 682T645 680Q696 680 723 681T752 682Q767 682 767 672Q767 650 759 642Q756 637 737 637Q666 633 648 597Q646 592 598 404Q557 235 548 205Q515 105 433 42T263 -22Q171 -22 116 34T60 167V183Q60 201 115 421Q164 622 164 628Q164 635 107 637Z"></path></g><g data-mml-node="mo" transform="translate(11701.7, 0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(12090.7, 0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mi" transform="translate(12519.7, 0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(13004.7, 0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(13576.7, 0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(14021.3, 0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(14454.3, 0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(14920.3, 0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(15520.3, 0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(15881.3, 0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(16332.3, 0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(16817.3, 0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(17162.3, 0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(17682.3, 0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span></p>
<p>图1是在VOC和COCO上的聚类结果：</p>
<p><img src= "/img/loading.gif" data-lazy-src="https://s1.ax1x.com/2020/07/12/U85NMq.png" alt="图1：Clustering dimensions on VOC and COCO" style="zoom:67%;"></p>
<p>实验结论：</p>
<ol type="1">
<li>采用聚类分析得到的先验框比手动设置的平均的IOU值更高，模型更容易训练和学习。</li>
<li>随着K的增加，平均的IOU是增加的。但是为了综合考虑模型的复杂度和召回率。最终选择K=5。使用5个聚类框就已经达到61 Avg IOU，相当于9个手工设置的先验框60.9 Avg IOU。</li>
</ol>
<p> </p>
<p>作者还发现：The cluster centroids are significantly different than hand-picked anchor boxes. There are fewer short, wide boxes and more tall, thin boxes.这个是个无关紧要的结论了。</p>
<p> </p>
<p> </p>
<h2 id="直接位置预测direct-location-prediction">1.5 直接位置预测（Direct Location Prediction）</h2>
<p>在引入anchor box后，另一个问题就是模型不稳定，特别是在训练前期，作者认为这种不稳定是因为边界框（bounding box）中心位置的预测不够成功。</p>
<p>基于候选框的网络一般是通过预测相对于anchor box中心的偏移值来预测边界框的的中心坐标。公式如下： <span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.667ex" xmlns="http://www.w3.org/2000/svg" width="34.484ex" height="2.364ex" role="img" focusable="false" viewBox="0 -750 15242.1 1045"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(849.8, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(1905.6, 0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(2294.6, 0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(361, -150) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g><g data-mml-node="mo" transform="translate(3332.2, 0)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path></g><g data-mml-node="msub" transform="translate(4054.5, 0)"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g><g data-mml-node="mi" transform="translate(716, -150) scale(0.707)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g></g><g data-mml-node="mo" transform="translate(5194.5, 0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(5805.7, 0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(6806, 0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(572, -150) scale(0.707)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g></g><g data-mml-node="mspace" transform="translate(7802, 0)"></g><g data-mml-node="mi" transform="translate(7802, 0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(8569.8, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(9625.6, 0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(10014.6, 0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(361, -150) scale(0.707)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(10994.3, 0)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path></g><g data-mml-node="msub" transform="translate(11716.5, 0)"><g data-mml-node="mi"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mi" transform="translate(576, -150) scale(0.707)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g></g><g data-mml-node="mo" transform="translate(12716.6, 0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(13327.8, 0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(14328, 0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(490, -150) scale(0.707)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g></g></g></g></svg></mjx-container></span> 其中 <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex" xmlns="http://www.w3.org/2000/svg" width="7.088ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 3132.8 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389, 0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(572, -150) scale(0.707)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g></g><g data-mml-node="mo" transform="translate(1385.1, 0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(1829.7, 0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(490, -150) scale(0.707)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g></g><g data-mml-node="mo" transform="translate(2743.8, 0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span> 是anchor box的中心坐标，<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex" xmlns="http://www.w3.org/2000/svg" width="8.135ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 3595.7 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g><g data-mml-node="mi" transform="translate(716, -150) scale(0.707)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g></g><g data-mml-node="mo" transform="translate(1417.8, 0)"><text data-variant="normal" transform="matrix(1 0 0 -1 0 0)" font-size="884px" font-family="serif">、</text></g><g data-mml-node="msub" transform="translate(2595.6, 0)"><g data-mml-node="mi"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mi" transform="translate(576, -150) scale(0.707)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g></g></g></g></svg></mjx-container></span> 是anchor box的宽和高， <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.667ex" xmlns="http://www.w3.org/2000/svg" width="6.325ex" height="2.364ex" role="img" focusable="false" viewBox="0 -750 2795.6 1045"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389, 0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(361, -150) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g><g data-mml-node="mo" transform="translate(1204.5, 0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(1649.1, 0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(361, -150) scale(0.707)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(2406.6, 0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span> 表示预测的偏移值， <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex" xmlns="http://www.w3.org/2000/svg" width="5.169ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 2284.7 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389, 0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(961, 0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1405.7, 0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1895.7, 0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span> 表示预测的边界框的中心坐标，这个公式对于 <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.667ex" xmlns="http://www.w3.org/2000/svg" width="6.325ex" height="2.364ex" role="img" focusable="false" viewBox="0 -750 2795.6 1045"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389, 0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(361, -150) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g><g data-mml-node="mo" transform="translate(1204.5, 0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(1649.1, 0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(361, -150) scale(0.707)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(2406.6, 0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span> 没有限制，这就表示预测的边界框容易向任何一个方向偏移，比如当 <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex" xmlns="http://www.w3.org/2000/svg" width="5.993ex" height="1.864ex" role="img" focusable="false" viewBox="0 -666 2649 823.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(361, -150) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g><g data-mml-node="mo" transform="translate(1093.2, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(2149, 0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></svg></mjx-container></span> 时，边界框就会向右偏移一个anchor box的宽度。所以，每一个预测的边界框可能处于图片中的任意位置，这就导致了模型的不稳定。</p>
<p>YOLI V2沿用了V1中的做法，预测边界框的中心点相对于对应网格左上角的偏移值，每个网格有5个anchor box来预测5个边界框，每个边界框预测得到5个值：<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.667ex" xmlns="http://www.w3.org/2000/svg" width="13.215ex" height="2.084ex" role="img" focusable="false" viewBox="0 -626 5841.1 921"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(361, -150) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g><g data-mml-node="mo" transform="translate(815.5, 0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(1260.1, 0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(361, -150) scale(0.707)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(2017.6, 0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(2462.3, 0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(361, -150) scale(0.707)"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g></g><g data-mml-node="mo" transform="translate(3379.6, 0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(3824.2, 0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(361, -150) scale(0.707)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g></g><g data-mml-node="mo" transform="translate(4642.5, 0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(5087.2, 0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(361, -150) scale(0.707)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g></g></g></g></svg></mjx-container></span> ，前四个是边界框的坐标和边长信息，<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex" xmlns="http://www.w3.org/2000/svg" width="1.706ex" height="1.773ex" role="img" focusable="false" viewBox="0 -626 753.9 783.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(361, -150) scale(0.707)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g></g></g></g></svg></mjx-container></span> 则类似于YOLO V1中的置信度，<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.667ex" xmlns="http://www.w3.org/2000/svg" width="6.651ex" height="2.364ex" role="img" focusable="false" viewBox="0 -750 2939.6 1045"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389, 0)"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(433, -150) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g><g data-mml-node="mo" transform="translate(1276.5, 0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(1721.1, 0)"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(433, -150) scale(0.707)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(2550.6, 0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span> 是当前网格相对于图像左上角的坐标，anchor box的先验宽度和高度为 <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex" xmlns="http://www.w3.org/2000/svg" width="5.575ex" height="1.439ex" role="img" focusable="false" viewBox="0 -442 2464.2 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(503, -150) scale(0.707)"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g></g><g data-mml-node="mo" transform="translate(1059.3, 0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(1504, 0)"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(503, -150) scale(0.707)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g></g></g></g></svg></mjx-container></span> ，那么参照图10，预测的公式为： <span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.667ex" xmlns="http://www.w3.org/2000/svg" width="85.274ex" height="2.802ex" role="img" focusable="false" viewBox="0 -943.3 37691.2 1238.3"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mi" transform="translate(429, -150) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g><g data-mml-node="mo" transform="translate(1161.2, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(2217, 0)"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g><g data-mml-node="mo" transform="translate(2661, 0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(3050, 0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(361, -150) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g><g data-mml-node="mo" transform="translate(3865.5, 0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(4476.7, 0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(5476.9, 0)"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(433, -150) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g><g data-mml-node="mspace" transform="translate(6364.4, 0)"></g><g data-mml-node="msub" transform="translate(6364.4, 0)"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mi" transform="translate(429, -150) scale(0.707)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(7467.7, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(8523.4, 0)"><path data-c="1D6FF" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></g><g data-mml-node="mo" transform="translate(8967.4, 0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(9356.4, 0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(361, -150) scale(0.707)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(10113.9, 0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(10725.1, 0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(11725.4, 0)"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(433, -150) scale(0.707)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mspace" transform="translate(12554.8, 0)"></g><g data-mml-node="msub" transform="translate(12554.8, 0)"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mi" transform="translate(429, -150) scale(0.707)"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g></g><g data-mml-node="mo" transform="translate(13817.9, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(14873.7, 0)"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(503, -150) scale(0.707)"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g></g><g data-mml-node="msup" transform="translate(15933, 0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(466, 413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389, 0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(361, -150) scale(0.707)"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g></g><g data-mml-node="mo" transform="translate(1306.3, 0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g><g data-mml-node="mspace" transform="translate(17647.7, 0)"></g><g data-mml-node="msub" transform="translate(17647.7, 0)"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mi" transform="translate(429, -150) scale(0.707)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g></g><g data-mml-node="mo" transform="translate(18811.8, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(19867.6, 0)"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(503, -150) scale(0.707)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g></g><g data-mml-node="msup" transform="translate(20827.9, 0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(466, 413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389, 0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(361, -150) scale(0.707)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g></g><g data-mml-node="mo" transform="translate(1207.3, 0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g><g data-mml-node="mspace" transform="translate(22472.6, 0)"></g><g data-mml-node="mi" transform="translate(22472.6, 0)"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="mi" transform="translate(23223.6, 0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(23674.6, 0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(24063.6, 0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(24548.6, 0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mi" transform="translate(24977.6, 0)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g><g data-mml-node="mi" transform="translate(25389.6, 0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(25855.6, 0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(26288.6, 0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(26649.6, 0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(27260.8, 0)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path></g><g data-mml-node="mi" transform="translate(27983.1, 0)"><path data-c="1D43C" d="M43 1Q26 1 26 10Q26 12 29 24Q34 43 39 45Q42 46 54 46H60Q120 46 136 53Q137 53 138 54Q143 56 149 77T198 273Q210 318 216 344Q286 624 286 626Q284 630 284 631Q274 637 213 637H193Q184 643 189 662Q193 677 195 680T209 683H213Q285 681 359 681Q481 681 487 683H497Q504 676 504 672T501 655T494 639Q491 637 471 637Q440 637 407 634Q393 631 388 623Q381 609 337 432Q326 385 315 341Q245 65 245 59Q245 52 255 50T307 46H339Q345 38 345 37T342 19Q338 6 332 0H316Q279 2 179 2Q143 2 113 2T65 2T43 1Z"></path></g><g data-mml-node="mi" transform="translate(28487.1, 0)"><path data-c="1D442" d="M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM637 476Q637 565 591 615T476 665Q396 665 322 605Q242 542 200 428T157 216Q157 126 200 73T314 19Q404 19 485 98T608 313Q637 408 637 476Z"></path></g><g data-mml-node="mi" transform="translate(29250.1, 0)"><path data-c="1D448" d="M107 637Q73 637 71 641Q70 643 70 649Q70 673 81 682Q83 683 98 683Q139 681 234 681Q268 681 297 681T342 682T362 682Q378 682 378 672Q378 670 376 658Q371 641 366 638H364Q362 638 359 638T352 638T343 637T334 637Q295 636 284 634T266 623Q265 621 238 518T184 302T154 169Q152 155 152 140Q152 86 183 55T269 24Q336 24 403 69T501 205L552 406Q599 598 599 606Q599 633 535 637Q511 637 511 648Q511 650 513 660Q517 676 519 679T529 683Q532 683 561 682T645 680Q696 680 723 681T752 682Q767 682 767 672Q767 650 759 642Q756 637 737 637Q666 633 648 597Q646 592 598 404Q557 235 548 205Q515 105 433 42T263 -22Q171 -22 116 34T60 167V183Q60 201 115 421Q164 622 164 628Q164 635 107 637Z"></path></g><g data-mml-node="mo" transform="translate(30017.1, 0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(30406.1, 0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mo" transform="translate(30835.1, 0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(31279.7, 0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(31764.7, 0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mi" transform="translate(32193.7, 0)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g><g data-mml-node="mi" transform="translate(32605.7, 0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(33071.7, 0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(33504.7, 0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(33865.7, 0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(34532.5, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(35588.3, 0)"><path data-c="1D70E" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path></g><g data-mml-node="mo" transform="translate(36159.3, 0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(36548.3, 0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(361, -150) scale(0.707)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g></g><g data-mml-node="mo" transform="translate(37302.2, 0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span> 为了将边界框的中心约束到当前网格中，利用sigmoid函数将 <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.667ex" xmlns="http://www.w3.org/2000/svg" width="4.565ex" height="2.084ex" role="img" focusable="false" viewBox="0 -626 2017.6 921"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(361, -150) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g><g data-mml-node="mo" transform="translate(815.5, 0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(1260.1, 0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(361, -150) scale(0.707)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container></span> 进行归一化处理，使得模型更加稳定。</p>
<p><img src= "/img/loading.gif" data-lazy-src="https://s1.ax1x.com/2020/07/12/U85Yzn.png" alt="图2：Bounding boxes with dimension priors and location prediction" style="zoom: 50%;"></p>
<p>通过对比实验发现，采用维度聚类与直接位置预测比单纯使用anchor box的方法在精度能多出5%。</p>
<p> </p>
<p> </p>
<h2 id="细粒度特征fine-gained-features">1.6 细粒度特征（Fine-Gained Features）</h2>
<p>YOLO V2最后一层卷积层输出的是13x13的特征图，检测时也是遵循的这个分辨率。这个分辨率对于大尺寸目标的检测是足够了，但是对于小目标则需要更细粒度的特征，因为越小的物体在经过层层池化后，体现在最终特征图中的可能性越小。</p>
<p>Faser R-CNN和SSD都在不同层次的特征图上产生区域建议以获得多尺度的适应性，YOLO V2则开创性地引入了直通层(passthrough layer)，这个直通层有点类似ResNet的dentity mappings结构，将浅层和深层两种不同尺寸的特征连接起来。在这里是将前一层高分辨率的特征图连接到低分辨率的特征图上：前一层的特征图的维度为26x26x512，在最后一个pooling之前将其1拆4形成4个13x13x512大小的特征图，然后将其与最后一层特征图（13x13x1024）连接成13x13x(1024+2048)的特征图，最后在此特征图上进行卷积预测（详细过程见下图3）。相当于做了一次特征融合，有利于检测小目标。</p>
<p><img src= "/img/loading.gif" data-lazy-src="https://s1.ax1x.com/2020/07/12/U85JRs.png" alt="图3：Passthrough Layer" style="zoom: 58%;"></p>
<p> </p>
<p> </p>
<h2 id="多尺度训练multi-scale-training">1.7 多尺度训练（Multi-Scale Training）</h2>
<p>在实际应用时，输入的图像大小有可能是变化的。我们也将这一点考虑进来。因为我们的网络是全卷积神经网络，只有conv和pooling层，没有全连接层，这样就可以处理任意尺寸的图像。为了应对不同尺寸的图像，YOLO V2中在训练的时候使用不同的尺寸图像。</p>
<p>具体来说，在训练的时候，每隔一定的epoch（例如10）后就会微调网络，随机改变网络的输入图像大小。YOLO V2共进行5次最大池化，即最终的降采样参数为32，所以随机生成的图像大小为32的倍数，即{320,352,…,608}，最终最小的尺寸为320×320，最大的尺寸为608×608。</p>
<p>该训练规则强迫模型取适应不同的输入分辨率。模型对于小尺寸的输入处理速度更快，因此YOLOv2可以按照需求调节速度和准确率。在低分辨率情况下（288×288），YOLOv2可以在保持和Fast R-CNN持平的准确率的情况下，处理速度可以达到90FPS。在高分辨率情况下，YOLOv2在VOC2007数据集上准确率可以达到state of the art（78.6mAP）</p>
<p>对于目前流行的检测方法（Faster RCNN，SSD，YOLO）的精度和帧率之间的关系，见下图4。可以看到，作者在30fps处画了一条竖线，这是算法能否达到实时处理的分水岭。Faster RCNN败下阵来，而YOLO V2的不同点代表了不同输入图像分辨率下算法的表现。对于详细数据，见表格1对比（VOC 2007上进行测试）。</p>
<p><img src= "/img/loading.gif" data-lazy-src="https://s1.ax1x.com/2020/07/12/U85GGj.png" alt="图4：YOLOv2与其它模型在VOC 2007数据集上的正确率与速度对比" style="zoom:38%;"></p>
<p> </p>
<p>​ <img src= "/img/loading.gif" data-lazy-src="https://s1.ax1x.com/2020/07/12/U858iQ.png" alt="表1：YOLOv2与其它模型在VOC 2007数据集上的性能对比" style="zoom:43%;">  </p>
<p> </p>
<h2 id="小结">小结</h2>
<p>YOLO V2针对YOLO定位不准确以及召回率低的问题，进行一些改变。 主要是借鉴Faster R-CNN的思想，引入了Anchor box。并且使用k-means的方法，通过聚类得到每个Anchor应该生成的Anchor box的的大小和形状。为了是提取到的特征有更细的粒度，其网络中借鉴ResNet的思想，将浅层的高分辨率特征和深层的特征进行了融合，这样能够更好的检测小的目标。 最后，由于YOLO V2的网络是全卷积网络，能够处理任意尺寸的图像，在训练的时候使用不同尺度的图像，以应对图像尺寸的变换。</p>
<p> </p>
<p>在Better这部分的末尾，作者给出了一个表格，指出了主要提升性能的措施。</p>
<p><img src= "/img/loading.gif" data-lazy-src="https://s1.ax1x.com/2020/07/12/U85Us0.png" alt="表2：不同改进措施的影响" style="zoom:55%;"></p>
<p> </p>
<p> </p>
<p> </p>
<h1 id="二faster">二、Faster</h1>
<p>为了精度与速度并重，作者在速度上也作了一些改进措施。大多数检测网络依赖于VGG-16作为特征提取网络，VGG-16是一个强大而准确的分类网络，但是确过于复杂。224*224的图片进行一次前向传播，其卷积层就需要多达306.9亿次浮点数运算。</p>
<p>YOLO使用的是基于Googlenet的自定制网络，比VGG-16更快，一次前向传播仅需85.2亿次运算，不过它的精度要略低于VGG-16。224*224图片取Single-Crop, Top-5 Accuracy，YOLO的定制网络得到88%（VGG-16得到90%）。</p>
<p> </p>
<h2 id="darknet-19">2.1 Darknet-19</h2>
<p>YOLOv2使用了一个新的分类网络作为特征提取部分，参考了前人的工作经验。类似于VGG，网络使用了较多的3<em>3卷积核，在每一次池化操作后把通道数翻倍。借鉴了Network In Network的思想，网络使用了全局平均池化（Global Average Pooling）做预测，把1</em>1的卷积核置于3*3的卷积核之间，用来压缩特征。使用Batch Normalization稳定模型训练，加速收敛，正则化模型。</p>
<p>最终得出的基础模型就是Darknet-19，包含19个卷积层、5个最大值池化层（Max Pooling Layers ）。Darknet-19处理一张照片需要55.8亿次运算，Imagenet的Top-1准确率为72.9%，Top-5准确率为91.2%。具体的网络结构见表3。</p>
<p><img src= "/img/loading.gif" data-lazy-src="https://s1.ax1x.com/2020/07/12/U85aLV.png" alt="表3：Darknet-19的网络结构" style="zoom:50%;"></p>
<p> </p>
<p> </p>
<h2 id="分类任务训练training-for-classiﬁcation">2.2 分类任务训练（Training For Classiﬁcation）</h2>
<p>作者采用ImageNet1000类数据集来训练分类模型。训练过程中，采用了 random crops, rotations, and hue, saturation, and exposure shifts等data augmentation方法。预训练后，作者采用高分辨率图像（448×448）对模型进行finetune。高分辨率下训练的分类网络Top-1准确率76.5%，Top-5准确率93.3%。</p>
<p> </p>
<p> </p>
<h2 id="检测任务训练training-for-detection">2.3 检测任务训练（Training For Detection）</h2>
<p>为了把分类网络改成检测网络，作者将分类模型的最后一层卷积层去除，替换为三层卷积层（3×3,1024 filters），最后一层为1×1卷积层，输出维度filters为需要检测的数目。对于VOC数据集，预测5种Boxes，每个Box包含5个坐标值和20个类别，所以总共是5 * （5+20）= 125个输出维度。因此，输出为125（5x20+5x5） filters。最后还加入了passthough 层，从最后3 x 3 x 512的卷积层连到倒数第二层，使模型有了细粒度特征。</p>
<p> </p>
<p> </p>
<p> </p>
<h1 id="三stronger">三、Stronger</h1>
<p>如之前所说，物体分类，是对整张图片打标签，比如这张图片中含有人，另一张图片中的物体为狗；而物体检测不仅对物体的类别进行预测，同时需要框出物体在图片中的位置。物体分类的数据集，最著名的ImageNet，物体类别有上万个，而物体检测数据集，例如coco，只有80个类别，因为物体检测、分割的打标签成本比物体分类打标签成本要高很多。所以在这里，作者提出了分类、检测训练集联合训练的方案。</p>
<p> </p>
<h2 id="joint-classification-and-detection联合分类和检测">3.1 Joint Classification And Detection（联合分类和检测）</h2>
<p>使用检测数据集的图片去学习检测相关的信息，例如Bounding Box 坐标预测，是否包含物体以及属于各个物体的概率。使用仅有类别标签的分类数据集图片去扩展可以检测的种类。训练过程中把监测数据和分类数据混合在一起。<strong>基本的思路是，如果是检测样本，训练时其Loss包括分类误差和定位误差，如果是分类样本，则Loss只包括分类误差。</strong>当然，一般的训练策略为，先在检测数据集上训练一定的epoch，待预测框的loss基本稳定后，再联合分类数据集、检测数据集进行交替训练，同时为了分类、检测数据量平衡，作者对coco数据集进行了上采样，使得coco数据总数和ImageNet大致相同。</p>
<p>联合分类与检测数据集，这里不同于将网络的backbone在ImageNet上进行预训练，预训练只能提高卷积核的鲁棒性，而分类检测数据集联合，可以扩充识别物体种类。比如狗，ImageNet上就包含超过100多类品种的狗。如果要联合训练，需要将这些标签进行合并。</p>
<p>大部分分类方法采用softmax输出所有类别的概率。采用softmax的前提假设是类别之间不相互包含（比如，犬和牧羊犬就是相互包含）。因此，我们需要一个多标签的模型来综合数据集，使类别之间不相互包含。</p>
<p>作者最后采用WordTree来整合数据集，解决了ImageNet与coco之间的类别问题。</p>
<p> </p>
<p> </p>
<h2 id="dataset-combination-with-wordtree">3.2 Dataset combination with WordTree</h2>
<p>可以使用WordTree把多个数据集整合在一起。只需要把数据集中的类别映射到树结构中的同义词集合（Synsets）。使用WordTree整合ImageNet和COCO的标签如图5所示：</p>
<p><img src= "/img/loading.gif" data-lazy-src="https://s1.ax1x.com/2020/07/12/U850dU.png" alt="图5：WordTree for COCO and ImageNet" style="zoom: 68%;"></p>
<p>树结构表示物体之间的从属关系非常合适，第一个大类，物体，物体之下有动物、人工制品、自然物体等，动物中又有更具体的分类。此时，在类别中，不对所有的类别进行softmax操作，而对同一层级的类别进行softmax：</p>
<p><img src= "/img/loading.gif" data-lazy-src="https://s1.ax1x.com/2020/07/12/U8oRUO.png" alt="图6：类别softmax" style="zoom: 50%;"></p>
<p>如图6中所示，同一颜色的位置，进行softmax操作，使得同一颜色中只有一个类别预测分值最大。在预测时，从树的根节点开始向下检索，每次选取预测分值最高的子节点，直到所有选择的节点预测分值连乘后小于某一阈值时停止。在训练时，如果标签为人，那么只对人这个节点以及其所有的父节点进行loss计算，而其子节点，男人、女人、小孩等，不进行loss计算。</p>
<p>最后的结果是，Yolo v2可以识别超过9000个物体，作者美其名曰Yolo9000。当然原文中也提到，只有当父节点在检测集中出现过，子节点的预测才会有效。如果子节点是裤子、T恤、裙子等，而父节点衣服在检测集中没有出现过，那么整条预测类别支路几乎都是检测失效的状态。这也合理，给神经网络看的都是狗，让它去预测猫，目前神经网络还没有这么智能。</p>
<p> </p>
<p> </p>
<p> </p>
<h1 id="四代码实现">四、代码实现</h1>
<p>tensorflow版本为1.14 。代码结构如图7所示。</p>
<p><img src= "/img/loading.gif" data-lazy-src="https://s1.ax1x.com/2020/07/28/akGAl4.png" alt="图7：代码结构" style="zoom:80%;"></p>
<p> </p>
<p><strong>训练图集为COOC数据集，为了方便，我直接使用的yolo2_coco_checkpoint权重文件。</strong></p>
<p> </p>
<h2 id="基于图片的目标检测">4.1 基于图片的目标检测</h2>
<p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> cv2 <span class="keyword">import</span> cv2 <span class="keyword">as</span> cv2</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">leaky_relu</span>(<span class="params">x</span>):</span>    <span class="comment">#leaky relu激活函数，leaky_relu激活函数一般用在比较深层次神经网络中</span></span><br><span class="line">    <span class="keyword">return</span> tf.maximum(<span class="number">0.1</span>*x,x)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">yolov2</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,cls_name</span>):</span></span><br><span class="line"></span><br><span class="line">        self.anchor_size = [[<span class="number">0.57273</span>, <span class="number">0.677385</span>], <span class="comment">#coco</span></span><br><span class="line">                           [<span class="number">1.87446</span>, <span class="number">2.06253</span>],</span><br><span class="line">                           [<span class="number">3.33843</span>, <span class="number">5.47434</span>],</span><br><span class="line">                           [<span class="number">7.88282</span>, <span class="number">3.52778</span>],</span><br><span class="line">                           [<span class="number">9.77052</span>, <span class="number">9.16828</span>]]</span><br><span class="line">        self.num_anchors = <span class="built_in">len</span>(self.anchor_size)</span><br><span class="line">        <span class="keyword">if</span> cls_name == <span class="string">'coco'</span>:</span><br><span class="line">            self.CLASS = [<span class="string">'person'</span>, <span class="string">'bicycle'</span>, <span class="string">'car'</span>, <span class="string">'motorbike'</span>, <span class="string">'aeroplane'</span>, <span class="string">'bus'</span>, <span class="string">'train'</span>,</span><br><span class="line">                          <span class="string">'truck'</span>, <span class="string">'boat'</span>, <span class="string">'traffic light'</span>, <span class="string">'fire hydrant'</span>, <span class="string">'stop sign'</span>,</span><br><span class="line">                          <span class="string">'parking meter'</span>, <span class="string">'bench'</span>, <span class="string">'bird'</span>, <span class="string">'cat'</span>, <span class="string">'dog'</span>, <span class="string">'horse'</span>, <span class="string">'sheep'</span>,</span><br><span class="line">                          <span class="string">'cow'</span>, <span class="string">'elephant'</span>, <span class="string">'bear'</span>, <span class="string">'zebra'</span>, <span class="string">'giraffe'</span>, <span class="string">'backpack'</span>, <span class="string">'umbrella'</span>,</span><br><span class="line">                          <span class="string">'handbag'</span>, <span class="string">'tie'</span>, <span class="string">'suitcase'</span>, <span class="string">'frisbee'</span>, <span class="string">'skis'</span>, <span class="string">'snowboard'</span>, <span class="string">'sports ball'</span>,</span><br><span class="line">                          <span class="string">'kite'</span>, <span class="string">'baseball bat'</span>, <span class="string">'baseball glove'</span>, <span class="string">'skateboard'</span>, <span class="string">'surfboard'</span>,</span><br><span class="line">                          <span class="string">'tennis racket'</span>, <span class="string">'bottle'</span>, <span class="string">'wine glass'</span>, <span class="string">'cup'</span>, <span class="string">'fork'</span>, <span class="string">'knife'</span>, <span class="string">'spoon'</span>,</span><br><span class="line">                          <span class="string">'bowl'</span>, <span class="string">'banana'</span>, <span class="string">'apple'</span>, <span class="string">'sandwich'</span>, <span class="string">'orange'</span>, <span class="string">'broccoli'</span>, <span class="string">'carrot'</span>,</span><br><span class="line">                          <span class="string">'hot dog'</span>, <span class="string">'pizza'</span>, <span class="string">'donut'</span>, <span class="string">'cake'</span>, <span class="string">'chair'</span>, <span class="string">'sofa'</span>, <span class="string">'pottedplant'</span>,</span><br><span class="line">                          <span class="string">'bed'</span>, <span class="string">'diningtable'</span>, <span class="string">'toilet'</span>, <span class="string">'tvmonitor'</span>, <span class="string">'laptop'</span>, <span class="string">'mouse'</span>,</span><br><span class="line">                          <span class="string">'remote'</span>, <span class="string">'keyboard'</span>, <span class="string">'cell phone'</span>, <span class="string">'microwave'</span>, <span class="string">'oven'</span>, <span class="string">'toaster'</span>,</span><br><span class="line">                          <span class="string">'sink'</span>, <span class="string">'refrigerator'</span>, <span class="string">'book'</span>, <span class="string">'clock'</span>, <span class="string">'vase'</span>, <span class="string">'scissors'</span>, <span class="string">'teddy bear'</span>,</span><br><span class="line">                          <span class="string">'hair drier'</span>, <span class="string">'toothbrush'</span>]  <span class="comment">#coco</span></span><br><span class="line">            self.f_num = <span class="number">425</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.CLASS = [<span class="string">"aeroplane"</span>, <span class="string">"bicycle"</span>, <span class="string">"bird"</span>, <span class="string">"boat"</span>, <span class="string">"bottle"</span>, <span class="string">"bus"</span>, <span class="string">"car"</span>, <span class="string">"cat"</span>, <span class="string">"chair"</span>, <span class="string">"cow"</span>, <span class="string">"diningtable"</span>, <span class="string">"dog"</span>, <span class="string">"horse"</span>, <span class="string">"motorbike"</span>, <span class="string">"person"</span>, <span class="string">"pottedplant"</span>, <span class="string">"sheep"</span>, <span class="string">"sofa"</span>, <span class="string">"train"</span>, <span class="string">"tvmonitor"</span>]</span><br><span class="line">            self.f_num = <span class="number">125</span></span><br><span class="line"></span><br><span class="line">        self.num_class = <span class="built_in">len</span>(self.CLASS)</span><br><span class="line">        self.feature_map_size = (<span class="number">13</span>,<span class="number">13</span>)</span><br><span class="line">        self.object_scale = <span class="number">5.</span> <span class="comment">#'物体位于gird cell时计算置信度的修正系数'</span></span><br><span class="line">        self.no_object_scale = <span class="number">1.</span>   <span class="comment">#'物体位于gird cell时计算置信度的修正系数'</span></span><br><span class="line">        self.class_scale = <span class="number">1.</span>  <span class="comment">#'计算分类损失的修正系数'</span></span><br><span class="line">        self.coordinates_scale = <span class="number">1.</span>  <span class="comment">#'计算坐标损失的修正系数'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#################################NewWork</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">conv2d</span>(<span class="params">self,x,filters_num,filters_size,pad_size=<span class="number">0</span>,stride=<span class="number">1</span>,batch_normalize=<span class="literal">True</span>,activation=leaky_relu,use_bias=<span class="literal">False</span>,name=<span class="string">'conv2d'</span></span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> pad_size &gt; <span class="number">0</span>:</span><br><span class="line">            x = tf.pad(x,[[<span class="number">0</span>,<span class="number">0</span>],[pad_size,pad_size],[pad_size,pad_size],[<span class="number">0</span>,<span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line">        out = tf.layers.conv2d(x,filters=filters_num,kernel_size=filters_size,strides=stride,padding=<span class="string">'VALID'</span>,activation=<span class="literal">None</span>,use_bias=use_bias,name=name)</span><br><span class="line">        <span class="comment"># BN应该在卷积层conv和激活函数activation之间,</span></span><br><span class="line">        <span class="comment"># (后面有BN层的conv就不用偏置bias，并激活函数activation在后)</span></span><br><span class="line">        <span class="keyword">if</span> batch_normalize:</span><br><span class="line">            out = tf.layers.batch_normalization(out,axis=-<span class="number">1</span>,momentum=<span class="number">0.9</span>,training=<span class="literal">False</span>,name=name+<span class="string">'_bn'</span>)</span><br><span class="line">        <span class="keyword">if</span> activation:</span><br><span class="line">            out = activation(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxpool</span>(<span class="params">self,x, size=<span class="number">2</span>, stride=<span class="number">2</span>, name=<span class="string">'maxpool'</span></span>):</span></span><br><span class="line">        <span class="keyword">return</span> tf.layers.max_pooling2d(x, pool_size=size, strides=stride,name=name)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># passthrough</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">passthrough</span>(<span class="params">self,x, stride</span>):</span></span><br><span class="line">        <span class="keyword">return</span> tf.space_to_depth(x, block_size=stride)</span><br><span class="line">        <span class="comment">#或者tf.extract_image_patches</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">darknet</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">        x = tf.placeholder(dtype=tf.float32,shape=[<span class="literal">None</span>,<span class="number">416</span>,<span class="number">416</span>,<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">        net = self.conv2d(x, filters_num=<span class="number">32</span>, filters_size=<span class="number">3</span>, pad_size=<span class="number">1</span>,</span><br><span class="line">                     name=<span class="string">'conv1'</span>)</span><br><span class="line">        net = self.maxpool(net, size=<span class="number">2</span>, stride=<span class="number">2</span>, name=<span class="string">'pool1'</span>)</span><br><span class="line"></span><br><span class="line">        net = self.conv2d(net, <span class="number">64</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">'conv2'</span>)</span><br><span class="line">        net = self.maxpool(net, <span class="number">2</span>, <span class="number">2</span>, name=<span class="string">'pool2'</span>)</span><br><span class="line"></span><br><span class="line">        net = self.conv2d(net, <span class="number">128</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">'conv3_1'</span>)</span><br><span class="line">        net = self.conv2d(net, <span class="number">64</span>, <span class="number">1</span>, <span class="number">0</span>, name=<span class="string">'conv3_2'</span>)</span><br><span class="line">        net = self.conv2d(net, <span class="number">128</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">'conv3_3'</span>)</span><br><span class="line">        net = self.maxpool(net, <span class="number">2</span>, <span class="number">2</span>, name=<span class="string">'pool3'</span>)</span><br><span class="line"></span><br><span class="line">        net = self.conv2d(net, <span class="number">256</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">'conv4_1'</span>)</span><br><span class="line">        net = self.conv2d(net, <span class="number">128</span>, <span class="number">1</span>, <span class="number">0</span>, name=<span class="string">'conv4_2'</span>)</span><br><span class="line">        net = self.conv2d(net, <span class="number">256</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">'conv4_3'</span>)</span><br><span class="line">        net = self.maxpool(net, <span class="number">2</span>, <span class="number">2</span>, name=<span class="string">'pool4'</span>)</span><br><span class="line"></span><br><span class="line">        net = self.conv2d(net, <span class="number">512</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">'conv5_1'</span>)</span><br><span class="line">        net = self.conv2d(net, <span class="number">256</span>, <span class="number">1</span>, <span class="number">0</span>, name=<span class="string">'conv5_2'</span>)</span><br><span class="line">        net = self.conv2d(net, <span class="number">512</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">'conv5_3'</span>)</span><br><span class="line">        net = self.conv2d(net, <span class="number">256</span>, <span class="number">1</span>, <span class="number">0</span>, name=<span class="string">'conv5_4'</span>)</span><br><span class="line">        net = self.conv2d(net, <span class="number">512</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">'conv5_5'</span>)  <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 这一层特征图，要进行后面passthrough</span></span><br><span class="line">        shortcut = net</span><br><span class="line">        net = self.maxpool(net, <span class="number">2</span>, <span class="number">2</span>, name=<span class="string">'pool5'</span>)  <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">        net = self.conv2d(net, <span class="number">1024</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">'conv6_1'</span>)</span><br><span class="line">        net = self.conv2d(net, <span class="number">512</span>, <span class="number">1</span>, <span class="number">0</span>, name=<span class="string">'conv6_2'</span>)</span><br><span class="line">        net = self.conv2d(net, <span class="number">1024</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">'conv6_3'</span>)</span><br><span class="line">        net = self.conv2d(net, <span class="number">512</span>, <span class="number">1</span>, <span class="number">0</span>, name=<span class="string">'conv6_4'</span>)</span><br><span class="line">        net = self.conv2d(net, <span class="number">1024</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">'conv6_5'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 训练检测网络时去掉了分类网络的网络最后一个卷积层，</span></span><br><span class="line">        <span class="comment"># 在后面增加了三个卷积核尺寸为3 * 3，卷积核数量为1024的卷积层，并在这三个卷积层的最后一层后面跟一个卷积核尺寸为1 * 1</span></span><br><span class="line">        <span class="comment"># 的卷积层，卷积核数量是（B * （5 + C））。</span></span><br><span class="line">        <span class="comment"># 对于VOC数据集，卷积层输入图像尺寸为416 * 416</span></span><br><span class="line">        <span class="comment"># 时最终输出是13 * 13</span></span><br><span class="line">        <span class="comment"># 个栅格，每个栅格预测5种boxes大小，每个box包含5个坐标值和20个条件类别概率，所以输出维度是13 * 13 * 5 * （5 + 20）= 13 * 13 * 125。</span></span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        <span class="comment"># 检测网络加入了passthrough layer，从最后一个输出为26 * 26 * 512</span></span><br><span class="line">        <span class="comment"># 的卷积层连接到新加入的三个卷积核尺寸为3 * 3</span></span><br><span class="line">        <span class="comment"># 的卷积层的第二层，使模型有了细粒度特征。</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 下面这部分主要是training for detection</span></span><br><span class="line">        net = self.conv2d(net, <span class="number">1024</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">'conv7_1'</span>)</span><br><span class="line">        net = self.conv2d(net, <span class="number">1024</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">'conv7_2'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># shortcut增加了一个中间卷积层，先采用64个1*1卷积核进行卷积，然后再进行passthrough处理</span></span><br><span class="line">        <span class="comment"># 这样26*26*512 -&gt; 26*26*64 -&gt; 13*13*256的特征图</span></span><br><span class="line">        shortcut = self.conv2d(shortcut, <span class="number">64</span>, <span class="number">1</span>, <span class="number">0</span>, name=<span class="string">'conv_shortcut'</span>)</span><br><span class="line">        shortcut = self.passthrough(shortcut, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 连接之后，变成13*13*（1024+256）</span></span><br><span class="line">        net = tf.concat([shortcut, net],-<span class="number">1</span>)  <span class="comment"># channel整合到一起，concatenated with the original features，passthrough层与ResNet网络的shortcut类似，以前面更高分辨率的特征图为输入，然后将其连接到后面的低分辨率特征图上，</span></span><br><span class="line">        net = self.conv2d(net, <span class="number">1024</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">'conv8'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># detection layer: 最后用一个1*1卷积去调整channel，该层没有BN层和激活函数，变成: S*S*(B*(5+C))，在这里为：13*13*425</span></span><br><span class="line">        output = self.conv2d(net, filters_num=self.f_num, filters_size=<span class="number">1</span>, batch_normalize=<span class="literal">False</span>, activation=<span class="literal">None</span>,</span><br><span class="line">                        use_bias=<span class="literal">True</span>, name=<span class="string">'conv_dec'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> output,x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#生成anchor  ---&gt;  decode</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">decode</span>(<span class="params">self,net</span>):</span></span><br><span class="line"></span><br><span class="line">        self.anchor_size = tf.constant(self.anchor_size , dtype=tf.float32)</span><br><span class="line"></span><br><span class="line">        net = tf.reshape(net, [-<span class="number">1</span>, <span class="number">13</span> * <span class="number">13</span>, self.num_anchors, self.num_class + <span class="number">5</span>]) <span class="comment">#[batch,169,5,85]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 偏移量、置信度、类别</span></span><br><span class="line">        <span class="comment">#中心坐标相对于该cell坐上角的偏移量，sigmoid函数归一化到(0,1)</span></span><br><span class="line">        xy_offset = tf.nn.sigmoid(net[:, :, :, <span class="number">0</span>:<span class="number">2</span>])</span><br><span class="line">        wh_offset = tf.exp(net[:, :, :, <span class="number">2</span>:<span class="number">4</span>])</span><br><span class="line">        obj_probs = tf.nn.sigmoid(net[:, :, :, <span class="number">4</span>])  <span class="comment"># 置信度,这个东西就是相当于v1中的confidence</span></span><br><span class="line">        class_probs = tf.nn.softmax(net[:, :, :, <span class="number">5</span>:])  <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 在feature map对应坐标生成anchors，每个坐标五个</span></span><br><span class="line">        height_index = tf.<span class="built_in">range</span>(self.feature_map_size[<span class="number">0</span>], dtype=tf.float32)</span><br><span class="line">        width_index = tf.<span class="built_in">range</span>(self.feature_map_size[<span class="number">1</span>], dtype=tf.float32)</span><br><span class="line"></span><br><span class="line">        x_cell, y_cell = tf.meshgrid(height_index, width_index)</span><br><span class="line">        x_cell = tf.reshape(x_cell, [<span class="number">1</span>, -<span class="number">1</span>, <span class="number">1</span>])  <span class="comment"># 和上面[H*W,num_anchors,num_class+5]对应</span></span><br><span class="line">        y_cell = tf.reshape(y_cell, [<span class="number">1</span>, -<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># decode</span></span><br><span class="line">        bbox_x = (x_cell + xy_offset[:, :, :, <span class="number">0</span>]) / <span class="number">13</span></span><br><span class="line">        bbox_y = (y_cell + xy_offset[:, :, :, <span class="number">1</span>]) / <span class="number">13</span></span><br><span class="line">        bbox_w = (self.anchor_size[:, <span class="number">0</span>] * wh_offset[:, :, :, <span class="number">0</span>]) / <span class="number">13</span></span><br><span class="line">        bbox_h = (self.anchor_size[:, <span class="number">1</span>] * wh_offset[:, :, :, <span class="number">1</span>]) / <span class="number">13</span></span><br><span class="line"></span><br><span class="line">        bboxes = tf.stack([bbox_x - bbox_w / <span class="number">2</span>, bbox_y - bbox_h / <span class="number">2</span>, bbox_x + bbox_w / <span class="number">2</span>, bbox_y + bbox_h / <span class="number">2</span>],</span><br><span class="line">                          axis=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> bboxes, obj_probs, class_probs</span><br><span class="line"></span><br><span class="line">    <span class="comment">#将边界框超出整张图片(0,0)—(415,415)的部分cut掉</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">bboxes_cut</span>(<span class="params">self,bbox_min_max, bboxes</span>):</span></span><br><span class="line">        bboxes = np.copy(bboxes)</span><br><span class="line">        bboxes = np.transpose(bboxes)</span><br><span class="line">        bbox_min_max = np.transpose(bbox_min_max)</span><br><span class="line">        <span class="comment"># cut the box</span></span><br><span class="line">        bboxes[<span class="number">0</span>] = np.maximum(bboxes[<span class="number">0</span>], bbox_min_max[<span class="number">0</span>])  <span class="comment"># xmin</span></span><br><span class="line">        bboxes[<span class="number">1</span>] = np.maximum(bboxes[<span class="number">1</span>], bbox_min_max[<span class="number">1</span>])  <span class="comment"># ymin</span></span><br><span class="line">        bboxes[<span class="number">2</span>] = np.minimum(bboxes[<span class="number">2</span>], bbox_min_max[<span class="number">2</span>])  <span class="comment"># xmax</span></span><br><span class="line">        bboxes[<span class="number">3</span>] = np.minimum(bboxes[<span class="number">3</span>], bbox_min_max[<span class="number">3</span>])  <span class="comment"># ymax</span></span><br><span class="line">        bboxes = np.transpose(bboxes)</span><br><span class="line">        <span class="keyword">return</span> bboxes</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">bboxes_sort</span>(<span class="params">self,classes, scores, bboxes, top_k=<span class="number">400</span></span>):</span></span><br><span class="line">        index = np.argsort(-scores)</span><br><span class="line">        classes = classes[index][:top_k]</span><br><span class="line">        scores = scores[index][:top_k]</span><br><span class="line">        bboxes = bboxes[index][:top_k]</span><br><span class="line">        <span class="keyword">return</span> classes, scores, bboxes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">bboxes_iou</span>(<span class="params">self,bboxes1, bboxes2</span>):</span></span><br><span class="line">        bboxes1 = np.transpose(bboxes1)</span><br><span class="line">        bboxes2 = np.transpose(bboxes2)</span><br><span class="line"></span><br><span class="line">        int_ymin = np.maximum(bboxes1[<span class="number">0</span>], bboxes2[<span class="number">0</span>])</span><br><span class="line">        int_xmin = np.maximum(bboxes1[<span class="number">1</span>], bboxes2[<span class="number">1</span>])</span><br><span class="line">        int_ymax = np.minimum(bboxes1[<span class="number">2</span>], bboxes2[<span class="number">2</span>])</span><br><span class="line">        int_xmax = np.minimum(bboxes1[<span class="number">3</span>], bboxes2[<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">        int_h = np.maximum(int_ymax - int_ymin, <span class="number">0.</span>)</span><br><span class="line">        int_w = np.maximum(int_xmax - int_xmin, <span class="number">0.</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算IOU</span></span><br><span class="line">        int_vol = int_h * int_w  <span class="comment"># 交集面积</span></span><br><span class="line">        vol1 = (bboxes1[<span class="number">2</span>] - bboxes1[<span class="number">0</span>]) * (bboxes1[<span class="number">3</span>] - bboxes1[<span class="number">1</span>])  <span class="comment"># bboxes1面积</span></span><br><span class="line">        vol2 = (bboxes2[<span class="number">2</span>] - bboxes2[<span class="number">0</span>]) * (bboxes2[<span class="number">3</span>] - bboxes2[<span class="number">1</span>])  <span class="comment"># bboxes2面积</span></span><br><span class="line">        IOU = int_vol / (vol1 + vol2 - int_vol)  <span class="comment"># IOU=交集/并集</span></span><br><span class="line">        <span class="keyword">return</span> IOU</span><br><span class="line"></span><br><span class="line">    <span class="comment"># NMS，或者用tf.image.non_max_suppression</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">bboxes_nms</span>(<span class="params">self,classes, scores, bboxes, nms_threshold=<span class="number">0.2</span></span>):</span></span><br><span class="line">        keep_bboxes = np.ones(scores.shape, dtype=np.<span class="built_in">bool</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(scores.size - <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> keep_bboxes[i]:</span><br><span class="line">                overlap = self.bboxes_iou(bboxes[i], bboxes[(i + <span class="number">1</span>):])</span><br><span class="line">                keep_overlap = np.logical_or(overlap &lt; nms_threshold,</span><br><span class="line">                                             classes[(i + <span class="number">1</span>):] != classes[i])  <span class="comment"># IOU没有超过0.5或者是不同的类则保存下来</span></span><br><span class="line">                keep_bboxes[(i + <span class="number">1</span>):] = np.logical_and(keep_bboxes[(i + <span class="number">1</span>):], keep_overlap)</span><br><span class="line"></span><br><span class="line">        idxes = np.where(keep_bboxes)</span><br><span class="line">        <span class="keyword">return</span> classes[idxes], scores[idxes], bboxes[idxes]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">postprocess</span>(<span class="params">self,bboxes, obj_probs, class_probs, image_shape=(<span class="params"><span class="number">416</span>, <span class="number">416</span></span>), threshold=<span class="number">0.5</span></span>):</span></span><br><span class="line"></span><br><span class="line">        bboxes = np.reshape(bboxes, [-<span class="number">1</span>, <span class="number">4</span>])</span><br><span class="line">        <span class="comment"># 将所有box还原成图片中真实的位置</span></span><br><span class="line">        bboxes[:, <span class="number">0</span>:<span class="number">1</span>] *= <span class="built_in">float</span>(image_shape[<span class="number">1</span>])</span><br><span class="line">        bboxes[:, <span class="number">1</span>:<span class="number">2</span>] *= <span class="built_in">float</span>(image_shape[<span class="number">0</span>])</span><br><span class="line">        bboxes[:, <span class="number">2</span>:<span class="number">3</span>] *= <span class="built_in">float</span>(image_shape[<span class="number">1</span>])</span><br><span class="line">        bboxes[:, <span class="number">3</span>:<span class="number">4</span>] *= <span class="built_in">float</span>(image_shape[<span class="number">0</span>])</span><br><span class="line">        bboxes = bboxes.astype(np.int32)  <span class="comment"># 转int</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        bbox_min_max = [<span class="number">0</span>, <span class="number">0</span>, image_shape[<span class="number">1</span>] - <span class="number">1</span>, image_shape[<span class="number">0</span>] - <span class="number">1</span>]</span><br><span class="line">        bboxes = self.bboxes_cut(bbox_min_max, bboxes)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        obj_probs = np.reshape(obj_probs, [-<span class="number">1</span>])  <span class="comment"># 13*13*5</span></span><br><span class="line">        class_probs = np.reshape(class_probs, [<span class="built_in">len</span>(obj_probs), -<span class="number">1</span>])  <span class="comment"># (13*13*5,80)</span></span><br><span class="line">        class_max_index = np.argmax(class_probs, axis=<span class="number">1</span>)  <span class="comment"># max类别概率对应的index</span></span><br><span class="line">        class_probs = class_probs[np.arange(<span class="built_in">len</span>(obj_probs)), class_max_index]</span><br><span class="line">        scores = obj_probs * class_probs  <span class="comment"># 置信度*max类别概率=类别置信度scores</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 类别置信度scores&gt;threshold的边界框bboxes留下</span></span><br><span class="line">        keep_index = scores &gt; threshold</span><br><span class="line">        class_max_index = class_max_index[keep_index]</span><br><span class="line">        scores = scores[keep_index]</span><br><span class="line">        bboxes = bboxes[keep_index]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># (2)排序top_k(默认为400)</span></span><br><span class="line">        class_max_index, scores, bboxes = self.bboxes_sort(class_max_index, scores, bboxes)</span><br><span class="line">        <span class="comment"># (3)NMS</span></span><br><span class="line">        class_max_index, scores, bboxes = self.bboxes_nms(class_max_index, scores, bboxes)</span><br><span class="line">        <span class="keyword">return</span> bboxes, scores, class_max_index</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">preprocess_image</span>(<span class="params">self,image, image_size=(<span class="params"><span class="number">416</span>, <span class="number">416</span></span>)</span>):</span></span><br><span class="line"></span><br><span class="line">        image_cp = np.copy(image).astype(np.float32)</span><br><span class="line">        image_rgb = cv2.cvtColor(image_cp, cv2.COLOR_BGR2RGB)</span><br><span class="line">        image_resized = cv2.resize(image_rgb, image_size)</span><br><span class="line">        image_normalized = image_resized.astype(np.float32) / <span class="number">225.0</span></span><br><span class="line">        image_expanded = np.expand_dims(image_normalized, axis=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> image_expanded</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    train part</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">preprocess_true_boxes</span>(<span class="params">self,true_box,anchors,img_size = (<span class="params"><span class="number">416</span>,<span class="number">416</span></span>)</span>):</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        :param true_box:实际框的位置和类别,2D TENSOR:(batch,5)</span></span><br><span class="line"><span class="string">        :param anchors:anchors : 实际anchor boxes 的值，论文中使用了五个。[w,h]，都是相对于gird cell 的比值。</span></span><br><span class="line"><span class="string">                2d</span></span><br><span class="line"><span class="string">            第二个维度：[w,h]，w,h,都是相对于gird cell长宽的比值。</span></span><br><span class="line"><span class="string">           [1.08, 1.19], [3.42, 4.41], [6.63, 11.38], [9.42, 5.11], [16.62, 10.52]</span></span><br><span class="line"><span class="string">        :param img_size:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">           -detectors_mask: 取值是0或者1，这里的shape是[13,13,5,1]</span></span><br><span class="line"><span class="string">                第四个维度：0/1。1的就是用于预测改true boxes 的 anchor boxes</span></span><br><span class="line"><span class="string">           -matching_true_boxes:这里的shape是[13,13,5,5]。</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        w,h = img_size</span><br><span class="line">        feature_w = w // <span class="number">32</span></span><br><span class="line">        feature_h = h // <span class="number">32</span></span><br><span class="line"></span><br><span class="line">        num_box_params = true_box.shape[<span class="number">1</span>]</span><br><span class="line">        detectors_mask = np.zeros((feature_h,feature_w,self.num_anchors,<span class="number">1</span>),dtype=np.float32)</span><br><span class="line">        matching_true_boxes = np.zeros((feature_h,feature_w,self.num_anchors,num_box_params),dtype=np.float32)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> true_box:</span><br><span class="line">            <span class="comment">#提取类别信息，属于哪类</span></span><br><span class="line">            box_class = i[<span class="number">4</span>:<span class="number">5</span>]</span><br><span class="line">            <span class="comment">#换算成相对于gird cell的值</span></span><br><span class="line">            box = i[<span class="number">0</span>:<span class="number">4</span>] * np.array([feature_w, feature_h, feature_w, feature_h])</span><br><span class="line">            k = np.floor(box[<span class="number">1</span>]).astype(<span class="string">'int'</span>) <span class="comment">#y方向上属于第几个gird cell</span></span><br><span class="line">            j = np.floor(box[<span class="number">0</span>]).astype(<span class="string">'int'</span>) <span class="comment">#x方向上属于第几个gird cell</span></span><br><span class="line">            best_iou = <span class="number">0</span></span><br><span class="line">            best_anchor = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">#计算anchor boxes 和 true boxes的iou ，一个true box一个best anchor</span></span><br><span class="line">            <span class="keyword">for</span> m,anchor <span class="keyword">in</span> <span class="built_in">enumerate</span>(anchors):</span><br><span class="line">                box_maxes = box[<span class="number">2</span>:<span class="number">4</span>] / <span class="number">2.</span></span><br><span class="line">                box_mins = -box_maxes</span><br><span class="line">                anchor_maxes = (anchor / <span class="number">2.</span>)</span><br><span class="line">                anchor_mins = -anchor_maxes</span><br><span class="line"></span><br><span class="line">                intersect_mins = np.maximum(box_mins, anchor_mins)</span><br><span class="line">                intersect_maxes = np.minimum(box_maxes, anchor_maxes)</span><br><span class="line">                intersect_wh = np.maximum(intersect_maxes - intersect_mins, <span class="number">0.</span>)</span><br><span class="line">                intersect_area = intersect_wh[<span class="number">0</span>] * intersect_wh[<span class="number">1</span>]</span><br><span class="line">                box_area = box[<span class="number">2</span>] * box[<span class="number">3</span>]</span><br><span class="line">                anchor_area = anchor[<span class="number">0</span>] * anchor[<span class="number">1</span>]</span><br><span class="line">                iou = intersect_area / (box_area + anchor_area - intersect_area)</span><br><span class="line">                <span class="keyword">if</span> iou &gt; best_iou:</span><br><span class="line">                    best_iou = iou</span><br><span class="line">                    best_anchor = m</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> best_iou &gt; <span class="number">0</span>:</span><br><span class="line">                detectors_mask[k, j, best_anchor] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                adjusted_box = np.array(  <span class="comment">#找到最佳预测anchor boxes</span></span><br><span class="line">                    [</span><br><span class="line">                        box[<span class="number">0</span>] - j, box[<span class="number">1</span>] - k, <span class="comment">#'x,y都是相对于gird cell的位置，左上角[0,0]，右下角[1,1]'</span></span><br><span class="line">                        np.log(box[<span class="number">2</span>] / anchors[best_anchor][<span class="number">0</span>]), <span class="comment">#'对应实际框w,h和anchor boxes w,h的比值取log函数'</span></span><br><span class="line">                        np.log(box[<span class="number">3</span>] / anchors[best_anchor][<span class="number">1</span>]), box_class <span class="comment">#'class实际框的物体是属于第几类'</span></span><br><span class="line">                    ],</span><br><span class="line">                    dtype=np.float32)</span><br><span class="line">                matching_true_boxes[k, j, best_anchor] = adjusted_box</span><br><span class="line">            <span class="keyword">return</span> detectors_mask, matching_true_boxes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">yolo_head</span>(<span class="params">self,feature_map, anchors, num_classes</span>):</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        这个函数是输入yolo的输出层的特征，转化成相对于gird cell坐标的x,y，相对于gird cell长宽的w,h，</span></span><br><span class="line"><span class="string">        pred_confidence是判断否存在物体的概率，pred_class_prob是sofrmax后各个类别分别的概率</span></span><br><span class="line"><span class="string">        :param feats:  网络最后一层输出 [none,13,13,125]/[none,13,13,425]</span></span><br><span class="line"><span class="string">        :param anchors:[5,n]</span></span><br><span class="line"><span class="string">        :param num_classes:类别数</span></span><br><span class="line"><span class="string">        :return:x,y,w,h在loss function中计算iou，然后计算iou损失。</span></span><br><span class="line"><span class="string">                然后和pred_confidence计算confidence_loss，pred_class_prob用于计算classification_loss。</span></span><br><span class="line"><span class="string">                box_xy : 每张图片的每个gird cell中的每个pred_boxes中心点x,y相对于其所在gird cell的坐标值，左上顶点为[0,0],右下顶点为[1,1]。</span></span><br><span class="line"><span class="string">                shape:[-1,13,13,5,2].</span></span><br><span class="line"><span class="string">                box_wh : 每张图片的每个gird cell中的每个pred_boxes的w,h都是相对于gird cell的比值</span></span><br><span class="line"><span class="string">                shape:[-1,13,13,5,2].</span></span><br><span class="line"><span class="string">                box_confidence : 每张图片的每个gird cell中的每个pred_boxes的，判断是否存在可检测物体的概率。</span></span><br><span class="line"><span class="string">                shape:[-1,13,13,5,1]。各维度信息同上。</span></span><br><span class="line"><span class="string">                box_class_pred : 每张图片的每个gird cell中的每个pred_boxes所框起来的各个类别分别的概率(经过了softmax)。</span></span><br><span class="line"><span class="string">                shape:[-1,13,13,5,20/80]</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">        anchors = tf.reshape(tf.constant(anchors,dtype=tf.float32),[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,self.num_anchors,<span class="number">2</span>])</span><br><span class="line">        num_gird_cell = tf.shape(feature_map)[<span class="number">1</span>:<span class="number">3</span>] <span class="comment">#[13,13]</span></span><br><span class="line">        conv_height_index = K.arange(<span class="number">0</span>,stop=num_gird_cell[<span class="number">0</span>])</span><br><span class="line">        conv_width_index = K.arange(<span class="number">0</span>,stop=num_gird_cell[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        conv_height_index = tf.tile(conv_height_index, [num_gird_cell[<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line">        conv_width_index = tf.tile(</span><br><span class="line">            tf.expand_dims(conv_width_index, <span class="number">0</span>), [num_gird_cell[<span class="number">0</span>], <span class="number">1</span>])</span><br><span class="line">        conv_width_index = K.flatten(K.transpose(conv_width_index))</span><br><span class="line">        conv_index = K.transpose(K.stack([conv_height_index,conv_width_index]))</span><br><span class="line">        conv_index = K.reshape(conv_index,[<span class="number">1</span>,num_gird_cell[<span class="number">0</span>],num_gird_cell[<span class="number">1</span>],<span class="number">1</span>,<span class="number">2</span>])<span class="comment">#[1，13，13，1，2]</span></span><br><span class="line">        conv_index = K.cast(conv_index,K.dtype(feature_map))</span><br><span class="line">        <span class="comment">#[[0,0][0,1]....[0,12],[1,0]...]</span></span><br><span class="line">        feature_map = K.reshape(feature_map,[-<span class="number">1</span>,num_gird_cell[<span class="number">0</span>],num_gird_cell[<span class="number">1</span>],self.num_anchors,self.num_class + <span class="number">5</span>])</span><br><span class="line">        num_gird_cell = K.cast(K.reshape(num_gird_cell,[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>]),K.dtype(feature_map))</span><br><span class="line"></span><br><span class="line">        box_xy = K.sigmoid(feature_map[...,:<span class="number">2</span>])</span><br><span class="line">        box_wh = K.exp(feature_map[...,<span class="number">2</span>:<span class="number">4</span>])</span><br><span class="line">        confidence = K.sigmoid(feature_map[...,<span class="number">4</span>:<span class="number">5</span>])</span><br><span class="line">        cls_prob = K.softmax(feature_map[...,<span class="number">5</span>:])</span><br><span class="line"></span><br><span class="line">        xy = (box_xy + conv_index) / num_gird_cell</span><br><span class="line">        wh = box_wh * anchors / num_gird_cell</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> xy,wh,confidence,cls_prob</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">loss</span>(<span class="params">self,</span></span></span><br><span class="line"><span class="function"><span class="params">             net,</span></span></span><br><span class="line"><span class="function"><span class="params">             true_boxes,</span></span></span><br><span class="line"><span class="function"><span class="params">             detectors_mask,</span></span></span><br><span class="line"><span class="function"><span class="params">             matching_true_boxes,</span></span></span><br><span class="line"><span class="function"><span class="params">             anchors,</span></span></span><br><span class="line"><span class="function"><span class="params">             num_classes</span>):</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        IOU损失，分类损失，坐标损失</span></span><br><span class="line"><span class="string">        confidence_loss：</span></span><br><span class="line"><span class="string">                共有845个anchor_boxes，与true_boxes匹配的用于预测pred_boxes，</span></span><br><span class="line"><span class="string">                未与true_boxes匹配的anchor_boxes用于预测background。在未与true_boxes匹配的anchor_boxes中，</span></span><br><span class="line"><span class="string">                与true_boxes的IOU小于0.6的被标记为background，这部分预测正确，未造成损失。</span></span><br><span class="line"><span class="string">                但未与true_boxes匹配的anchor_boxes中，若与true_boxes的IOU大于0.6的我们需要计算其损失，</span></span><br><span class="line"><span class="string">                因为它未能准确预测background，与true_boxes重合度过高，就是no_objects_loss。</span></span><br><span class="line"><span class="string">                而objects_loss则是与true_boxes匹配的anchor_boxes的预测误差。与YOLOv1不同的是修正系数的改变，</span></span><br><span class="line"><span class="string">                YOLOv1中no_objects_loss和objects_loss分别是0.5和1，而YOLOv2中则是1和5。</span></span><br><span class="line"><span class="string">        classification_loss:</span></span><br><span class="line"><span class="string">                经过softmax（）后，20维向量（数据集中分类种类为20种）的均方误差。</span></span><br><span class="line"><span class="string">        coordinates_loss：</span></span><br><span class="line"><span class="string">                计算x,y的误差由相对于整个图像（416x416）的offset坐标误差的均方改变为相对于gird cell的offset（这个offset是取sigmoid函数得到的处于（0,1）的值）坐标误差的均方。</span></span><br><span class="line"><span class="string">                也将修正系数由5改为了1 。计算w,h的误差由w,h平方根的差的均方误差变为了，</span></span><br><span class="line"><span class="string">                w,h与对true_boxes匹配的anchor_boxes的长宽的比值取log函数，</span></span><br><span class="line"><span class="string">                和YOLOv1的想法一样，对于相等的误差值，降低对大物体误差的惩罚，加大对小物体误差的惩罚。同时也将修正系数由5改为了1。</span></span><br><span class="line"><span class="string">        :param net:[batch_size,13,13,125],网络最后一层输出</span></span><br><span class="line"><span class="string">        :param true_boxes:实际框的位置和类别 [batch,5]</span></span><br><span class="line"><span class="string">        :param detectors_mask:取值是0或者1，[ batch_size，13,13,5,1]</span></span><br><span class="line"><span class="string">                1的就是用于预测改true boxes 的 anchor boxes</span></span><br><span class="line"><span class="string">        :param matching_true_boxes:[-1,13,13,5,5]</span></span><br><span class="line"><span class="string">        :param anchors:</span></span><br><span class="line"><span class="string">        :param num_classes:20</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line"></span><br><span class="line">        xy, wh, confidence, cls_prob = self.yolo_head(net,anchors,num_classes)</span><br><span class="line">        shape = tf.shape(net)</span><br><span class="line">        feature_map = tf.reshape(net,[-<span class="number">1</span>,shape[<span class="number">1</span>],shape[<span class="number">2</span>],self.num_anchors,num_classes + <span class="number">5</span>])</span><br><span class="line">        <span class="comment">#用于和matching_true_boxes计算坐标损失</span></span><br><span class="line">        pred_box = tf.concat([K.sigmoid(feature_map[...,<span class="number">0</span>:<span class="number">2</span>]),feature_map[...,<span class="number">2</span>:<span class="number">4</span>]],-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        pred_xy = tf.to_float(tf.expand_dims(xy,<span class="number">4</span>))<span class="comment">#[-1,13,13,5,2]--&gt;[-1,13,13,5,1,2]</span></span><br><span class="line">        pred_wh = tf.to_float(tf.expand_dims(wh,<span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">        pred_min = tf.to_float(pred_xy - pred_wh / <span class="number">2.0</span>)</span><br><span class="line">        pred_max = tf.to_float(pred_xy + pred_wh / <span class="number">2.0</span>)</span><br><span class="line"></span><br><span class="line">        true_box_shape = K.shape(true_boxes)</span><br><span class="line">        print(true_box_shape)</span><br><span class="line">        true_boxes = K.reshape(true_boxes,[-<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,true_box_shape[<span class="number">1</span>], <span class="number">5</span>])</span><br><span class="line">        <span class="comment">#[-1,1,1,1,-1,5],batch, conv_height, conv_width, num_anchors, num_true_boxes, box_params'</span></span><br><span class="line"></span><br><span class="line">        true_xy = tf.to_float(true_boxes[...,<span class="number">0</span>:<span class="number">2</span>])</span><br><span class="line">        true_wh = tf.to_float(true_boxes[...,<span class="number">2</span>:<span class="number">4</span>])</span><br><span class="line">        true_min = tf.to_float(true_xy - true_wh / <span class="number">2.0</span>)</span><br><span class="line">        true_max = tf.to_float(true_xy + true_wh / <span class="number">2.0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#计算所以abox和tbox的iou</span></span><br><span class="line">        intersect_mins = tf.maximum(pred_min, true_min)</span><br><span class="line">        intersect_maxes = tf.minimum(pred_max, true_max)</span><br><span class="line">        intersect_wh = tf.maximum(intersect_maxes - intersect_mins, <span class="number">0.</span>)</span><br><span class="line">        intersect_areas = tf.to_float(intersect_wh[..., <span class="number">0</span>] * intersect_wh[..., <span class="number">1</span>])</span><br><span class="line">        pred_areas = pred_wh[..., <span class="number">0</span>] * pred_wh[..., <span class="number">1</span>]</span><br><span class="line">        true_areas = true_wh[..., <span class="number">0</span>] * true_wh[..., <span class="number">1</span>]</span><br><span class="line">        union_areas = pred_areas + true_areas - intersect_areas</span><br><span class="line">        iou_scores = intersect_areas / union_areas</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">#可能会有多个tbox落在同一个cell ，只去iou最大的</span></span><br><span class="line">        <span class="comment"># tf.argmax(iou_scores,4)</span></span><br><span class="line">        best_ious = K.<span class="built_in">max</span>(iou_scores, axis=<span class="number">4</span>)</span><br><span class="line">        best_ious = tf.expand_dims(best_ious,axis=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#选出IOU大于0.6的，若IOU小于0.6的被标记为background，</span></span><br><span class="line">        obj_dec = tf.cast(best_ious &gt; <span class="number">0.6</span>,dtype=K.dtype(best_ious))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">#IOU loss</span></span><br><span class="line">        no_obj_w = (self.no_object_scale * obj_dec * detectors_mask) <span class="comment">#</span></span><br><span class="line">        no_obj_loss = no_obj_w * tf.square(-confidence)</span><br><span class="line">        obj_loss = self.object_scale * detectors_mask * tf.square(<span class="number">1</span> - confidence)</span><br><span class="line">        confidence_loss = no_obj_loss + obj_loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">#class loss</span></span><br><span class="line">        match_cls = tf.cast(matching_true_boxes[...,<span class="number">4</span>],dtype=tf.int32)</span><br><span class="line">        match_cls = tf.one_hot(match_cls,num_classes)</span><br><span class="line"></span><br><span class="line">        class_loss = (self.class_scale * detectors_mask * tf.square(match_cls - cls_prob))</span><br><span class="line"></span><br><span class="line">        <span class="comment">#坐标loss</span></span><br><span class="line">        match_box = matching_true_boxes[...,<span class="number">0</span>:<span class="number">4</span>]</span><br><span class="line">        coord_loss = self.coordinates_scale * detectors_mask * tf.square(match_box - pred_box)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        confidence_loss_sum = K.<span class="built_in">sum</span>(confidence_loss)</span><br><span class="line">        class_loss_sum = K.<span class="built_in">sum</span>(class_loss)</span><br><span class="line">        coord_loss_sum = K.<span class="built_in">sum</span>(coord_loss)</span><br><span class="line">        all_loss = <span class="number">0.5</span> * (confidence_loss_sum + class_loss_sum + coord_loss_sum)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> all_loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">draw_detection</span>(<span class="params">self,im, bboxes, scores, cls_inds, labels</span>):</span></span><br><span class="line"></span><br><span class="line">        imgcv = np.copy(im)</span><br><span class="line">        h, w, _ = imgcv.shape</span><br><span class="line">        <span class="keyword">for</span> i, box <span class="keyword">in</span> <span class="built_in">enumerate</span>(bboxes):</span><br><span class="line">            cls_indx = cls_inds[i]</span><br><span class="line">            thick = <span class="built_in">int</span>((h + w) / <span class="number">1000</span>)</span><br><span class="line">            cv2.rectangle(imgcv, (box[<span class="number">0</span>], box[<span class="number">1</span>]), (box[<span class="number">2</span>], box[<span class="number">3</span>]), (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), thick)</span><br><span class="line">            print(<span class="string">"[x, y, w, h]=[%d, %d, %d, %d]"</span> % (box[<span class="number">0</span>], box[<span class="number">1</span>], box[<span class="number">2</span>], box[<span class="number">3</span>]))</span><br><span class="line">            mess = <span class="string">'%s: %.3f'</span> % (labels[cls_indx], scores[i])</span><br><span class="line">            text_loc = (box[<span class="number">0</span>], box[<span class="number">1</span>] - <span class="number">10</span>)</span><br><span class="line">            cv2.putText(imgcv, mess, text_loc, cv2.FONT_HERSHEY_SIMPLEX, <span class="number">1e-3</span> * h, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), thick)</span><br><span class="line">        <span class="comment"># return imgcv</span></span><br><span class="line">        cv2.imshow(<span class="string">"detection_results"</span>, imgcv)  <span class="comment"># 显示图片</span></span><br><span class="line">        cv2.waitKey(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#v1 - v2 , v2 - v3</span></span><br><span class="line"><span class="comment"># 1、加入BN层 批次归一化   input --&gt; 均值为0方差为1正太分布</span></span><br><span class="line"><span class="comment">#    ---》白化  --&gt; 对‘input 变换到 均值0单位方差内的分布</span></span><br><span class="line"><span class="comment"># #使用：input * w --&gt;bn</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    network = yolov2(<span class="string">'coco'</span>)</span><br><span class="line"></span><br><span class="line">    net,x = network.darknet()</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    saver = tf.train.Saver()</span><br><span class="line">    ckpt_path = <span class="string">'./model/v2/yolo2_coco.ckpt'</span></span><br><span class="line">    sess = tf.Session()</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    saver.restore(sess,ckpt_path)</span><br><span class="line"></span><br><span class="line">    img = cv2.imread(<span class="string">'./test/3.jpg'</span>)</span><br><span class="line">    <span class="comment">#shape = img.shape[:2]</span></span><br><span class="line">    img_r = network.preprocess_image(img)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    bboxes, obj_probs, class_probs = network.decode(net)</span><br><span class="line">    bboxes, obj_probs, class_probs = sess.run([bboxes, obj_probs, class_probs],feed_dict={x:img_r})</span><br><span class="line">    bboxes, scores, class_max_index = network.postprocess(bboxes, obj_probs, class_probs)</span><br><span class="line">   </span><br><span class="line">   </span><br><span class="line">    print(<span class="string">'置信度：'</span>,end=<span class="string">""</span>)</span><br><span class="line">    print(scores)</span><br><span class="line">    print(<span class="string">'类别信息：'</span>,end=<span class="string">""</span>)</span><br><span class="line">    print(class_max_index)</span><br><span class="line"></span><br><span class="line">    img_detection = network.draw_detection(cv2.resize(img,(<span class="number">416</span>,<span class="number">416</span>)), bboxes, scores, class_max_index, network.CLASS)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string"> yi、</span></span><br><span class="line"><span class="string">    第一大层  :conv maxpoiling</span></span><br><span class="line"><span class="string">    第2大层:3个卷积，maxpool</span></span><br><span class="line"><span class="string">    3:3个卷积，maxpool</span></span><br><span class="line"><span class="string">    4：3卷积，maxpool</span></span><br><span class="line"><span class="string">    5:5卷积，maxpool   -----------</span></span><br><span class="line"><span class="string">    6:5卷积                       | + add</span></span><br><span class="line"><span class="string">    7三个卷积---------------------</span></span><br><span class="line"><span class="string">    conv  </span></span><br><span class="line"><span class="string"> er:</span></span><br><span class="line"><span class="string">    ahchors生成和decode</span></span><br><span class="line"><span class="string"> san:</span></span><br><span class="line"><span class="string">    裁剪、选出前TOP_K，NMS </span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure>
<p> </p>
<p>
<h4 id="测试1">测试1：</h4>
<p>对同一张测试图片分别做V1和V2版本的目标检测，对比图如下。</p>
<p><img src= "/img/loading.gif" data-lazy-src="https://s1.ax1x.com/2020/07/11/U1Zy9J.jpg" alt="图8：YOLO V1图片检测结果" style="zoom: 60%;"></p>
<p> </p>
<p><img src= "/img/loading.gif" data-lazy-src="https://s1.ax1x.com/2020/07/12/UG9A2t.png" alt="图9：YOLO V2图片检测结果" style="zoom:63%;"></p>
<p>从对比图中可以看出：在YOLO V1中，对于本张测试图片，程序只检测出了人和猫两个物体，并且它们的置信度只有0.249和0.504；而在V2版本中，不仅检测到了更多的物体，人和猫的检测置信度也高达0.778和0.797，说明准确率也在提高。此外，程序在显示多个boungding box的同时也输出了他们的坐标以及大小信息。</p>
<p> </p>
<h4 id="测试2">测试2：</h4>
<p>当然，在V1中有一个失败的测试，即那个行人、车辆都很密集且都尺寸比较小的图片，很遗憾在V2的版本中也没有检测到任何物体。</p>
<p><img src= "/img/loading.gif" data-lazy-src="https://s1.ax1x.com/2020/07/11/U1mTOI.jpg" alt="图10：YOLO V2图片检测结果（失败）" style="zoom:63%;"></p>
<p> </p>
<h4 id="测试3">测试3：</h4>
<p>最后，以我的女神tsy与她剧组的合照作为测试的结尾，效果还是很好的。</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="https://s1.ax1x.com/2020/07/12/UG9ExP.png" alt="图11：YOLO V2图片检测结果（成功）"><figcaption>图11：YOLO V2图片检测结果（成功）</figcaption>
</figure>
<p> </p>
<p> </p>
<h2 id="基于视频的目标检测">4.2 基于视频的目标检测</h2>
<p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br><span class="line">571</span><br><span class="line">572</span><br><span class="line">573</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> cv2 <span class="keyword">import</span> cv2 <span class="keyword">as</span> cv2</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">leaky_relu</span>(<span class="params">x</span>):</span>    <span class="comment">#leaky relu激活函数，leaky_relu激活函数一般用在比较深层次神经网络中</span></span><br><span class="line">    <span class="keyword">return</span> tf.maximum(<span class="number">0.1</span>*x,x)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">yolov2</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,cls_name</span>):</span></span><br><span class="line"></span><br><span class="line">        self.anchor_size = [[<span class="number">0.57273</span>, <span class="number">0.677385</span>], <span class="comment">#coco</span></span><br><span class="line">                           [<span class="number">1.87446</span>, <span class="number">2.06253</span>],</span><br><span class="line">                           [<span class="number">3.33843</span>, <span class="number">5.47434</span>],</span><br><span class="line">                           [<span class="number">7.88282</span>, <span class="number">3.52778</span>],</span><br><span class="line">                           [<span class="number">9.77052</span>, <span class="number">9.16828</span>]]</span><br><span class="line">        self.num_anchors = <span class="built_in">len</span>(self.anchor_size)</span><br><span class="line">        <span class="keyword">if</span> cls_name == <span class="string">'coco'</span>:</span><br><span class="line">            self.CLASS = [<span class="string">'person'</span>, <span class="string">'bicycle'</span>, <span class="string">'car'</span>, <span class="string">'motorbike'</span>, <span class="string">'aeroplane'</span>, <span class="string">'bus'</span>, <span class="string">'train'</span>,</span><br><span class="line">                          <span class="string">'truck'</span>, <span class="string">'boat'</span>, <span class="string">'traffic light'</span>, <span class="string">'fire hydrant'</span>, <span class="string">'stop sign'</span>,</span><br><span class="line">                          <span class="string">'parking meter'</span>, <span class="string">'bench'</span>, <span class="string">'bird'</span>, <span class="string">'cat'</span>, <span class="string">'dog'</span>, <span class="string">'horse'</span>, <span class="string">'sheep'</span>,</span><br><span class="line">                          <span class="string">'cow'</span>, <span class="string">'elephant'</span>, <span class="string">'bear'</span>, <span class="string">'zebra'</span>, <span class="string">'giraffe'</span>, <span class="string">'backpack'</span>, <span class="string">'umbrella'</span>,</span><br><span class="line">                          <span class="string">'handbag'</span>, <span class="string">'tie'</span>, <span class="string">'suitcase'</span>, <span class="string">'frisbee'</span>, <span class="string">'skis'</span>, <span class="string">'snowboard'</span>, <span class="string">'sports ball'</span>,</span><br><span class="line">                          <span class="string">'kite'</span>, <span class="string">'baseball bat'</span>, <span class="string">'baseball glove'</span>, <span class="string">'skateboard'</span>, <span class="string">'surfboard'</span>,</span><br><span class="line">                          <span class="string">'tennis racket'</span>, <span class="string">'bottle'</span>, <span class="string">'wine glass'</span>, <span class="string">'cup'</span>, <span class="string">'fork'</span>, <span class="string">'knife'</span>, <span class="string">'spoon'</span>,</span><br><span class="line">                          <span class="string">'bowl'</span>, <span class="string">'banana'</span>, <span class="string">'apple'</span>, <span class="string">'sandwich'</span>, <span class="string">'orange'</span>, <span class="string">'broccoli'</span>, <span class="string">'carrot'</span>,</span><br><span class="line">                          <span class="string">'hot dog'</span>, <span class="string">'pizza'</span>, <span class="string">'donut'</span>, <span class="string">'cake'</span>, <span class="string">'chair'</span>, <span class="string">'sofa'</span>, <span class="string">'pottedplant'</span>,</span><br><span class="line">                          <span class="string">'bed'</span>, <span class="string">'diningtable'</span>, <span class="string">'toilet'</span>, <span class="string">'tvmonitor'</span>, <span class="string">'laptop'</span>, <span class="string">'mouse'</span>,</span><br><span class="line">                          <span class="string">'remote'</span>, <span class="string">'keyboard'</span>, <span class="string">'cell phone'</span>, <span class="string">'microwave'</span>, <span class="string">'oven'</span>, <span class="string">'toaster'</span>,</span><br><span class="line">                          <span class="string">'sink'</span>, <span class="string">'refrigerator'</span>, <span class="string">'book'</span>, <span class="string">'clock'</span>, <span class="string">'vase'</span>, <span class="string">'scissors'</span>, <span class="string">'teddy bear'</span>,</span><br><span class="line">                          <span class="string">'hair drier'</span>, <span class="string">'toothbrush'</span>]  <span class="comment">#coco</span></span><br><span class="line">            self.f_num = <span class="number">425</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.CLASS = [<span class="string">"aeroplane"</span>, <span class="string">"bicycle"</span>, <span class="string">"bird"</span>, <span class="string">"boat"</span>, <span class="string">"bottle"</span>, <span class="string">"bus"</span>, <span class="string">"car"</span>, <span class="string">"cat"</span>, <span class="string">"chair"</span>, <span class="string">"cow"</span>, <span class="string">"diningtable"</span>, <span class="string">"dog"</span>, <span class="string">"horse"</span>, <span class="string">"motorbike"</span>, <span class="string">"person"</span>, <span class="string">"pottedplant"</span>, <span class="string">"sheep"</span>, <span class="string">"sofa"</span>, <span class="string">"train"</span>, <span class="string">"tvmonitor"</span>]</span><br><span class="line">            self.f_num = <span class="number">125</span></span><br><span class="line"></span><br><span class="line">        self.num_class = <span class="built_in">len</span>(self.CLASS)</span><br><span class="line">        self.feature_map_size = (<span class="number">13</span>,<span class="number">13</span>)</span><br><span class="line">        self.object_scale = <span class="number">5.</span> <span class="comment">#'物体位于gird cell时计算置信度的修正系数'</span></span><br><span class="line">        self.no_object_scale = <span class="number">1.</span>   <span class="comment">#'物体位于gird cell时计算置信度的修正系数'</span></span><br><span class="line">        self.class_scale = <span class="number">1.</span>  <span class="comment">#'计算分类损失的修正系数'</span></span><br><span class="line">        self.coordinates_scale = <span class="number">1.</span>  <span class="comment">#'计算坐标损失的修正系数'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#  NewWork</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">conv2d</span>(<span class="params">self,x,filters_num,filters_size,pad_size=<span class="number">0</span>,stride=<span class="number">1</span>,batch_normalize=<span class="literal">True</span>,activation=leaky_relu,use_bias=<span class="literal">False</span>,name=<span class="string">'conv2d'</span></span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> pad_size &gt; <span class="number">0</span>:</span><br><span class="line">            x = tf.pad(x,[[<span class="number">0</span>,<span class="number">0</span>],[pad_size,pad_size],[pad_size,pad_size],[<span class="number">0</span>,<span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line">        out = tf.layers.conv2d(x,filters=filters_num,kernel_size=filters_size,strides=stride,padding=<span class="string">'VALID'</span>,activation=<span class="literal">None</span>,use_bias=use_bias,name=name)</span><br><span class="line">        <span class="comment"># BN应该在卷积层conv和激活函数activation之间,</span></span><br><span class="line">        <span class="comment"># (后面有BN层的conv就不用偏置bias，并激活函数activation在后)</span></span><br><span class="line">        <span class="keyword">if</span> batch_normalize:</span><br><span class="line">            out = tf.layers.batch_normalization(out,axis=-<span class="number">1</span>,momentum=<span class="number">0.9</span>,training=<span class="literal">False</span>,name=name+<span class="string">'_bn'</span>)</span><br><span class="line">        <span class="keyword">if</span> activation:</span><br><span class="line">            out = activation(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxpool</span>(<span class="params">self,x, size=<span class="number">2</span>, stride=<span class="number">2</span>, name=<span class="string">'maxpool'</span></span>):</span></span><br><span class="line">        <span class="keyword">return</span> tf.layers.max_pooling2d(x, pool_size=size, strides=stride,name=name)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># passthrough</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">passthrough</span>(<span class="params">self,x, stride</span>):</span></span><br><span class="line">        <span class="keyword">return</span> tf.space_to_depth(x, block_size=stride)</span><br><span class="line">        <span class="comment">#或者tf.extract_image_patches</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">darknet</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">        x = tf.placeholder(dtype=tf.float32,shape=[<span class="literal">None</span>,<span class="number">416</span>,<span class="number">416</span>,<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">        net = self.conv2d(x, filters_num=<span class="number">32</span>, filters_size=<span class="number">3</span>, pad_size=<span class="number">1</span>,</span><br><span class="line">                     name=<span class="string">'conv1'</span>)</span><br><span class="line">        net = self.maxpool(net, size=<span class="number">2</span>, stride=<span class="number">2</span>, name=<span class="string">'pool1'</span>)</span><br><span class="line"></span><br><span class="line">        net = self.conv2d(net, <span class="number">64</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">'conv2'</span>)</span><br><span class="line">        net = self.maxpool(net, <span class="number">2</span>, <span class="number">2</span>, name=<span class="string">'pool2'</span>)</span><br><span class="line"></span><br><span class="line">        net = self.conv2d(net, <span class="number">128</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">'conv3_1'</span>)</span><br><span class="line">        net = self.conv2d(net, <span class="number">64</span>, <span class="number">1</span>, <span class="number">0</span>, name=<span class="string">'conv3_2'</span>)</span><br><span class="line">        net = self.conv2d(net, <span class="number">128</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">'conv3_3'</span>)</span><br><span class="line">        net = self.maxpool(net, <span class="number">2</span>, <span class="number">2</span>, name=<span class="string">'pool3'</span>)</span><br><span class="line"></span><br><span class="line">        net = self.conv2d(net, <span class="number">256</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">'conv4_1'</span>)</span><br><span class="line">        net = self.conv2d(net, <span class="number">128</span>, <span class="number">1</span>, <span class="number">0</span>, name=<span class="string">'conv4_2'</span>)</span><br><span class="line">        net = self.conv2d(net, <span class="number">256</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">'conv4_3'</span>)</span><br><span class="line">        net = self.maxpool(net, <span class="number">2</span>, <span class="number">2</span>, name=<span class="string">'pool4'</span>)</span><br><span class="line"></span><br><span class="line">        net = self.conv2d(net, <span class="number">512</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">'conv5_1'</span>)</span><br><span class="line">        net = self.conv2d(net, <span class="number">256</span>, <span class="number">1</span>, <span class="number">0</span>, name=<span class="string">'conv5_2'</span>)</span><br><span class="line">        net = self.conv2d(net, <span class="number">512</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">'conv5_3'</span>)</span><br><span class="line">        net = self.conv2d(net, <span class="number">256</span>, <span class="number">1</span>, <span class="number">0</span>, name=<span class="string">'conv5_4'</span>)</span><br><span class="line">        net = self.conv2d(net, <span class="number">512</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">'conv5_5'</span>)  <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 这一层特征图，要进行后面passthrough</span></span><br><span class="line">        shortcut = net</span><br><span class="line">        net = self.maxpool(net, <span class="number">2</span>, <span class="number">2</span>, name=<span class="string">'pool5'</span>)  <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">        net = self.conv2d(net, <span class="number">1024</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">'conv6_1'</span>)</span><br><span class="line">        net = self.conv2d(net, <span class="number">512</span>, <span class="number">1</span>, <span class="number">0</span>, name=<span class="string">'conv6_2'</span>)</span><br><span class="line">        net = self.conv2d(net, <span class="number">1024</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">'conv6_3'</span>)</span><br><span class="line">        net = self.conv2d(net, <span class="number">512</span>, <span class="number">1</span>, <span class="number">0</span>, name=<span class="string">'conv6_4'</span>)</span><br><span class="line">        net = self.conv2d(net, <span class="number">1024</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">'conv6_5'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 训练检测网络时去掉了分类网络的网络最后一个卷积层，</span></span><br><span class="line">        <span class="comment"># 在后面增加了三个卷积核尺寸为3 * 3，卷积核数量为1024的卷积层，并在这三个卷积层的最后一层后面跟一个卷积核尺寸为1 * 1</span></span><br><span class="line">        <span class="comment"># 的卷积层，卷积核数量是（B * （5 + C））。</span></span><br><span class="line">        <span class="comment"># 对于VOC数据集，卷积层输入图像尺寸为416 * 416</span></span><br><span class="line">        <span class="comment"># 时最终输出是13 * 13</span></span><br><span class="line">        <span class="comment"># 个栅格，每个栅格预测5种boxes大小，每个box包含5个坐标值和20个条件类别概率，所以输出维度是13 * 13 * 5 * （5 + 20）= 13 * 13 * 125。</span></span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        <span class="comment"># 检测网络加入了passthrough layer，从最后一个输出为26 * 26 * 512</span></span><br><span class="line">        <span class="comment"># 的卷积层连接到新加入的三个卷积核尺寸为3 * 3</span></span><br><span class="line">        <span class="comment"># 的卷积层的第二层，使模型有了细粒度特征。</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 下面这部分主要是training for detection</span></span><br><span class="line">        net = self.conv2d(net, <span class="number">1024</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">'conv7_1'</span>)</span><br><span class="line">        net = self.conv2d(net, <span class="number">1024</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">'conv7_2'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># shortcut增加了一个中间卷积层，先采用64个1*1卷积核进行卷积，然后再进行passthrough处理</span></span><br><span class="line">        <span class="comment"># 这样26*26*512 -&gt; 26*26*64 -&gt; 13*13*256的特征图</span></span><br><span class="line">        shortcut = self.conv2d(shortcut, <span class="number">64</span>, <span class="number">1</span>, <span class="number">0</span>, name=<span class="string">'conv_shortcut'</span>)</span><br><span class="line">        shortcut = self.passthrough(shortcut, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 连接之后，变成13*13*（1024+256）</span></span><br><span class="line">        net = tf.concat([shortcut, net],axis=-<span class="number">1</span>)  <span class="comment"># channel整合到一起，concatenated with the original features，passthrough层与ResNet网络的shortcut类似，以前面更高分辨率的特征图为输入，然后将其连接到后面的低分辨率特征图上，</span></span><br><span class="line">        net = self.conv2d(net, <span class="number">1024</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">'conv8'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># detection layer: 最后用一个1*1卷积去调整channel，该层没有BN层和激活函数，变成: S*S*(B*(5+C))，在这里为：13*13*425</span></span><br><span class="line">        output = self.conv2d(net, filters_num=self.f_num, filters_size=<span class="number">1</span>, batch_normalize=<span class="literal">False</span>, activation=<span class="literal">None</span>,</span><br><span class="line">                        use_bias=<span class="literal">True</span>, name=<span class="string">'conv_dec'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> output,x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#生成anchor  ---&gt;  decode</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">decode</span>(<span class="params">self,net</span>):</span></span><br><span class="line"></span><br><span class="line">        self.anchor_size = tf.constant(self.anchor_size , dtype=tf.float32)</span><br><span class="line">       </span><br><span class="line"></span><br><span class="line">        net = tf.reshape(net, [-<span class="number">1</span>, <span class="number">13</span> * <span class="number">13</span>, self.num_anchors, self.num_class + <span class="number">5</span>]) <span class="comment">#[batch,169,5,85]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 偏移量、置信度、类别</span></span><br><span class="line">        <span class="comment">#中心坐标相对于该cell坐上角的偏移量，sigmoid函数归一化到(0,1)</span></span><br><span class="line">        xy_offset = tf.nn.sigmoid(net[:, :, :, <span class="number">0</span>:<span class="number">2</span>])</span><br><span class="line">        wh_offset = tf.exp(net[:, :, :, <span class="number">2</span>:<span class="number">4</span>])</span><br><span class="line">        obj_probs = tf.nn.sigmoid(net[:, :, :, <span class="number">4</span>])  <span class="comment"># 置信度,这个东西就是相当于v1中的confidence</span></span><br><span class="line">        class_probs = tf.nn.softmax(net[:, :, :, <span class="number">5</span>:])  <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 在feature map对应坐标生成anchors，每个坐标五个</span></span><br><span class="line">        height_index = tf.<span class="built_in">range</span>(self.feature_map_size[<span class="number">0</span>], dtype=tf.float32)</span><br><span class="line">        width_index = tf.<span class="built_in">range</span>(self.feature_map_size[<span class="number">1</span>], dtype=tf.float32)</span><br><span class="line"></span><br><span class="line">        x_cell, y_cell = tf.meshgrid(height_index, width_index)</span><br><span class="line">        x_cell = tf.reshape(x_cell, [<span class="number">1</span>, -<span class="number">1</span>, <span class="number">1</span>])  <span class="comment"># 和上面[H*W,num_anchors,num_class+5]对应</span></span><br><span class="line">        y_cell = tf.reshape(y_cell, [<span class="number">1</span>, -<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># decode</span></span><br><span class="line">        bbox_x = (x_cell + xy_offset[:, :, :, <span class="number">0</span>]) / <span class="number">13</span></span><br><span class="line">        bbox_y = (y_cell + xy_offset[:, :, :, <span class="number">1</span>]) / <span class="number">13</span></span><br><span class="line">        bbox_w = (self.anchor_size[:, <span class="number">0</span>] * wh_offset[:, :, :, <span class="number">0</span>]) / <span class="number">13</span></span><br><span class="line">        bbox_h = (self.anchor_size[:, <span class="number">1</span>] * wh_offset[:, :, :, <span class="number">1</span>]) / <span class="number">13</span></span><br><span class="line"></span><br><span class="line">        bboxes = tf.stack([bbox_x - bbox_w / <span class="number">2</span>, bbox_y - bbox_h / <span class="number">2</span>, bbox_x + bbox_w / <span class="number">2</span>, bbox_y + bbox_h / <span class="number">2</span>],</span><br><span class="line">                          axis=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> bboxes, obj_probs, class_probs</span><br><span class="line"></span><br><span class="line">    <span class="comment">#将边界框超出整张图片(0,0)—(415,415)的部分cut掉</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">bboxes_cut</span>(<span class="params">self,bbox_min_max, bboxes</span>):</span></span><br><span class="line">        bboxes = np.copy(bboxes)</span><br><span class="line">        bboxes = np.transpose(bboxes)</span><br><span class="line">        bbox_min_max = np.transpose(bbox_min_max)</span><br><span class="line">        <span class="comment"># cut the box</span></span><br><span class="line">        bboxes[<span class="number">0</span>] = np.maximum(bboxes[<span class="number">0</span>], bbox_min_max[<span class="number">0</span>])  <span class="comment"># xmin</span></span><br><span class="line">        bboxes[<span class="number">1</span>] = np.maximum(bboxes[<span class="number">1</span>], bbox_min_max[<span class="number">1</span>])  <span class="comment"># ymin</span></span><br><span class="line">        bboxes[<span class="number">2</span>] = np.minimum(bboxes[<span class="number">2</span>], bbox_min_max[<span class="number">2</span>])  <span class="comment"># xmax</span></span><br><span class="line">        bboxes[<span class="number">3</span>] = np.minimum(bboxes[<span class="number">3</span>], bbox_min_max[<span class="number">3</span>])  <span class="comment"># ymax</span></span><br><span class="line">        bboxes = np.transpose(bboxes)</span><br><span class="line">        <span class="keyword">return</span> bboxes</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">bboxes_sort</span>(<span class="params">self,classes, scores, bboxes, top_k=<span class="number">400</span></span>):</span></span><br><span class="line">        index = np.argsort(-scores)</span><br><span class="line">        classes = classes[index][:top_k]</span><br><span class="line">        scores = scores[index][:top_k]</span><br><span class="line">        bboxes = bboxes[index][:top_k]</span><br><span class="line">        <span class="keyword">return</span> classes, scores, bboxes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">bboxes_iou</span>(<span class="params">self,bboxes1, bboxes2</span>):</span></span><br><span class="line">        bboxes1 = np.transpose(bboxes1)</span><br><span class="line">        bboxes2 = np.transpose(bboxes2)</span><br><span class="line"></span><br><span class="line">        int_ymin = np.maximum(bboxes1[<span class="number">0</span>], bboxes2[<span class="number">0</span>])</span><br><span class="line">        int_xmin = np.maximum(bboxes1[<span class="number">1</span>], bboxes2[<span class="number">1</span>])</span><br><span class="line">        int_ymax = np.minimum(bboxes1[<span class="number">2</span>], bboxes2[<span class="number">2</span>])</span><br><span class="line">        int_xmax = np.minimum(bboxes1[<span class="number">3</span>], bboxes2[<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">        int_h = np.maximum(int_ymax - int_ymin, <span class="number">0.</span>)</span><br><span class="line">        int_w = np.maximum(int_xmax - int_xmin, <span class="number">0.</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算IOU</span></span><br><span class="line">        int_vol = int_h * int_w  <span class="comment"># 交集面积</span></span><br><span class="line">        vol1 = (bboxes1[<span class="number">2</span>] - bboxes1[<span class="number">0</span>]) * (bboxes1[<span class="number">3</span>] - bboxes1[<span class="number">1</span>])  <span class="comment"># bboxes1面积</span></span><br><span class="line">        vol2 = (bboxes2[<span class="number">2</span>] - bboxes2[<span class="number">0</span>]) * (bboxes2[<span class="number">3</span>] - bboxes2[<span class="number">1</span>])  <span class="comment"># bboxes2面积</span></span><br><span class="line">        IOU = int_vol / (vol1 + vol2 - int_vol)  <span class="comment"># IOU=交集/并集</span></span><br><span class="line">        <span class="keyword">return</span> IOU</span><br><span class="line"></span><br><span class="line">    <span class="comment"># NMS，或者用tf.image.non_max_suppression</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">bboxes_nms</span>(<span class="params">self,classes, scores, bboxes, nms_threshold=<span class="number">0.2</span></span>):</span></span><br><span class="line">        keep_bboxes = np.ones(scores.shape, dtype=np.<span class="built_in">bool</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(scores.size - <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> keep_bboxes[i]:</span><br><span class="line">                overlap = self.bboxes_iou(bboxes[i], bboxes[(i + <span class="number">1</span>):])</span><br><span class="line">                keep_overlap = np.logical_or(overlap &lt; nms_threshold,</span><br><span class="line">                                             classes[(i + <span class="number">1</span>):] != classes[i])  <span class="comment"># IOU没有超过0.5或者是不同的类则保存下来</span></span><br><span class="line">                keep_bboxes[(i + <span class="number">1</span>):] = np.logical_and(keep_bboxes[(i + <span class="number">1</span>):], keep_overlap)</span><br><span class="line"></span><br><span class="line">        idxes = np.where(keep_bboxes)</span><br><span class="line">        <span class="keyword">return</span> classes[idxes], scores[idxes], bboxes[idxes]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">postprocess</span>(<span class="params">self,bboxes, obj_probs, class_probs, image_shape=(<span class="params"><span class="number">416</span>, <span class="number">416</span></span>), threshold=<span class="number">0.5</span></span>):</span></span><br><span class="line"></span><br><span class="line">        bboxes = np.reshape(bboxes, [-<span class="number">1</span>, <span class="number">4</span>])</span><br><span class="line">        <span class="comment"># 将所有box还原成图片中真实的位置</span></span><br><span class="line">        bboxes[:, <span class="number">0</span>:<span class="number">1</span>] *= <span class="built_in">float</span>(image_shape[<span class="number">1</span>])</span><br><span class="line">        bboxes[:, <span class="number">1</span>:<span class="number">2</span>] *= <span class="built_in">float</span>(image_shape[<span class="number">0</span>])</span><br><span class="line">        bboxes[:, <span class="number">2</span>:<span class="number">3</span>] *= <span class="built_in">float</span>(image_shape[<span class="number">1</span>])</span><br><span class="line">        bboxes[:, <span class="number">3</span>:<span class="number">4</span>] *= <span class="built_in">float</span>(image_shape[<span class="number">0</span>])</span><br><span class="line">        bboxes = bboxes.astype(np.int32)  <span class="comment"># 转int</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        bbox_min_max = [<span class="number">0</span>, <span class="number">0</span>, image_shape[<span class="number">1</span>] - <span class="number">1</span>, image_shape[<span class="number">0</span>] - <span class="number">1</span>]</span><br><span class="line">        bboxes = self.bboxes_cut(bbox_min_max, bboxes)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        obj_probs = np.reshape(obj_probs, [-<span class="number">1</span>])  <span class="comment"># 13*13*5</span></span><br><span class="line">        class_probs = np.reshape(class_probs, [<span class="built_in">len</span>(obj_probs), -<span class="number">1</span>])  <span class="comment"># (13*13*5,80)</span></span><br><span class="line">        class_max_index = np.argmax(class_probs, axis=<span class="number">1</span>)  <span class="comment"># max类别概率对应的index</span></span><br><span class="line">        class_probs = class_probs[np.arange(<span class="built_in">len</span>(obj_probs)), class_max_index]</span><br><span class="line">        scores = obj_probs * class_probs  <span class="comment"># 置信度*max类别概率=类别置信度scores</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 类别置信度scores&gt;threshold的边界框bboxes留下</span></span><br><span class="line">        keep_index = scores &gt; threshold</span><br><span class="line">        class_max_index = class_max_index[keep_index]</span><br><span class="line">        scores = scores[keep_index]</span><br><span class="line">        bboxes = bboxes[keep_index]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># (2)排序top_k(默认为400)</span></span><br><span class="line">        class_max_index, scores, bboxes = self.bboxes_sort(class_max_index, scores, bboxes)</span><br><span class="line">        <span class="comment"># (3)NMS</span></span><br><span class="line">        class_max_index, scores, bboxes = self.bboxes_nms(class_max_index, scores, bboxes)</span><br><span class="line">        <span class="keyword">return</span> bboxes, scores, class_max_index</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">preprocess_image</span>(<span class="params">self,image, image_size=(<span class="params"><span class="number">416</span>, <span class="number">416</span></span>)</span>):</span></span><br><span class="line"></span><br><span class="line">        image_cp = np.copy(image).astype(np.float32)</span><br><span class="line">        image_rgb = cv2.cvtColor(image_cp, cv2.COLOR_BGR2RGB)</span><br><span class="line">        image_resized = cv2.resize(image_rgb, image_size)</span><br><span class="line">        image_normalized = image_resized.astype(np.float32) / <span class="number">225.0</span></span><br><span class="line">        image_expanded = np.expand_dims(image_normalized, axis=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> image_expanded</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    train part</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">preprocess_true_boxes</span>(<span class="params">self,true_box,anchors,img_size = (<span class="params"><span class="number">416</span>,<span class="number">416</span></span>)</span>):</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        :param true_box:实际框的位置和类别,2D TENSOR:(batch,5)</span></span><br><span class="line"><span class="string">        :param anchors:anchors : 实际anchor boxes 的值，论文中使用了五个。[w,h]，都是相对于gird cell 的比值。</span></span><br><span class="line"><span class="string">                2d</span></span><br><span class="line"><span class="string">            第二个维度：[w,h]，w,h,都是相对于gird cell长宽的比值。</span></span><br><span class="line"><span class="string">           [1.08, 1.19], [3.42, 4.41], [6.63, 11.38], [9.42, 5.11], [16.62, 10.52]</span></span><br><span class="line"><span class="string">        :param img_size:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">           -detectors_mask: 取值是0或者1，这里的shape是[13,13,5,1]</span></span><br><span class="line"><span class="string">                第四个维度：0/1。1的就是用于预测改true boxes 的 anchor boxes</span></span><br><span class="line"><span class="string">           -matching_true_boxes:这里的shape是[13,13,5,5]。</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        w,h = img_size</span><br><span class="line">        feature_w = w // <span class="number">32</span></span><br><span class="line">        feature_h = h // <span class="number">32</span></span><br><span class="line"></span><br><span class="line">        num_box_params = true_box.shape[<span class="number">1</span>]</span><br><span class="line">        detectors_mask = np.zeros((feature_h,feature_w,self.num_anchors,<span class="number">1</span>),dtype=np.float32)</span><br><span class="line">        matching_true_boxes = np.zeros((feature_h,feature_w,self.num_anchors,num_box_params),dtype=np.float32)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> true_box:</span><br><span class="line">            <span class="comment">#提取类别信息，属于哪类</span></span><br><span class="line">            box_class = i[<span class="number">4</span>:<span class="number">5</span>]</span><br><span class="line">            <span class="comment">#换算成相对于gird cell的值</span></span><br><span class="line">            box = i[<span class="number">0</span>:<span class="number">4</span>] * np.array([feature_w, feature_h, feature_w, feature_h])</span><br><span class="line">            k = np.floor(box[<span class="number">1</span>]).astype(<span class="string">'int'</span>) <span class="comment">#y方向上属于第几个gird cell</span></span><br><span class="line">            j = np.floor(box[<span class="number">0</span>]).astype(<span class="string">'int'</span>) <span class="comment">#x方向上属于第几个gird cell</span></span><br><span class="line">            best_iou = <span class="number">0</span></span><br><span class="line">            best_anchor = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">#计算anchor boxes 和 true boxes的iou ，一个true box一个best anchor</span></span><br><span class="line">            <span class="keyword">for</span> m,anchor <span class="keyword">in</span> <span class="built_in">enumerate</span>(anchors):</span><br><span class="line">                box_maxes = box[<span class="number">2</span>:<span class="number">4</span>] / <span class="number">2.</span></span><br><span class="line">                box_mins = -box_maxes</span><br><span class="line">                anchor_maxes = (anchor / <span class="number">2.</span>)</span><br><span class="line">                anchor_mins = -anchor_maxes</span><br><span class="line"></span><br><span class="line">                intersect_mins = np.maximum(box_mins, anchor_mins)</span><br><span class="line">                intersect_maxes = np.minimum(box_maxes, anchor_maxes)</span><br><span class="line">                intersect_wh = np.maximum(intersect_maxes - intersect_mins, <span class="number">0.</span>)</span><br><span class="line">                intersect_area = intersect_wh[<span class="number">0</span>] * intersect_wh[<span class="number">1</span>]</span><br><span class="line">                box_area = box[<span class="number">2</span>] * box[<span class="number">3</span>]</span><br><span class="line">                anchor_area = anchor[<span class="number">0</span>] * anchor[<span class="number">1</span>]</span><br><span class="line">                iou = intersect_area / (box_area + anchor_area - intersect_area)</span><br><span class="line">                <span class="keyword">if</span> iou &gt; best_iou:</span><br><span class="line">                    best_iou = iou</span><br><span class="line">                    best_anchor = m</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> best_iou &gt; <span class="number">0</span>:</span><br><span class="line">                detectors_mask[k, j, best_anchor] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                adjusted_box = np.array(  <span class="comment">#找到最佳预测anchor boxes</span></span><br><span class="line">                    [</span><br><span class="line">                        box[<span class="number">0</span>] - j, box[<span class="number">1</span>] - k, <span class="comment">#'x,y都是相对于gird cell的位置，左上角[0,0]，右下角[1,1]'</span></span><br><span class="line">                        np.log(box[<span class="number">2</span>] / anchors[best_anchor][<span class="number">0</span>]), <span class="comment">#'对应实际框w,h和anchor boxes w,h的比值取log函数'</span></span><br><span class="line">                        np.log(box[<span class="number">3</span>] / anchors[best_anchor][<span class="number">1</span>]), box_class <span class="comment">#'class实际框的物体是属于第几类'</span></span><br><span class="line">                    ],</span><br><span class="line">                    dtype=np.float32)</span><br><span class="line">                matching_true_boxes[k, j, best_anchor] = adjusted_box</span><br><span class="line">            <span class="keyword">return</span> detectors_mask, matching_true_boxes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">yolo_head</span>(<span class="params">self,feature_map, anchors, num_classes</span>):</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        这个函数是输入yolo的输出层的特征，转化成相对于gird cell坐标的x,y，相对于gird cell长宽的w,h，</span></span><br><span class="line"><span class="string">        pred_confidence是判断否存在物体的概率，pred_class_prob是sofrmax后各个类别分别的概率</span></span><br><span class="line"><span class="string">        :param feats:  网络最后一层输出 [none,13,13,125]/[none,13,13,425]</span></span><br><span class="line"><span class="string">        :param anchors:[5,n]</span></span><br><span class="line"><span class="string">        :param num_classes:类别数</span></span><br><span class="line"><span class="string">        :return:x,y,w,h在loss function中计算iou，然后计算iou损失。</span></span><br><span class="line"><span class="string">                然后和pred_confidence计算confidence_loss，pred_class_prob用于计算classification_loss。</span></span><br><span class="line"><span class="string">                box_xy : 每张图片的每个gird cell中的每个pred_boxes中心点x,y相对于其所在gird cell的坐标值，左上顶点为[0,0],右下顶点为[1,1]。</span></span><br><span class="line"><span class="string">                shape:[-1,13,13,5,2].</span></span><br><span class="line"><span class="string">                box_wh : 每张图片的每个gird cell中的每个pred_boxes的w,h都是相对于gird cell的比值</span></span><br><span class="line"><span class="string">                shape:[-1,13,13,5,2].</span></span><br><span class="line"><span class="string">                box_confidence : 每张图片的每个gird cell中的每个pred_boxes的，判断是否存在可检测物体的概率。</span></span><br><span class="line"><span class="string">                shape:[-1,13,13,5,1]。各维度信息同上。</span></span><br><span class="line"><span class="string">                box_class_pred : 每张图片的每个gird cell中的每个pred_boxes所框起来的各个类别分别的概率(经过了softmax)。</span></span><br><span class="line"><span class="string">                shape:[-1,13,13,5,20/80]</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">        anchors = tf.reshape(tf.constant(anchors,dtype=tf.float32),[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,self.num_anchors,<span class="number">2</span>])</span><br><span class="line">        num_gird_cell = tf.shape(feature_map)[<span class="number">1</span>:<span class="number">3</span>] <span class="comment">#[13,13]</span></span><br><span class="line">        conv_height_index = K.arange(<span class="number">0</span>,stop=num_gird_cell[<span class="number">0</span>])</span><br><span class="line">        conv_width_index = K.arange(<span class="number">0</span>,stop=num_gird_cell[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        conv_height_index = tf.tile(conv_height_index, [num_gird_cell[<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line">        conv_width_index = tf.tile(</span><br><span class="line">            tf.expand_dims(conv_width_index, <span class="number">0</span>), [num_gird_cell[<span class="number">0</span>], <span class="number">1</span>])</span><br><span class="line">        conv_width_index = K.flatten(K.transpose(conv_width_index))</span><br><span class="line">        conv_index = K.transpose(K.stack([conv_height_index,conv_width_index]))</span><br><span class="line">        conv_index = K.reshape(conv_index,[<span class="number">1</span>,num_gird_cell[<span class="number">0</span>],num_gird_cell[<span class="number">1</span>],<span class="number">1</span>,<span class="number">2</span>])<span class="comment">#[1，13，13，1，2]</span></span><br><span class="line">        conv_index = K.cast(conv_index,K.dtype(feature_map))</span><br><span class="line">        <span class="comment">#[[0,0][0,1]....[0,12],[1,0]...]</span></span><br><span class="line">        feature_map = K.reshape(feature_map,[-<span class="number">1</span>,num_gird_cell[<span class="number">0</span>],num_gird_cell[<span class="number">1</span>],self.num_anchors,self.num_class + <span class="number">5</span>])</span><br><span class="line">        num_gird_cell = K.cast(K.reshape(num_gird_cell,[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>]),K.dtype(feature_map))</span><br><span class="line"></span><br><span class="line">        box_xy = K.sigmoid(feature_map[...,:<span class="number">2</span>])</span><br><span class="line">        box_wh = K.exp(feature_map[...,<span class="number">2</span>:<span class="number">4</span>])</span><br><span class="line">        confidence = K.sigmoid(feature_map[...,<span class="number">4</span>:<span class="number">5</span>])</span><br><span class="line">        cls_prob = K.softmax(feature_map[...,<span class="number">5</span>:])</span><br><span class="line"></span><br><span class="line">        xy = (box_xy + conv_index) / num_gird_cell</span><br><span class="line">        wh = box_wh * anchors / num_gird_cell</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> xy,wh,confidence,cls_prob</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">loss</span>(<span class="params">self,</span></span></span><br><span class="line"><span class="function"><span class="params">             net,</span></span></span><br><span class="line"><span class="function"><span class="params">             true_boxes,</span></span></span><br><span class="line"><span class="function"><span class="params">             detectors_mask,</span></span></span><br><span class="line"><span class="function"><span class="params">             matching_true_boxes,</span></span></span><br><span class="line"><span class="function"><span class="params">             anchors,</span></span></span><br><span class="line"><span class="function"><span class="params">             num_classes</span>):</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        IOU损失，分类损失，坐标损失</span></span><br><span class="line"><span class="string">        confidence_loss：</span></span><br><span class="line"><span class="string">                共有845个anchor_boxes，与true_boxes匹配的用于预测pred_boxes，</span></span><br><span class="line"><span class="string">                未与true_boxes匹配的anchor_boxes用于预测background。在未与true_boxes匹配的anchor_boxes中，</span></span><br><span class="line"><span class="string">                与true_boxes的IOU小于0.6的被标记为background，这部分预测正确，未造成损失。</span></span><br><span class="line"><span class="string">                但未与true_boxes匹配的anchor_boxes中，若与true_boxes的IOU大于0.6的我们需要计算其损失，</span></span><br><span class="line"><span class="string">                因为它未能准确预测background，与true_boxes重合度过高，就是no_objects_loss。</span></span><br><span class="line"><span class="string">                而objects_loss则是与true_boxes匹配的anchor_boxes的预测误差。与YOLOv1不同的是修正系数的改变，</span></span><br><span class="line"><span class="string">                YOLOv1中no_objects_loss和objects_loss分别是0.5和1，而YOLOv2中则是1和5。</span></span><br><span class="line"><span class="string">        classification_loss:</span></span><br><span class="line"><span class="string">                经过softmax（）后，20维向量（数据集中分类种类为20种）的均方误差。</span></span><br><span class="line"><span class="string">        coordinates_loss：</span></span><br><span class="line"><span class="string">                计算x,y的误差由相对于整个图像（416x416）的offset坐标误差的均方改变为相对于gird cell的offset（这个offset是取sigmoid函数得到的处于（0,1）的值）坐标误差的均方。</span></span><br><span class="line"><span class="string">                也将修正系数由5改为了1 。计算w,h的误差由w,h平方根的差的均方误差变为了，</span></span><br><span class="line"><span class="string">                w,h与对true_boxes匹配的anchor_boxes的长宽的比值取log函数，</span></span><br><span class="line"><span class="string">                和YOLOv1的想法一样，对于相等的误差值，降低对大物体误差的惩罚，加大对小物体误差的惩罚。同时也将修正系数由5改为了1。</span></span><br><span class="line"><span class="string">        :param net:[batch_size,13,13,125],网络最后一层输出</span></span><br><span class="line"><span class="string">        :param true_boxes:实际框的位置和类别 [batch,5]</span></span><br><span class="line"><span class="string">        :param detectors_mask:取值是0或者1，[ batch_size，13,13,5,1]</span></span><br><span class="line"><span class="string">                1的就是用于预测改true boxes 的 anchor boxes</span></span><br><span class="line"><span class="string">        :param matching_true_boxes:[-1,13,13,5,5]</span></span><br><span class="line"><span class="string">        :param anchors:</span></span><br><span class="line"><span class="string">        :param num_classes:20</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line"></span><br><span class="line">        xy, wh, confidence, cls_prob = self.yolo_head(net,anchors,num_classes)</span><br><span class="line">        shape = tf.shape(net)</span><br><span class="line">        feature_map = tf.reshape(net,[-<span class="number">1</span>,shape[<span class="number">1</span>],shape[<span class="number">2</span>],self.num_anchors,num_classes + <span class="number">5</span>])</span><br><span class="line">        <span class="comment">#用于和matching_true_boxes计算坐标损失</span></span><br><span class="line">        pred_box = tf.concat([K.sigmoid(feature_map[...,<span class="number">0</span>:<span class="number">2</span>]),feature_map[...,<span class="number">2</span>:<span class="number">4</span>]],axis=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        pred_xy = tf.to_float(tf.expand_dims(xy,<span class="number">4</span>))<span class="comment">#[-1,13,13,5,2]--&gt;[-1,13,13,5,1,2]</span></span><br><span class="line">        pred_wh = tf.to_float(tf.expand_dims(wh,<span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">        pred_min = tf.to_float(pred_xy - pred_wh / <span class="number">2.0</span>)</span><br><span class="line">        pred_max = tf.to_float(pred_xy + pred_wh / <span class="number">2.0</span>)</span><br><span class="line"></span><br><span class="line">        true_box_shape = K.shape(true_boxes)</span><br><span class="line">        print(true_box_shape)</span><br><span class="line">        true_boxes = K.reshape(true_boxes,[-<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,true_box_shape[<span class="number">1</span>], <span class="number">5</span>])</span><br><span class="line">        <span class="comment">#[-1,1,1,1,-1,5],batch, conv_height, conv_width, num_anchors, num_true_boxes, box_params'</span></span><br><span class="line"></span><br><span class="line">        true_xy = tf.to_float(true_boxes[...,<span class="number">0</span>:<span class="number">2</span>])</span><br><span class="line">        true_wh = tf.to_float(true_boxes[...,<span class="number">2</span>:<span class="number">4</span>])</span><br><span class="line">        true_min = tf.to_float(true_xy - true_wh / <span class="number">2.0</span>)</span><br><span class="line">        true_max = tf.to_float(true_xy + true_wh / <span class="number">2.0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#计算所以abox和tbox的iou</span></span><br><span class="line">        intersect_mins = tf.maximum(pred_min, true_min)</span><br><span class="line">        intersect_maxes = tf.minimum(pred_max, true_max)</span><br><span class="line">        intersect_wh = tf.maximum(intersect_maxes - intersect_mins, <span class="number">0.</span>)</span><br><span class="line">        intersect_areas = tf.to_float(intersect_wh[..., <span class="number">0</span>] * intersect_wh[..., <span class="number">1</span>])</span><br><span class="line">        pred_areas = pred_wh[..., <span class="number">0</span>] * pred_wh[..., <span class="number">1</span>]</span><br><span class="line">        true_areas = true_wh[..., <span class="number">0</span>] * true_wh[..., <span class="number">1</span>]</span><br><span class="line">        union_areas = pred_areas + true_areas - intersect_areas</span><br><span class="line">        iou_scores = intersect_areas / union_areas</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">#可能会有多个tbox落在同一个cell ，只去iou最大的</span></span><br><span class="line">        <span class="comment"># tf.argmax(iou_scores,4)</span></span><br><span class="line">        best_ious = K.<span class="built_in">max</span>(iou_scores, axis=<span class="number">4</span>)</span><br><span class="line">        best_ious = tf.expand_dims(best_ious,axis=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#选出IOU大于0.6的，若IOU小于0.6的被标记为background，</span></span><br><span class="line">        obj_dec = tf.cast(best_ious &gt; <span class="number">0.6</span>,dtype=K.dtype(best_ious))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">#IOU loss</span></span><br><span class="line">        no_obj_w = (self.no_object_scale * obj_dec * detectors_mask) <span class="comment">#</span></span><br><span class="line">        no_obj_loss = no_obj_w * tf.square(-confidence)</span><br><span class="line">        obj_loss = self.object_scale * detectors_mask * tf.square(<span class="number">1</span> - confidence)</span><br><span class="line">        confidence_loss = no_obj_loss + obj_loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">#class loss</span></span><br><span class="line">        match_cls = tf.cast(matching_true_boxes[...,<span class="number">4</span>],dtype=tf.int32)</span><br><span class="line">        match_cls = tf.one_hot(match_cls,num_classes)</span><br><span class="line"></span><br><span class="line">        class_loss = (self.class_scale * detectors_mask * tf.square(match_cls - cls_prob))</span><br><span class="line"></span><br><span class="line">        <span class="comment">#坐标loss</span></span><br><span class="line">        match_box = matching_true_boxes[...,<span class="number">0</span>:<span class="number">4</span>]</span><br><span class="line">        coord_loss = self.coordinates_scale * detectors_mask * tf.square(match_box - pred_box)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        confidence_loss_sum = K.<span class="built_in">sum</span>(confidence_loss)</span><br><span class="line">        class_loss_sum = K.<span class="built_in">sum</span>(class_loss)</span><br><span class="line">        coord_loss_sum = K.<span class="built_in">sum</span>(coord_loss)</span><br><span class="line">        all_loss = <span class="number">0.5</span> * (confidence_loss_sum + class_loss_sum + coord_loss_sum)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> all_loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">draw_detection</span>(<span class="params">self,j,im, bboxes, scores, cls_inds, labels</span>):</span></span><br><span class="line">        f = <span class="built_in">open</span>(<span class="string">'./output/final.txt'</span>, <span class="string">"a"</span>)</span><br><span class="line"></span><br><span class="line">        imgcv = np.copy(im)</span><br><span class="line">        h, w, _ = imgcv.shape</span><br><span class="line">        <span class="keyword">for</span> i, box <span class="keyword">in</span> <span class="built_in">enumerate</span>(bboxes):</span><br><span class="line">            cls_indx = cls_inds[i]</span><br><span class="line">            thick = <span class="built_in">int</span>((h + w) / <span class="number">1000</span>)</span><br><span class="line">            cv2.rectangle(imgcv, (box[<span class="number">0</span>], box[<span class="number">1</span>]), (box[<span class="number">2</span>], box[<span class="number">3</span>]), (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), thick)</span><br><span class="line">            f.write(<span class="string">'[x, y, w, h]=['</span>+<span class="built_in">str</span>(box[<span class="number">0</span>])+<span class="string">','</span>+<span class="built_in">str</span>(box[<span class="number">1</span>])+<span class="string">','</span>+<span class="built_in">str</span>(box[<span class="number">2</span>])+<span class="string">','</span>+<span class="built_in">str</span>(box[<span class="number">3</span>])+<span class="string">']\n'</span>)</span><br><span class="line">            <span class="comment">#print("[x, y, w, h]=[%d, %d, %d, %d]" % (box[0], box[1], box[2], box[3]))</span></span><br><span class="line">            mess = <span class="string">'%s: %.3f'</span> % (labels[cls_indx], scores[i])</span><br><span class="line">            text_loc = (box[<span class="number">0</span>], box[<span class="number">1</span>] - <span class="number">10</span>)</span><br><span class="line">            cv2.putText(imgcv, mess, text_loc, cv2.FONT_HERSHEY_SIMPLEX, <span class="number">1e-3</span> * h, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), thick)</span><br><span class="line">        <span class="comment"># return imgcv</span></span><br><span class="line">        <span class="comment">#将处理后的每帧图片存到本地</span></span><br><span class="line">        address = <span class="string">'./output/'</span> + <span class="built_in">str</span>(j)+ <span class="string">'.jpg'</span></span><br><span class="line">        cv2.imwrite(address,imgcv)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#将位置信息写入文件</span></span><br><span class="line">        f.write(<span class="string">'\n'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#v1 - v2 , v2 - v3</span></span><br><span class="line"><span class="comment"># 1、加入BN层 批次归一化   input --&gt; 均值为0方差为1正太分布</span></span><br><span class="line"><span class="comment">#    ---》白化  --&gt; 对‘input 变换到 均值0单位方差内的分布</span></span><br><span class="line"><span class="comment"># #使用：input * w --&gt;bn</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    network = yolov2(<span class="string">'coco'</span>)</span><br><span class="line">  </span><br><span class="line">    net,x = network.darknet()</span><br><span class="line">    _bboxes, _obj_probs, _class_probs = network.decode(net)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    saver = tf.train.Saver()</span><br><span class="line">    ckpt_path = <span class="string">'./model/v2/yolo2_coco.ckpt'</span></span><br><span class="line">    sess = tf.Session()</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    saver.restore(sess,ckpt_path)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 读取视频文件</span></span><br><span class="line">    cap = cv2.VideoCapture(<span class="string">"./test/3.mp4"</span>)</span><br><span class="line">    <span class="comment"># 通过摄像头的方式</span></span><br><span class="line">    <span class="comment"># videoCapture=cv2.VideoCapture(1)</span></span><br><span class="line">    <span class="comment">#读帧</span></span><br><span class="line">    j=<span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> cap.isOpened():</span><br><span class="line">        ret, frame = cap.read()</span><br><span class="line">        img_r = network.preprocess_image(frame)</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        bboxes, obj_probs, class_probs = sess.run([_bboxes, _obj_probs, _class_probs],feed_dict={x:img_r})</span><br><span class="line">        bboxes, scores, class_max_index = network.postprocess(bboxes, obj_probs, class_probs)</span><br><span class="line">        <span class="comment">#print(scores, box_classes)</span></span><br><span class="line">        img_detection = network.draw_detection(j, cv2.resize(frame,(<span class="number">416</span>,<span class="number">416</span>)), bboxes, scores, class_max_index, network.CLASS)</span><br><span class="line">        j=j+<span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string"> yi、</span></span><br><span class="line"><span class="string">    第一大层  :conv maxpoiling</span></span><br><span class="line"><span class="string">    第2大层:3个卷积，maxpool</span></span><br><span class="line"><span class="string">    3:3个卷积，maxpool</span></span><br><span class="line"><span class="string">    4：3卷积，maxpool</span></span><br><span class="line"><span class="string">    5:5卷积，maxpool   -----------</span></span><br><span class="line"><span class="string">    6:5卷积                       | + add</span></span><br><span class="line"><span class="string">    7三个卷积---------------------</span></span><br><span class="line"><span class="string">    conv  </span></span><br><span class="line"><span class="string"> er:</span></span><br><span class="line"><span class="string">    ahchors生成和decode</span></span><br><span class="line"><span class="string"> san:</span></span><br><span class="line"><span class="string">    裁剪、选出前TOP_K，NMS </span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure>
<p> </p>
<p>
<p>视频还是上一篇文章中的测试视频。限于上传困难，在这里依然只展示单帧的测试。对比图如下（上面的是v1，下面的是v2）</p>
<p><img src= "/img/loading.gif" data-lazy-src="https://s1.ax1x.com/2020/07/11/U1Z639.jpg" alt="图12：YOLO V1视频检测结果（单帧）" style="zoom: 80%;"></p>
<p> </p>
<p><img src= "/img/loading.gif" data-lazy-src="https://s1.ax1x.com/2020/07/13/UGOObj.jpg" alt="图13：YOLO V2视频检测结果（单帧）" style="zoom:80%;"></p>
<p>从对比图可以看出，与V1版本第30帧的检测结果相比，V2可以检测到更多的物体，并且准确率更高。</p>
<p> </p>
<div class="note success flat"><p>原视频 。见：<a target="_blank" rel="noopener" href="https://wwa.lanzous.com/ivijLej0vmb">传送门</a></p>
<p>处理后的视频。见：<a target="_blank" rel="noopener" href="https://wwa.lanzous.com/inuQfek7lhe">传送门</a></p>
<p>另外，检测到的bbox位置也特别多，无法截图展示，我就把信息全部写入到了txt文本中。见：<a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/han-suyu/cdn_others/final_v2.txt">传送门</a>)</p>
</div>
<p> </p>
<p> </p>
<p> </p>
<blockquote>
<p><strong>参考</strong>： https://pjreddie.com/darknet/yolo/ https://xmfbit.github.io/2017/02/04/yolo-paper/ https://www.cnblogs.com/AntonioSu/p/12164255.html https://zhuanlan.zhihu.com/p/25052190 http://lanbing510.info/2017/09/04/YOLOV2.html https://segmentfault.com/a/1190000016842636#comment-area https://www.youtube.com/watch?v=VOC3huqHrss https://www.cnblogs.com/wangguchangqing/p/10480995.html https://zhuanlan.zhihu.com/p/74540100</p>
</blockquote>
</p></p></p></p><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script></article><div class="tag_share"><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/han-suyu/cover/22.png" data-sites="wechat,weibo,qq,facebook,twitter"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/07/3774741536.html"><img class="prev-cover" data-lazy-src="https://cdn.jsdelivr.net/gh/han-suyu/cover/24.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">YOLO v1学习总结</div></div></a></div><div class="next-post pull-right"><a href="/2020/07/2746093957.html"><img class="next-cover" data-lazy-src="https://cdn.jsdelivr.net/gh/han-suyu/cover/26.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">解决安装hexo-renderer-sass失败的问题</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" data-lazy-src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/wechat.jpg'" alt="avatar"/><div class="author-info__name">Seven</div><div class="author-info__description">谦虚受益，满盈招损</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">179</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">38</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">26</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/han-suyu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="http://wpa.qq.com/msgrd?v=3&amp;uin=1121687782&amp;site=qq&amp;menu=yes" target="_blank" title="QQ"><i class="iconfont icon-QQ"></i></a><a class="social-icon" href="https://cdn.jsdelivr.net/gh/han-suyu/cdn/WeChat.jpg" target="_blank" title="WeChat"><i class="iconfont icon-wechat"></i></a><a class="social-icon" href="mailto:han-suyu@foxmail.com" target="_blank" title="Email"><i class="iconfont icon-EMAILMARKETING"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2"><span class="toc-text">写在前面</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80better"><span class="toc-text">一、Better</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%95%E5%85%A5bn%E5%B1%82batch-normalization"><span class="toc-text">1.1 引入BN层（Batch Normalization）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%AB%98%E5%88%86%E8%BE%A8%E7%8E%87%E5%88%86%E7%B1%BB%E5%99%A8high-resolution-classifier"><span class="toc-text">1.2 高分辨率分类器（High Resolution Classifier）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%95%E5%85%A5%E5%85%88%E9%AA%8C%E6%A1%86anchor-box"><span class="toc-text">1.3 引入先验框（Anchor Box）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%95%E5%85%A5%E8%81%9A%E7%B1%BB%E6%8F%90%E5%8F%96%E5%85%88%E9%AA%8C%E6%A1%86%E5%B0%BA%E5%BA%A6dimension-cluster"><span class="toc-text">1.4 引入聚类提取先验框尺度（Dimension Cluster）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%B4%E6%8E%A5%E4%BD%8D%E7%BD%AE%E9%A2%84%E6%B5%8Bdirect-location-prediction"><span class="toc-text">1.5 直接位置预测（Direct Location Prediction）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%86%E7%B2%92%E5%BA%A6%E7%89%B9%E5%BE%81fine-gained-features"><span class="toc-text">1.6 细粒度特征（Fine-Gained Features）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E5%B0%BA%E5%BA%A6%E8%AE%AD%E7%BB%83multi-scale-training"><span class="toc-text">1.7 多尺度训练（Multi-Scale Training）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93"><span class="toc-text">小结</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8Cfaster"><span class="toc-text">二、Faster</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#darknet-19"><span class="toc-text">2.1 Darknet-19</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E8%AE%AD%E7%BB%83training-for-classi%EF%AC%81cation"><span class="toc-text">2.2 分类任务训练（Training For Classiﬁcation）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A3%80%E6%B5%8B%E4%BB%BB%E5%8A%A1%E8%AE%AD%E7%BB%83training-for-detection"><span class="toc-text">2.3 检测任务训练（Training For Detection）</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89stronger"><span class="toc-text">三、Stronger</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#joint-classification-and-detection%E8%81%94%E5%90%88%E5%88%86%E7%B1%BB%E5%92%8C%E6%A3%80%E6%B5%8B"><span class="toc-text">3.1 Joint Classification And Detection（联合分类和检测）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#dataset-combination-with-wordtree"><span class="toc-text">3.2 Dataset combination with WordTree</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%9B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-text">四、代码实现</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%9B%BE%E7%89%87%E7%9A%84%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B"><span class="toc-text">4.1 基于图片的目标检测</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B5%8B%E8%AF%951"><span class="toc-text">测试1：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B5%8B%E8%AF%952"><span class="toc-text">测试2：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B5%8B%E8%AF%953"><span class="toc-text">测试3：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E8%A7%86%E9%A2%91%E7%9A%84%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B"><span class="toc-text">4.2 基于视频的目标检测</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2021 By Seven</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    loader: {
      source: {
        '[tex]/amsCd': '[tex]/amscd'
      }
    },
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        addClass: [200,() => {
          document.querySelectorAll('mjx-container:not([display=\'true\']').forEach( node => {
            const target = node.parentNode
            if (!target.classList.contains('has-jax')) {
              target.classList.add('mathjax-overflow')
            }
          })
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'twikoo-comment-6ghgiokk80ee2970',
      region: 'ap-shanghai'
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'twikoo-comment-6ghgiokk80ee2970',
      region: 'ap-shanghai',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/gh/metowolf/MetingJS@1.2/dist/Meting.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>