<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>卷积：如何成为一个很厉害的神经网络 | 明天又是周六了</title><meta name="robots" content="noindex"><meta name="keywords" content="学习总结"><meta name="author" content="Seven"><meta name="copyright" content="Seven"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="什么是卷积神经网络？又为什么很重要？ 卷积神经网络(Convolutional Neural Networks, ConvNets or CNNs)是一种在图像识别与分类领域被证明特别有效的神经网络。卷积网络已经成功地识别人脸、物体、交通标志，应用在机器人和无人车等载具。  图1  在上面的图1当中，卷积网络能够识别场景而系统可以自动推荐相关标签（如一个足球运动员正在踢球）。图2则展示了">
<meta property="og:type" content="article">
<meta property="og:title" content="卷积：如何成为一个很厉害的神经网络">
<meta property="og:url" content="https://hansy.tech/2020/06/3272311197.html">
<meta property="og:site_name" content="明天又是周六了">
<meta property="og:description" content="什么是卷积神经网络？又为什么很重要？ 卷积神经网络(Convolutional Neural Networks, ConvNets or CNNs)是一种在图像识别与分类领域被证明特别有效的神经网络。卷积网络已经成功地识别人脸、物体、交通标志，应用在机器人和无人车等载具。  图1  在上面的图1当中，卷积网络能够识别场景而系统可以自动推荐相关标签（如一个足球运动员正在踢球）。图2则展示了">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/han-suyu/cover/21.jpg">
<meta property="article:published_time" content="2020-06-24T11:31:15.000Z">
<meta property="article:modified_time" content="2020-06-24T11:31:15.000Z">
<meta property="article:author" content="Seven">
<meta property="article:tag" content="学习总结">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/han-suyu/cover/21.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://hansy.tech/2020/06/3272311197"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="u9AaJlYHNmU4dpUtiWPMA9_vQRU4zjcERKUymU8aEao"/><meta name="baidu-site-verification" content="m7BzC4y6nU"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: true
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: true,
  isanchor: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2020-06-24 19:31:15'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/my.css"><link rel="stylesheet" href="https://at.alicdn.com/t/font_2107761_ythu35kdfcq.css"><meta name="generator" content="Hexo 5.3.0"><link rel="alternate" href="/atom.xml" title="明天又是周六了" type="application/atom+xml">
</head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" data-lazy-src="/img/avatar.jpg" onerror="onerror=null;src='/img/wechat.jpg'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">179</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">38</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">26</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-calendar"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tag"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/photos/"><i class="fa-fw fa fa-camera"></i><span> 相册</span></a></div><div class="menus_item"><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></div><div class="menus_item"><a class="site-page" href="/toolbox/"><i class="fa-fw fa fa-leaf"></i><span> 小工具</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-institution"></i><span> 实验室</span><i class="fas fa-chevron-down expand hide"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/color/"><i class="fa-fw fa fa-tachometer"></i><span> RGB颜色</span></a></li><li><a class="site-page" href="/colorPick/"><i class="fa-fw fa fa-magic"></i><span> 颜色提取</span></a></li><li><a class="site-page" href="/hexconvert/"><i class="fa-fw fa fa-calculator"></i><span> 进制转换</span></a></li><li><a class="site-page" href="/diff/"><i class="fa-fw fa fa-clone"></i><span> 文本对比</span></a></li><li><a class="site-page" href="/map/"><i class="fa-fw fa fa-globe"></i><span> 地球图层</span></a></li><li><a class="site-page" href="/dog/"><i class="fa-fw fa fa-heartbeat"></i><span> 舔狗日记</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-game"></i><span> 小游戏</span><i class="fas fa-chevron-down expand hide"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/Sudoku/"><span> 数独</span></a></li><li><a class="site-page" href="/puzzleNumber/"><span> 数字拼图</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/han-suyu/cover/21.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">明天又是周六了</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-calendar"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tag"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/photos/"><i class="fa-fw fa fa-camera"></i><span> 相册</span></a></div><div class="menus_item"><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></div><div class="menus_item"><a class="site-page" href="/toolbox/"><i class="fa-fw fa fa-leaf"></i><span> 小工具</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-institution"></i><span> 实验室</span><i class="fas fa-chevron-down expand hide"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/color/"><i class="fa-fw fa fa-tachometer"></i><span> RGB颜色</span></a></li><li><a class="site-page" href="/colorPick/"><i class="fa-fw fa fa-magic"></i><span> 颜色提取</span></a></li><li><a class="site-page" href="/hexconvert/"><i class="fa-fw fa fa-calculator"></i><span> 进制转换</span></a></li><li><a class="site-page" href="/diff/"><i class="fa-fw fa fa-clone"></i><span> 文本对比</span></a></li><li><a class="site-page" href="/map/"><i class="fa-fw fa fa-globe"></i><span> 地球图层</span></a></li><li><a class="site-page" href="/dog/"><i class="fa-fw fa fa-heartbeat"></i><span> 舔狗日记</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-game"></i><span> 小游戏</span><i class="fas fa-chevron-down expand hide"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/Sudoku/"><span> 数独</span></a></li><li><a class="site-page" href="/puzzleNumber/"><span> 数字拼图</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">卷积：如何成为一个很厉害的神经网络<a class="post-edit-link" href="https://github.com/han-suyu/hansy.tech/edit/main/source/_posts/卷积：如何成为一个很厉害的神经网络.md" title="编辑" target="_blank"><i class="fas fa-pencil-alt"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-06-24T11:31:15.000Z" title="发表于 2020-06-24 19:31:15">2020-06-24</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2020-06-24T11:31:15.000Z" title="更新于 2020-06-24 19:31:15">2020-06-24</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Machine-Learning/">Machine Learning</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">5k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>15分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2020/06/3272311197.html#post-comment"><span id="twikoo-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="什么是卷积神经网络又为什么很重要">什么是卷积神经网络？又为什么很重要？</h2>
<p>卷积神经网络(Convolutional Neural Networks, ConvNets or CNNs)是一种在图像识别与分类领域被证明特别有效的神经网络。卷积网络已经成功地识别人脸、物体、交通标志，应用在机器人和无人车等载具。</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2017-05-28-at-11-41-55-pm.png?w=1024" alt="图1" /><figcaption>图1</figcaption>
</figure>
<p>在上面的<strong>图1</strong>当中，卷积网络能够识别场景而系统可以自动推荐相关标签（如一个足球运动员正在踢球）。<strong>图2</strong>则展示了卷积网络识别日常事物如人、动物的例子。最近，卷积网络也已经在自然语言处理上显示出了威力（比如句子分类）。</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="https://pic2.zhimg.com/80/v2-8404ab90cd524d9cd3e6a1b326763b19_720w.png" alt="图2" /><figcaption>图2</figcaption>
</figure>
<p>卷积网络，在今天的绝大多数机器学习应用中都是极重要的工具。但是，理解卷积网络并首次学着使用，这体验有时并不友好。本文的主旨在于帮助读者理解，卷积神经网络是如何作用于图片的。</p>
<p>在本文，多层感知机(Multi-Layer Perceptrons, MLP)也被记作全连接层(Fully Connected Layers)。</p>
<h2 id="lenet架构1990年代">LeNet架构(1990年代）</h2>
<p>LeNet是最早用于深度学习了领域的卷积神经网络之一。Yann LeCun的这一杰作LeNet5得名于他自1988年以来的系列成功迭代。彼时LeNet架构还主要被用于识别邮政编码等任务。</p>
<p>下面我们将直观地感受一下，LeNet是如何学习识别图像的。近几年已经出现了很多建立在LeNet之上的新架构，但是基本概念还是来自于LeNet，并且理解了LeNet再学其他的也会更简单。</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="https://pic1.zhimg.com/80/v2-38f71f3d4d0baac609d1cc6fe6f22a74_720w.png" alt="图3：简单的ConvNet" /><figcaption>图3：简单的ConvNet</figcaption>
</figure>
<p><strong>图3</strong>的卷积神经网络与LeNet的原始架构十分接近，把图片分入四个类别：狗，猫，船，鸟（LeNet最早主要就是用来做这些）。如上图所示，当获得一张船图作为输入的时候，网络正确的给船的分类赋予了最高的概率(0.94)。输出层的各个概率相加应为1.</p>
<p><strong>图3</strong>的卷积神经网络主要执行了四个操作：</p>
<ol type="1">
<li>卷积</li>
<li>非线性(ReLU)</li>
<li>池化或下采样</li>
<li>分类（全连接层）</li>
</ol>
<p>这些操作也是所有卷积神经网络的基石，所以理解好这些工作对于理解整个神经网络至关重要。接下来我们将尝试最直观地理解以上操作。</p>
<h2 id="图片是像素值的矩阵">图片是像素值的矩阵</h2>
<p>本质上来讲，每个图片都可以表示为像素值组成的矩阵：</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="https://ujwlkarn.files.wordpress.com/2016/08/8-gif.gif?w=192&amp;h=192" alt="图4：像素值矩阵" /><figcaption>图4：像素值矩阵</figcaption>
</figure>
<p><strong>通道</strong>是代指图片特定成分的习语。常见数码相机拍出来的照片有三个通道——红、绿、蓝-可以想象为是三个2d矩阵（每种颜色对应一个）叠在一起，每个矩阵的值都在0-255之间。</p>
<p>另一方面，<strong>灰度</strong>图像只有单通道。本文为简单起见只考虑灰度图像，这样就是一个2d矩阵。矩阵中的每个像素值还是0到255——0表示黑，255表示白。</p>
<h2 id="卷积">卷积</h2>
<p>卷积网络是因为<strong>“卷积”操作</strong>而得名的。卷积的根本目的是从输入图片中提取特征。卷积用一个小方阵的数据学习图像特征，可以保留像素之间的空间关系。这里不深入探讨卷积的数学原理，重在理解工作过程。</p>
<p>如上所述，每个图片都是像素值矩阵。考虑一个5x5的图像，其像素值为0和1，下面的绿色矩阵是灰度图的特例（常规灰度图的像素值取值0-255），同时考虑如下的3x3矩阵：</p>
<p><img src= "/img/loading.gif" data-lazy-src="https://pic1.zhimg.com/80/v2-add89dece41a5210a24b91f8f2af03e4_720w.png" /></p>
<p>然后，5x5图像和3x3矩阵之间的卷积计算，可由下图的动画所表示：</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="https://ujwlkarn.files.wordpress.com/2016/07/convolution_schematic.gif?w=268&amp;h=196" alt="图5：卷积操作。输出矩阵叫卷积特征或特征映射" /><figcaption>图5：卷积操作。输出矩阵叫卷积特征或特征映射</figcaption>
</figure>
<p>想一想以上操作是如何完成的，我们在原始图片（绿色）上1像素、1像素地滑动橙色矩阵（也称'stride'），并且在每个位置上，我们都对两个矩阵的对应元素相乘后求和得到一个整数，这就是输出矩阵（粉色）的元素。注意，3x3矩阵每次只“看见”输入图片的一部分。</p>
<p>3x3矩阵也叫“<strong>滤波器</strong>”、“核”或“特征探测器”，在原图上滑动滤波器、点乘矩阵所得的矩阵称为“卷积特征”、“激励映射”或“<strong>特征映射</strong>”。这里的重点就是，理解滤波器对于原输入图片来说，是个特征探测器。</p>
<p>对于同一张照片，不同的滤波器将会产生不同的特征映射。比如考虑下面这张输入图片：</p>
<p><img src= "/img/loading.gif" data-lazy-src="https://pic3.zhimg.com/80/v2-dbba2a167aec7a158d145004f98393b2_720w.jpg" /></p>
<p>下表可见各种不同卷积核对于上图的效果。只需调整滤波器的数值，我们就可以执行诸如边缘检测、锐化、模糊等效果——这说明不同的滤波器会从图片中探测到不同的特征，比如边缘、曲线等。</p>
<p><img src= "/img/loading.gif" data-lazy-src="https://pic1.zhimg.com/80/v2-034c6058037c03c544955111a749c280_720w.png" /></p>
<p>另一种对卷积操作很好的理解方式就是观察<strong>图6</strong>的动画：</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="https://ujwlkarn.files.wordpress.com/2016/08/giphy.gif?w=748" alt="图6：卷积运算" /><figcaption>图6：卷积运算</figcaption>
</figure>
<p>一个滤波器（红框）在图片上滑动（卷积）产生特征映射。在同一个图片上，另一个滤波器（绿框）的卷积产生了不同的特征映射。须知，卷积操作捕捉的是原图的局部依赖性。另外，注意观察两个不同的滤波器怎样产生不同的特征映射。其实不管是图片，还是两个滤波器，本质上都不过是我们刚才看过的数值矩阵而已。</p>
<p>在实践当中，卷积神经网络在训练过程中学习滤波器的值，当然我们还是要在训练之前需要指定一些参数：滤波器的个数，滤波器尺寸、网络架构等等。滤波器越多，从图像中提取的特征就越多，模式识别能力就越强。</p>
<p>特征映射的尺寸由三个参数控制，我们需要在卷积步骤之前就设定好：</p>
<ul>
<li>深度(Depth)： 深度就是卷积操作中用到的滤波器个数。如<strong>图7</strong>所示，我们对原始的船图用了三个不同的滤波器，从而产生了三个特征映射。你可以认为这三个特征映射也是堆叠的2d矩阵，所以这里特征映射的“深度”就是3。</li>
</ul>
<figure>
<img src= "/img/loading.gif" data-lazy-src="https://pic2.zhimg.com/80/v2-6388221cc6d20c9c3a1298e5baa8793d_720w.png" alt="图7" /><figcaption>图7</figcaption>
</figure>
<ul>
<li>步幅(Stride)：步幅是每次滑过的像素数。当Stride=1的时候就是逐个像素地滑动。当Stride=2的时候每次就会滑过2个像素。步幅越大，特征映射越小。</li>
<li>补零(Zero-padding)：有时候在输入矩阵的边缘填补一圈0会很方便，这样我们就可以对图像矩阵的边缘像素也施加滤波器。补零的好处是让我们可以控制特征映射的尺寸。补零也叫宽卷积，不补零就叫窄卷积。</li>
</ul>
<h2 id="非线性">非线性</h2>
<p>如<strong>图3</strong>所示，每个卷积操作之后，都有一个叫<strong>ReLU</strong>的附加操作。ReLU的全称是纠正线性单元(Rectified Linear Unit)，是一种非线性操作，其输出如下：</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="https://pic1.zhimg.com/80/v2-c8afbf19afabcfccb1d0f27ac5f7eed0_720w.png" alt="图8：ReLU" /><figcaption>图8：ReLU</figcaption>
</figure>
<p>ReLU是以像素为单位生效的，其将所有负值像素替换为0。ReLU的目的是向卷积网络中引入非线性，因为真实世界里大多数需要学习的问题都是非线性的（单纯的卷积操作时线性的——矩阵相乘、相加，所以才需要额外的计算引入非线性）。</p>
<p>图9可以帮助我们清晰地理解，ReLU应用在<strong>图6</strong>得到的特征映射上，输出的新特征映射也叫“纠正”特征映射。（黑色被抹成了灰色）</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="https://pic4.zhimg.com/80/v2-9feb833b3e855d9d282fce472429311b_720w.png" alt="图9：ReLU" /><figcaption>图9：ReLU</figcaption>
</figure>
<p>其他非线性方程比如<strong>tanh</strong>或<strong>sigmoid</strong>也可以替代ReLU，但多数情况下ReLU的表现更好。</p>
<h2 id="池化">池化</h2>
<p>空间池化（也叫亚采样或下采样）降低了每个特征映射的维度，但是保留了最重要的信息。空间池化可以有很多种形式：最大(Max)，平均(Average)，求和(Sum)等等。</p>
<p>以最大池化为例，我们定义了空间上的邻域（2x2的窗）并且从纠正特征映射中取出窗里最大的元素。除了取最大值以额外，我们也可以取平均值（平均池化）或者把窗里所有元素加起来。实际上，最大池化已经显示了最好的成效。</p>
<p><strong>图10</strong>显示了对纠正特征映射的最大池化操作（在卷积+ReLU之后），使用的是2x2的窗。</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="https://pic3.zhimg.com/80/v2-97065f08e3bb34c4e42e223636cc5b0e_720w.png" alt="图10：最大池化" /><figcaption>图10：最大池化</figcaption>
</figure>
<p>我们以2格的步幅(Stride)滑动2x2的窗，并且取每个区域的最大值。<strong>图10</strong>同样显示了池化可以减少特征映射的维度。</p>
<p>在<strong>图11</strong>所示的网络中，池化操作分别应用于每个特征映射（注意正因如此，我们从三个输入映射得到了三个输出映射）。</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="https://pic4.zhimg.com/80/v2-22eebe9b4d2b2070815c7d571cc94e83_720w.png" alt="图11：对纠正特征映射应用池化" /><figcaption>图11：对纠正特征映射应用池化</figcaption>
</figure>
<p><strong>图12</strong>即为池化操作施加在<strong>图9</strong>所得纠正特征映射上的效果。</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="https://pic2.zhimg.com/80/v2-b8e2a2e05956b1b4191f853c2c65befd_720w.png" alt="图12：池化" /><figcaption>图12：池化</figcaption>
</figure>
<p>池化的功能室逐步减少输入表征的空间尺寸。特别地，池化</p>
<ul>
<li>使输入表征（特征维度）更小而易操作</li>
<li>减少网络中的参数与计算数量，从而遏制过拟合</li>
<li>增强网络对输入图像中的小变形、扭曲、平移的鲁棒性（输入里的微小扭曲不会改变池化输出——因为我们在局部邻域已经取了最大值/平均值）。</li>
<li>帮助我们获得不因尺寸而改变的等效图片表征。这非常有用，因为这样我们就可以探测到图片里的物体，不论那个物体在哪。</li>
</ul>
<p>截至目前：</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="https://pic3.zhimg.com/80/v2-cfd915e11fa53fbeb7a41716f3c1a236_720w.png" alt="图13" /><figcaption>图13</figcaption>
</figure>
<p>至此我们已经了解了卷积、ReLU和池化是如何运转的，这些层对于所有的卷积神经网络都是最基础的单元。如<strong>图13</strong>所示，我们有两组“卷积+ReLU+池化”层——其中第二组对第一组的输出施加了六个滤波器，产生了六个特征映射。ReLU分别作用域这六个特征映射，再对生成的纠正特征映射使用最大池化。</p>
<p>这些层合力提取出有用的特征，为网络引入了非线性并降低了维度，还使特征对尺寸和平移保持不变性。</p>
<p>第二个池化层的输出相当于全连接层的输入，我们将在下一节继续探讨。</p>
<h2 id="全连接层">全连接层</h2>
<p>全连接层(Fully Connected layer)就是使用了softmax激励函数作为输出层的多层感知机(Multi-Layer Perceptron)，其他很多分类器如支持向量机也使用了softmax。“全连接”表示上一层的每一个神经元，都和下一层的每一个神经元是相互连接的。</p>
<p>卷积层和池化层呢个的输出代表了输入图像的高级特征，全连接层的目的就是用这些特征进行分类，类别基于训练集。比如图14所示的图像分类任务，有四种可能的类别。（注意，图14没有显示出所有的神经元节点）</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="https://pic1.zhimg.com/80/v2-45a9987d6c4838c4c8a24c1b3a4ce7d8_720w.png" alt="图14：全连接层——每个节点都与相邻层的所有节点相连" /><figcaption>图14：全连接层——每个节点都与相邻层的所有节点相连</figcaption>
</figure>
<p>除了分类以外，加入全连接层也是学习特征之间非线性组合的有效办法。卷积层和池化层提取出来的特征很好，但是如果考虑这些特征之间的组合，就更好了。</p>
<p>全连接层的输出概率之和为1，这是由激励函数Softmax保证的。Softmax函数把任意实值的向量转变成元素取之0-1且和为1的向量。</p>
<h2 id="联合起来反向传播训练">联合起来——反向传播训练</h2>
<p>综上，卷积+池化是特征提取器，全连接层是分类器。</p>
<p>注意<strong>图15</strong>，因为输入图片是条船，所以目标概率对船是1，其他类别是0.</p>
<ul>
<li>输入图像 = 船</li>
<li>目标向量 = [0, 0, 1 ,0]</li>
</ul>
<figure>
<img src= "/img/loading.gif" data-lazy-src="https://pic3.zhimg.com/80/v2-73cc788cfc81dfe5411c82cd53b007be_720w.png" alt="图15：训练卷积神经网络" /><figcaption>图15：训练卷积神经网络</figcaption>
</figure>
<p>卷积网络的训练过程可以概括如下：</p>
<p><strong>Step 1:</strong> 用随机数初始化所有的滤波器和参数/权重</p>
<ul>
<li><p><strong>Step 2:</strong> 网络将训练图片作为输入，执行前向步骤（卷积，ReLU，池化以及全连接层的前向传播）并计算每个类别的对应输出概率。</p>
<ul>
<li>假设船图的输出概率是[0.2, 0.4, 0.1, 0.3]</li>
<li>因为第一个训练样本的权重都是随机的，所以这个输出概率也跟随机的差不多</li>
</ul></li>
<li><p><strong>Step 3:</strong> 计算输出层的总误差（4类别之和）</p>
<ul>
<li><strong>总误差=∑12(目标概率−输出概率)2总误差=∑12(目标概率−输出概率)2</strong></li>
</ul></li>
<li><p><strong>Step 4:</strong> 反向传播算法计算误差相对于所有权重的梯度，并用<em>梯度下降法</em>更新所有的滤波器/权重和参数的值，以使输出误差最小化。</p></li>
<li><ul>
<li>权重的调整程度与其对总误差的贡献成正比。</li>
<li>当同一图像再次被输入，这次的输出概率可能是[0.1, 0.1, 0.7, 0.1]，与目标[0, 0, 1, 0]更接近了。</li>
<li>这说明我们的神经网络已经学习着分类特定图片了，学习的方式是调整权重/滤波器以降低输出误差。</li>
<li>如滤波器个数、滤波器尺寸、网络架构这些参数，是在Step 1之前就已经固定的，且不会在训练过程中改变——只有滤波矩阵和神经元突触权重会更新。</li>
</ul></li>
</ul>
<p>以上步骤<em>训练</em>了卷积网络——本质上就是优化所有的权重和参数，使其能够正确地分类训练集里的图片。</p>
<p>当一个新的（前所未见的）的图片输入至卷积网络，网络会执行前向传播步骤并输出每个类别的概率（对于新图像，输出概率用的也是训练过的权重值）。如果我们的训练集足够大，网络就有望正确分类新图片，获得良好的泛化(generalization)能力。</p>
<p><strong>注意 1:</strong> 以上步骤已被极大简化，且数学细节均以忽略，这是为了让训练过程更直观。</p>
<p><strong>注意 2:</strong> 上例中，我们用了两组卷积+池化层，其实这些操作可以在一个卷积网络内重复无数次。如今有些表现出众的卷积网络，都有数以十计的卷积+池化层！并且，不是每个卷积层后面都要跟个池化层。由<strong>图16</strong>可见，我们可以有连续多组卷积+ReLU层，后面再加一个池化层。</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="https://pic3.zhimg.com/80/v2-36df4a5bf0be915e0ed2ea085f69de32_720w.png" alt="图16" /><figcaption>图16</figcaption>
</figure>
<h2 id="可视化卷积神经网络">可视化卷积神经网络</h2>
<p>一般来说，卷积层越多，能学会的特征也就越复杂。比如在图像分类中，一个卷积神经网络的第一层学会了探测像素中的边缘，然后第二层用这些边缘再去探测简单的形状，其他层再用形状去探测高级特征，比如脸型，如<strong>图17</strong>所示——这些特征是<a target="_blank" rel="noopener" href="https://web.eecs.umich.edu/~honglak/icml09-ConvolutionalDeepBeliefNetworks.pdf">Convolutional Deep Belief Network</a>学得的。这里只是一个简单的例子，实际上卷积滤波器可能会探测出一些没有意义的特征。</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="https://pic2.zhimg.com/80/v2-d9979f93198a3e21e34ba34aaace0a49_720w.png" alt="图17：Convolutional Deep Belief Network学习的特征" /><figcaption>图17：Convolutional Deep Belief Network学习的特征</figcaption>
</figure>
<p>Adam Harley做了一个非常惊艳的卷积神经网络可视化，这个网络是用MNIST手写数字数据库训练而来的。我强烈推荐大家<a target="_blank" rel="noopener" href="https://scs.ryerson.ca/~aharley/vis/conv/flat.html">玩一玩</a>，以便更深地理解卷积神经网络的细节。</p>
<p>如下我们将看到网络是如何识别输入数字&quot;8&quot;的。注意，<strong>图18</strong>没有把ReLU过程单独显示出来。</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="https://pic4.zhimg.com/80/v2-adbba7de0c0a0e52fe846c01fbc91ccb_720w.png" alt="图18：可视化卷积神经网络" /><figcaption>图18：可视化卷积神经网络</figcaption>
</figure>
<p>输入图像有1024个像素（32x32图片），第一个卷积层(Convolution Layer 1)有六个不同的5x5滤波器(Stride = 1)。由图可见，六个不同的滤波器产生了深度为6的特征映射。</p>
<p>Convolutional Layer 1 后面跟着Pooling Layer 1, 对六个特征映射分别进行2x2的最大池化（Stride = 2）。你可以在动态网页中的每个像素上活动鼠标指针，观察其在前一个卷积层里对应的4x4网格（如<strong>图19</strong>）。不难发现，每个4x4网格里的最亮的像素（对应最大值）构成了池化层。</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="https://pic1.zhimg.com/80/v2-3eb08067b3bd57996614f1ea12f90798_720w.png" alt="图19：可视化池化操作" /><figcaption>图19：可视化池化操作</figcaption>
</figure>
<p>之后我们有三个全连接(FC)层：</p>
<ul>
<li><strong>FC 1:</strong> 120神经元</li>
<li><strong>FC 2:</strong> 100神经元</li>
<li><strong>FC 3:</strong> 10神经元，对应10个数字——也即输出层</li>
</ul>
<p>在<strong>图20</strong>，输出层10个节点中的每一个，都与第二个全连接层的100个节点相连（所以叫“全连接”）。</p>
<p>注意输出层里的唯一的亮点对应着8——这说明网络正确的识别了手写数字（越亮的节点代表越高的概率，比如这里8就拥有最高的概率）。</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="https://pic4.zhimg.com/80/v2-b6379c3895d6f695c6db7fedfea419b7_720w.png" alt="图20：可视化全连接层" /><figcaption>图20：可视化全连接层</figcaption>
</figure>
<p>该可视化的3D版可见于<a target="_blank" rel="noopener" href="http://scs.ryerson.ca/~aharley/vis/conv/">这里</a>。</p>
<h2 id="其他卷积网络架构">其他卷积网络架构</h2>
<p>卷积神经网络始自1990年代起，我们已经认识了最早的LeNet，其他一些很有影响力的架构列举如下：</p>
<ul>
<li>1990s至2012：从90年代到2010年代早期，卷积神经网络都处于孵化阶段。随着数据量增大和计算能力提高，卷积神经网络能搞定的问题也越来越有意思了。</li>
<li>AlexNet(2012)：2012年，Alex Krizhevsky发布了<a target="_blank" rel="noopener" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf">AlexNet</a>，是LeNet的更深、更宽版本，并且大比分赢得了当年的ImageNet大规模图像识别挑战赛(ILSVRC)。这是一次非常重要的大突破，现在普及的卷积神经网络应用都要感谢这一壮举。</li>
<li>ZF Net(2013)：2013年的ILSVRC赢家是Matthew Zeiler和Rob Fergus的卷积网络，被称作<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1311.2901">ZF Net</a>，这是调整过架构超参数的AlexNet改进型。</li>
<li>GoogleNet(2014)：2014的ILSVRC胜者是来自Google的<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1409.4842">Szegedy et al.</a>。其主要贡献是研发了<em>Inception Module</em>，它大幅减少了网络中的参数数量（四百万，相比AlexNet的六千万）。</li>
<li>VGGNet(2014)：当年的ILSVRC亚军是<a target="_blank" rel="noopener" href="https://www.robots.ox.ac.uk/~vgg/research/very_deep/">VGGNet</a>，突出贡献是展示了网络的深度（层次数量）是良好表现的关键因素。</li>
<li>ResNet(2015)： Kaiming He研发的<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1512.03385">Residual Network</a>是2015年的ILSVRC冠军，也代表了卷积神经网络的最高水平，同时还是实践的默认选择（2016年5月）。</li>
<li>DenseNet（2016年8月）： 由Gao Huang发表，<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1608.06993">Densely Connected Convolutional Network</a>的每一层都直接与其他各层前向连接。DenseNet已经在五个高难度的物体识别基础集上，显式出非凡的进步。</li>
</ul>
<p><strong>（翻译部分 完）</strong></p>
<p>经过本文和之前的<a target="_blank" rel="noopener" href="https://jizhi.im/blog/post/nn_py_9">系列文章</a>，您应该已经掌握了卷积神经网络的基本原理。接下来我们尝试用流行的Python深度学习库<a target="_blank" rel="noopener" href="https://keras-cn.readthedocs.io/">Keras</a>，动手实地搭建一个LeNet。</p>
<p>实践是神经网络的唯一标准</p>
<p>回顾LeNet的架构，补全第二组卷积+激励+池化，搭建出经典的LeNet网络。</p>
<p>提示：</p>
<ul>
<li>第二组卷积层有16个滤波器，尺寸为8x8。</li>
<li>第二组激励层使用tanh函数</li>
<li>第二组最大池化层的尺寸和步幅均为3x3</li>
</ul>
<p>请在下方的Python开发环境中补全代码，并点击蓝色按钮【运行】检查答案是否正确。</p>
<p><strong>（需访问：<a target="_blank" rel="noopener" href="https://jizhi.im/blog/post/intuitive_explanation_cnn">卷积：如何成为一个很厉害的神经网络 - 集智专栏</a>）</strong></p>
<p>如下图，第二组卷积+激励+池化层的参数设置有误，就会得到红色提示，并指出具体的错误所在。</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="https://pic3.zhimg.com/80/v2-f85c12d234d526e12c8979288a8b9676_720w.jpg" alt="img" /><figcaption>img</figcaption>
</figure>
<p> </p>
<p> </p>
<p> </p>
<blockquote>
<p>参考：https://zhuanlan.zhihu.com/p/25754846</p>
<p>原文：https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/</p>
</blockquote>
<!-- flag of hidden posts --><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script></article><div class="tag_share"><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/han-suyu/cover/21.jpg" data-sites="wechat,weibo,qq,facebook,twitter"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" data-lazy-src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/wechat.jpg'" alt="avatar"/><div class="author-info__name">Seven</div><div class="author-info__description">谦虚受益，满盈招损</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">179</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">38</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">26</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/han-suyu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="http://wpa.qq.com/msgrd?v=3&amp;uin=1121687782&amp;site=qq&amp;menu=yes" target="_blank" title="QQ"><i class="iconfont icon-QQ"></i></a><a class="social-icon" href="https://cdn.jsdelivr.net/gh/han-suyu/cdn/WeChat.jpg" target="_blank" title="WeChat"><i class="iconfont icon-wechat"></i></a><a class="social-icon" href="mailto:han-suyu@foxmail.com" target="_blank" title="Email"><i class="iconfont icon-EMAILMARKETING"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%88%E4%B8%BA%E4%BB%80%E4%B9%88%E5%BE%88%E9%87%8D%E8%A6%81"><span class="toc-text">什么是卷积神经网络？又为什么很重要？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lenet%E6%9E%B6%E6%9E%841990%E5%B9%B4%E4%BB%A3"><span class="toc-text">LeNet架构(1990年代）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BE%E7%89%87%E6%98%AF%E5%83%8F%E7%B4%A0%E5%80%BC%E7%9A%84%E7%9F%A9%E9%98%B5"><span class="toc-text">图片是像素值的矩阵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF"><span class="toc-text">卷积</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9D%9E%E7%BA%BF%E6%80%A7"><span class="toc-text">非线性</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B1%A0%E5%8C%96"><span class="toc-text">池化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82"><span class="toc-text">全连接层</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%81%94%E5%90%88%E8%B5%B7%E6%9D%A5%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E8%AE%AD%E7%BB%83"><span class="toc-text">联合起来——反向传播训练</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%AF%E8%A7%86%E5%8C%96%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-text">可视化卷积神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84"><span class="toc-text">其他卷积网络架构</span></a></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2021 By Seven</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'twikoo-comment-6ghgiokk80ee2970',
      region: 'ap-shanghai'
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'twikoo-comment-6ghgiokk80ee2970',
      region: 'ap-shanghai',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/gh/metowolf/MetingJS@1.2/dist/Meting.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>