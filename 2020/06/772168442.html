<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>基于GoogLeNet模型实现MNIST手写体数据集的训练 | 愿风载尘</title><meta name="description" content="GoogLeNet（也就是InceptionNet v1版本）诞生于2014年，当年ImageNet竟赛冠军，Top5错误率为6.67%。  VGG获得了第二名，Top5错误率为7.32%。VGG继承了LeNet以及AlexNet的一些框架结构，而GoogLeNet则做了更加大胆的网络结构尝试，虽然深度只有22层，但大小却比AlexNet和VGG小很多：GoogleNet参数为500万个，Alex"><meta name="author" content="Seven"><meta name="copyright" content="Seven"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://hansuyu.com/2020/06/772168442.html"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="u9AaJlYHNmU4dpUtiWPMA9_vQRU4zjcERKUymU8aEao"/><meta name="baidu-site-verification" content="m7BzC4y6nU"/><meta property="og:type" content="article"><meta property="og:title" content="基于GoogLeNet模型实现MNIST手写体数据集的训练"><meta property="og:url" content="http://hansuyu.com/2020/06/772168442.html"><meta property="og:site_name" content="愿风载尘"><meta property="og:description" content="GoogLeNet（也就是InceptionNet v1版本）诞生于2014年，当年ImageNet竟赛冠军，Top5错误率为6.67%。  VGG获得了第二名，Top5错误率为7.32%。VGG继承了LeNet以及AlexNet的一些框架结构，而GoogLeNet则做了更加大胆的网络结构尝试，虽然深度只有22层，但大小却比AlexNet和VGG小很多：GoogleNet参数为500万个，Alex"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/han-suyu/cover/61.jpg"><meta property="article:published_time" content="2020-06-28T02:00:39.000Z"><meta property="article:modified_time" content="2020-06-30T02:16:00.453Z"><meta name="twitter:card" content="summary"><script>var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#000')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#fff')
  }
}

var getCookies = function (name) {
  const value = `; ${document.cookie}`
  const parts = value.split(`; ${name}=`)
  if (parts.length === 2) return parts.pop().split(';').shift()
}

var autoChangeMode = 'false'
var t = getCookies('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (Cookies.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><link rel="next" title="基于LeNet模型实现MNIST手写体数据集的训练" href="http://hansuyu.com/2020/06/670302972.html"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  translate: {"defaultEncoding":1,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: {"languages":{"author":"作者: Seven","link":"链接: ","source":"来源: 愿风载尘","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: {"bookmark":{"message_prev":"按","message_next":"键将本页加入书签"},"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#2d3035","position":"top-center"},
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  isPhotoFigcaption: true,
  islazyload: true,
  isanchor: true    
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true
  }</script><noscript><style>
#nav {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@latest/butterfly/css/flink.min.css"><link rel="stylesheet" href="/css/my.css"><meta name="generator" content="Hexo 4.2.1"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">158</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">30</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">19</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-calendar"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tag"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/photos/"><i class="fa-fw fa fa-camera"></i><span> 相册</span></a></div><div class="menus_item"><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> 电影</span></a></div><div class="menus_item"><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></div><div class="menus_item"><a class="site-page" href="/artitalk/"><i class="fa-fw fa fa-edit"></i><span> 心情</span></a></div><div class="menus_item"><a class="site-page" href="/toolbox/"><i class="fa-fw fa fa-leaf"></i><span> 小工具</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-institution"></i><span> 实验室</span><i class="fas fa-chevron-down menus-expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/color/"><i class="fa-fw fa fa-magic"></i><span> RGB颜色</span></a></li><li><a class="site-page" href="/hexconvert/"><i class="fa-fw fa fa-calculator"></i><span> 进制转换</span></a></li><li><a class="site-page" href="/diff/"><i class="fa-fw fa fa-clone"></i><span> 文本对比</span></a></li><li><a class="site-page" href="/map/"><i class="fa-fw fa fa-globe"></i><span> 地球图层</span></a></li><li><a class="site-page" href="/dog/"><i class="fa-fw fa fa-heartbeat"></i><span> 舔狗日记</span></a></li></ul></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-game"></i><span> 小游戏</span><i class="fas fa-chevron-down menus-expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/Sudoku/"><span> 数独</span></a></li><li><a class="site-page" href="/jumper/"><span> 跳一跳</span></a></li><li><a class="site-page" href="/puzzleNumber/"><span> 数字拼图</span></a></li><li><a class="site-page" href="/referrence/"><span> referrence</span></a></li></ul></div></div></div></div><i class="fas fa-arrow-right" id="toggle-sidebar"></i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#二、论文关键点解析"><span class="toc-text">二、论文关键点解析</span></a></li></ol></div></div></div><div id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://cdn.jsdelivr.net/gh/han-suyu/cover/61.jpg)"><nav id="nav"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/">愿风载尘</a></span><span class="pull-right menus"><div id="search_button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-calendar"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tag"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/photos/"><i class="fa-fw fa fa-camera"></i><span> 相册</span></a></div><div class="menus_item"><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> 电影</span></a></div><div class="menus_item"><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></div><div class="menus_item"><a class="site-page" href="/artitalk/"><i class="fa-fw fa fa-edit"></i><span> 心情</span></a></div><div class="menus_item"><a class="site-page" href="/toolbox/"><i class="fa-fw fa fa-leaf"></i><span> 小工具</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-institution"></i><span> 实验室</span><i class="fas fa-chevron-down menus-expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/color/"><i class="fa-fw fa fa-magic"></i><span> RGB颜色</span></a></li><li><a class="site-page" href="/hexconvert/"><i class="fa-fw fa fa-calculator"></i><span> 进制转换</span></a></li><li><a class="site-page" href="/diff/"><i class="fa-fw fa fa-clone"></i><span> 文本对比</span></a></li><li><a class="site-page" href="/map/"><i class="fa-fw fa fa-globe"></i><span> 地球图层</span></a></li><li><a class="site-page" href="/dog/"><i class="fa-fw fa fa-heartbeat"></i><span> 舔狗日记</span></a></li></ul></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-game"></i><span> 小游戏</span><i class="fas fa-chevron-down menus-expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/Sudoku/"><span> 数独</span></a></li><li><a class="site-page" href="/jumper/"><span> 跳一跳</span></a></li><li><a class="site-page" href="/puzzleNumber/"><span> 数字拼图</span></a></li><li><a class="site-page" href="/referrence/"><span> referrence</span></a></li></ul></div></div><span class="toggle-menu close"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">基于GoogLeNet模型实现MNIST手写体数据集的训练</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2020-06-28 10:00:39"><i class="far fa-calendar-alt fa-fw"></i> 发表于 2020-06-28</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2020-06-30 10:16:00"><i class="fas fa-history fa-fw"></i> 更新于 2020-06-30</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fas fa-inbox fa-fw post-meta__icon"></i><a class="post-meta__categories" href="/categories/Computer-Version/">Computer Version</a></span></div><div class="meta-secondline"> <span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta__icon"></i><span>字数总计:</span><span class="word-count">4.9k</span><span class="post-meta__separator">|</span><i class="far fa-clock fa-fw post-meta__icon"></i><span>阅读时长: 16 分钟</span></span></div><div class="meta-thirdline"><span class="post-meta-pv-cv"><span class="post-meta__separator">|</span><i class="far fa-eye fa-fw post-meta__icon"></i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"><span class="post-meta__separator">|</span><i class="far fa-comments fa-fw post-meta__icon"></i><span>评论数:</span><a href="/2020/06/772168442.html#post-comment" itemprop="discussionUrl"><span class="valine-comment-count comment-count" data-xid="/2020/06/772168442.html" itemprop="commentCount"></span></a></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><p>GoogLeNet（也就是InceptionNet v1版本）诞生于2014年，当年ImageNet竟赛冠军，Top5错误率为6.67%。</p>
<blockquote>
<p>VGG获得了第二名，Top5错误率为7.32%。VGG继承了LeNet以及AlexNet的一些框架结构，而GoogLeNet则做了更加大胆的网络结构尝试，虽然深度只有22层，但大小却比AlexNet和VGG小很多：GoogleNet参数为500万个，AlexNet参数个数是GoogleNet的12倍，VGGNet参数又是AlexNet的3倍，因此在内存或计算资源有限时，GoogleNet是比较好的选择；从模型结果来看，GoogLeNet的性能却更加优越。</p>
<blockquote>
<p>小知识：<br>GoogLeNet是谷歌（Google）研究出来的深度网络结构，为什么不叫“GoogleNet”，而叫“GoogLeNet”，据说是为了向“LeNet”致敬，因此取名为“GoogLeNet”</p>
</blockquote>
</blockquote>
<p>&nbsp;</p>
<p>一般来说，提升网络性能最直接的办法就是增加网络深度和宽度，深度指网络层次数量、宽度指神经元数量（如AlexNet、VGG等结构）。但这种方式存在以下问题：</p>
<ol>
<li>参数太多，如果训练数据集有限，很容易产生过拟合</li>
<li>网络越大、参数越多，计算复杂度越大，难以应用</li>
<li>网络越深，容易出现梯度弥散问题（梯度越往后穿越容易消失），难以优化模型。</li>
</ol>
<p>&nbsp;</p>
<p>解决这些问题的方法当然就是在增加网络深度和宽度的同时减少参数，为了减少参数，自然就想到将全连接变成稀疏连接。但是在实现上，全连接变成稀疏连接后实际计算量并不会有质的提升，因为大部分硬件是针对密集矩阵计算优化的，稀疏矩阵虽然数据量少，但是计算所消耗的时间却很难减少。</p>
<p>那么，有没有一种方法既能保持网络结构的稀疏性，又能利用密集矩阵的高计算性能。大量的文献表明可以将稀疏矩阵聚类为较为密集的子矩阵来提高计算性能，就如人类的大脑是可以看做是神经元的重复堆积，因此，GoogLeNet团队提出了Inception网络结构，就是构造一种“基础神经元”结构，来搭建一个稀疏性、高计算性能的网络结构。</p>
<p><strong>InceptionNet引入了Inception结构块（核心），在同一层网络内使用不同尺寸的卷积核来提取不同尺寸的特征，提升了模型感知力，使用了批标准化，缓解了梯度消失问题。</strong></p>
<p>通过设计一个稀疏网络结构，但是能够产生稠密的数据，既能增加神经网络表现，又能保证计算资源的使用效率。谷歌提出了最原始Inception的基本结构：<br>                                   <img src= "/img/loading.gif" data-src="https://static.oschina.net/uploads/space/2018/0317/141510_fIWh_876354.png" alt="Inception原始网络结构"><br>该结构将CNN中常用的卷积（1x1，3x3，5x5）、池化操作（3x3）堆叠在一起（卷积、池化后的尺寸相同，将通道相加），一方面增加了网络的宽度，另一方面也增加了网络对尺度的适应性。<br>网络卷积层中的网络能够提取输入的每一个细节信息，同时5x5的滤波器也能够覆盖大部分接受层的的输入。还可以进行一个池化操作，以减少空间大小，降低过度拟合。在这些层之上，在每一个卷积层后都要做一个ReLU操作，以增加网络的非线性特征。<br>然而这个Inception原始版本，所有的卷积核都在上一层的所有输出上来做，而那个5x5的卷积核所需的计算量就太大了，造成了特征图的厚度很大，为了避免这种情况，在3x3前、5x5前、max pooling后分别加上了1x1的卷积核，以起到了降低特征图厚度的作用，这也就形成了Inception v1的网络结构，如下图所示：</p>
<p><img src= "/img/loading.gif" data-src="https://static.oschina.net/uploads/space/2018/0317/141520_31TH_876354.png" alt="改进后的Inception网络结构"></p>
<p>具体来说，inception结构的主要特点有两个：一是使用1x1的卷积来进行升降维；二是在多个尺寸上同时进行卷积再聚合。</p>
<p><strong>1、1x1卷积</strong></p>
<p>可以看到图1中有多个黄色的1x1卷积模块，这样的卷积有什么用处呢？</p>
<p><strong>作用1：</strong>在相同尺寸的感受野中叠加更多的卷积，能提取到更丰富的特征。这个观点来自于Network in Network(NIN, <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1312.4400.pdf">https://arxiv.org/pdf/1312.4400.pdf</a>)，图1里三个1x1卷积都起到了该作用。</p>
<p><img src= "/img/loading.gif" data-src="https://pic3.zhimg.com/80/v2-c98a6c44c6d943fb8dbacc29513dcf6e_720w.jpg" alt="img">图2:线性卷积和NIN结构对比</p>
<p>图2左侧是是传统的卷积层结构（线性卷积），在一个尺度上只有一次卷积；右图是Network in Network结构（NIN结构），先进行一次普通的卷积（比如3x3），紧跟再进行一次1x1的卷积，对于某个像素点来说1x1卷积等效于该像素点在所有特征上进行一次全连接的计算，所以右侧图的1x1卷积画成了全连接层的形式，需要注意的是NIN结构中无论是第一个3x3卷积还是新增的1x1卷积，后面都紧跟着激活函数（比如relu）。将两个卷积串联，就能组合出更多的非线性特征。举个例子，假设第1个3x3卷积＋激活函数近似于f1(x)=ax2+bx+c，第二个1x1卷积＋激活函数近似于f2(x)=mx2+nx+q，那f1(x)和f2(f1(x))比哪个非线性更强，更能模拟非线性的特征？答案是显而易见的。NIN的结构和传统的神经网络中多层的结构有些类似，后者的多层是跨越了不同尺寸的感受野（通过层与层中间加pool层），从而在更高尺度上提取出特征；NIN结构是在同一个尺度上的多层（中间没有pool层），从而在相同的感受野范围能提取更强的非线性。</p>
<p><strong>作用2：</strong></p>
<p>1x1卷积的主要目的是为了减少维度，还用于修正线性激活（ReLU）。比如，上一层的输出为100x100x128，经过具有256个通道的5x5卷积层之后(stride=1，pad=2)，输出数据为100x100x256，其中，卷积层的参数为128x5x5x256= 819200。而假如上一层输出先经过具有32个通道的1x1卷积层，再经过具有256个输出的5x5卷积层，那么输出数据仍为为100x100x256，但卷积参数量已经减少为128x1x1x32 + 32x5x5x256= 204800，大约减少了4倍。相应的，计算量也会大大的减少。</p>
<p><strong>2、多个尺寸上进行卷积再聚合</strong></p>
<p>图2可以看到对输入做了4个分支，分别用不同尺寸的filter进行卷积或池化，最后再在特征维度上拼接到一起。这种全新的结构有什么好处呢？Szegedy从多个角度进行了解释：</p>
<p><strong>解释1：</strong>在直观感觉上在多个尺度上同时进行卷积，能提取到不同尺度的特征。特征更为丰富也意味着最后分类判断时更加准确。</p>
<p><strong>解释2：</strong>利用稀疏矩阵分解成密集矩阵计算的原理来加快收敛速度。举个例子下图左侧是个稀疏矩阵（很多元素都为0，不均匀分布在矩阵中），和一个2x2的矩阵进行卷积，需要对稀疏矩阵中的每一个元素进行计算；如果像右图那样把稀疏矩阵分解成2个子密集矩阵，再和2x2矩阵进行卷积，稀疏矩阵中0较多的区域就可以不用计算，计算量就大大降低。<strong>这个原理应用到inception上就是要在特征维度上进行分解！</strong>传统的卷积层的输入数据只和一种尺度（比如3x3）的卷积核进行卷积，输出固定维度（比如256个特征）的数据，所有256个输出特征基本上是均匀分布在3x3尺度范围上，这可以理解成输出了一个稀疏分布的特征集；而inception模块在多个尺度上提取特征（比如1x1，3x3，5x5），输出的256个特征就不再是均匀分布，而是相关性强的特征聚集在一起（比如1x1的的96个特征聚集在一起，3x3的96个特征聚集在一起，5x5的64个特征聚集在一起），这可以理解成多个密集分布的子特征集。这样的特征集中因为相关性较强的特征聚集在了一起，不相关的非关键特征就被弱化，同样是输出256个特征，inception方法输出的特征“冗余”的信息较少。用这样的“纯”的特征集层层传递最后作为反向计算的输入，自然收敛的速度更快。</p>
<p><img src= "/img/loading.gif" data-src="https://pic4.zhimg.com/80/v2-eacad5957624f2b0dec823af256817cf_720w.jpg" alt="img">图4: 将稀疏矩阵分解成子密集矩阵来进行计算</p>
<p><strong>解释3：</strong>Hebbin赫布原理。Hebbin原理是神经科学上的一个理论，解释了在学习的过程中脑中的神经元所发生的变化，用一句话概括就是<em>fire togethter, wire together</em>。赫布认为“两个神经元或者神经元系统，如果总是同时兴奋，就会形成一种‘组合’，其中一个神经元的兴奋会促进另一个的兴奋”。比如狗看到肉会流口水，反复刺激后，脑中识别肉的神经元会和掌管唾液分泌的神经元会相互促进，“缠绕”在一起，以后再看到肉就会更快流出口水。用在inception结构中就是要把相关性强的特征汇聚到一起。这有点类似上面的解释2，把1x1，3x3，5x5的特征分开。因为训练收敛的最终目的就是要提取出独立的特征，所以预先把相关性强的特征汇聚，就能起到加速收敛的作用。</p>
<p>在inception模块中有一个分支使用了max pooling，作者认为pooling也能起到提取特征的作用，所以也加入模块中。注意这个pooling的stride=1，pooling后没有减少数据的尺寸。</p>
<p>（1）GoogLeNet采用了模块化的结构（Inception结构），方便增添和修改；<br>（2）网络最后采用了average pooling（平均池化）来代替全连接层，该想法来自NIN（Network in Network），事实证明这样可以将准确率提高0.6%。但是，实际在最后还是加了一个全连接层，主要是为了方便对输出进行灵活调整；<br>（3）虽然移除了全连接，但是网络中依然使用了Dropout ;<br>（4）为了避免梯度消失，网络额外增加了2个辅助的softmax用于向前传导梯度（辅助分类器）。辅助分类器是将中间某一层的输出用作分类，并按一个较小的权重（0.3）加到最终分类结果中，这样相当于做了模型融合，同时给网络增加了反向传播的梯度信号，也提供了额外的正则化，对于整个网络的训练很有裨益。而在实际测试的时候，这两个额外的softmax会被去掉。</p>
<p>GoogLeNet的网络结构图细节如下：<br><img src= "/img/loading.gif" data-src="https://static.oschina.net/uploads/space/2018/0317/141605_c1XW_876354.png" alt="img"><br>注：上表中的“#3x3 reduce”，“#5x5 reduce”表示在3x3，5x5卷积操作之前使用了1x1卷积的数量。</p>
<p>GoogLeNet网络结构明细表解析如下：<br><strong>0、输入</strong><br>原始输入图像为224x224x3，且都进行了零均值化的预处理操作（图像每个像素减去均值）。<br><strong>1、第一层（卷积层）</strong><br>使用7x7的卷积核（滑动步长2，padding为3），64通道，输出为112x112x64，卷积后进行ReLU操作<br>经过3x3的max pooling（步长为2），输出为((112 - 3+1)/2)+1=56，即56x56x64，再进行ReLU操作<br><strong>2、第二层（卷积层）</strong><br>使用3x3的卷积核（滑动步长为1，padding为1），192通道，输出为56x56x192，卷积后进行ReLU操作<br>经过3x3的max pooling（步长为2），输出为((56 - 3+1)/2)+1=28，即28x28x192，再进行ReLU操作<br><strong>3a、第三层（Inception 3a层）</strong><br>分为四个分支，采用不同尺度的卷积核来进行处理<br>（1）64个1x1的卷积核，然后RuLU，输出28x28x64<br>（2）96个1x1的卷积核，作为3x3卷积核之前的降维，变成28x28x96，然后进行ReLU计算，再进行128个3x3的卷积（padding为1），输出28x28x128<br>（3）16个1x1的卷积核，作为5x5卷积核之前的降维，变成28x28x16，进行ReLU计算后，再进行32个5x5的卷积（padding为2），输出28x28x32<br>（4）pool层，使用3x3的核（padding为1），输出28x28x192，然后进行32个1x1的卷积，输出28x28x32。<br>将四个结果进行连接，对这四部分输出结果的第三维并联，即64+128+32+32=256，最终输出28x28x256<br><strong>3b、第三层（Inception 3b层）</strong><br>（1）128个1x1的卷积核，然后RuLU，输出28x28x128<br>（2）128个1x1的卷积核，作为3x3卷积核之前的降维，变成28x28x128，进行ReLU，再进行192个3x3的卷积（padding为1），输出28x28x192<br>（3）32个1x1的卷积核，作为5x5卷积核之前的降维，变成28x28x32，进行ReLU计算后，再进行96个5x5的卷积（padding为2），输出28x28x96<br>（4）pool层，使用3x3的核（padding为1），输出28x28x256，然后进行64个1x1的卷积，输出28x28x64。<br>将四个结果进行连接，对这四部分输出结果的第三维并联，即128+192+96+64=480，最终输出输出为28x28x480</p>
<p>第四层（4a,4b,4c,4d,4e）、第五层（5a,5b）……，与3a、3b类似，在此就不再重复。</p>
<h2 id="二、论文关键点解析"><a href="#二、论文关键点解析" class="headerlink" title="二、论文关键点解析"></a>二、论文关键点解析</h2><p><strong>Page 3:</strong>The fundamental way of solving both issues would be by ultimately moving from fully connected to sparsely connected architectures, even inside the convolutions. Besides mimicking biological systems, this would also have the advantage of firmer theoretical underpinnings due to the ground-breaking work of Arora et al. [2]. Their main result states that if the probability distribution of the data-set is representable by a large, very sparse deep neural network, then the optimal network topology can be constructed layer by layer by analyzing the correlation statistics of the activations of the last layer and clustering neurons with highly correlated outputs.</p>
<p>作者提出需要将全连接的结构转化成稀疏连接的结构。稀疏连接有两种方法，一种是空间（spatial）上的稀疏连接，也就是传统的CNN卷积结构：只对输入图像的某一部分patch进行卷积，而不是对整个图像进行卷积，共享参数降低了总参数的数目减少了计算量；另一种方法是在特征（feature）维度进行稀疏连接，就是前一节提到的在多个尺寸上进行卷积再聚合，把相关性强的特征聚集到一起，每一种尺寸的卷积只输出256个特征中的一部分，这也是种稀疏连接。作者提到这种方法的理论基础来自于Arora et al的论文Provable bounds for learning some deep representations（Arora et al这篇论文数学要求太高了，没读懂）。</p>
<p><strong>Page3:</strong>On the downside, todays computing infrastructures are very inefficient when it comes to numerical calculation on non-uniform sparse data structures. Even if the number of arithmetic operations is reduced by100×, the overhead of lookups and cache misses is so dominant that switching to sparse matrices would not pay off. The gap is widened even further by the use of steadily improving, highly tuned, numerical libraries that allow for extremely fast dense matrix multiplication, exploit-ing the minute details of the underlying CPU or GPU hardware [16,9]. Also, non-uniform sparse models require more sophisticated engineering and computing infrastructure. Most current vision oriented machine learning systems utilize sparsity in the spatial domain just by the virtue of employing convolutions. However, convolutions are implemented as collections of dense connections to the patches in the earlier layer. ConvNets have traditionally used random and sparse connection tables in the feature dimensions since [11] in order to break the symmetry and improve learning, the trend changed back to full connections with [9] in order to better optimize parallel computing. The uniformity of the structure and a large number of filters and greater batch size allow for utilizing efficient dense computation.</p>
<p>作者提到如今的计算机对稀疏数据进行计算的效率是很低的，即使使用稀疏矩阵算法也得不偿失（见笔者图4描述的计算方法，注意图4左侧的那种稀疏矩阵在计算机内部都是使用元素值＋行列值的形式来存储，只存储非0元素）。使用稀疏矩阵算法来进行计算虽然计算量会大大减少，但会增加中间缓存（具体原因请研究稀疏矩阵的计算方法）。</p>
<p>当今最常见的利用数据稀疏性的方法是通过卷积对局部patch进行计算（CNN方法，就是前面提到的在spatial上利用稀疏性）；另一种利用数据稀疏性的方法是在特征维度进行利用，比如ConvNets结构，它使用特征连接表来决定哪些卷积的输出才累加到一起（普通结构使用一个卷积核对所有输入特征做卷积，再将所有结果累加到一起，输出一个特征； 而ConvNets是选择性的对某些卷积结果做累加）。ConvNets利用稀疏性的方法现在已经很少用了，因为只有在特征维度上进行全连接才能更高效的利用gpu的并行计算的能力，否则你就得为这样的特征连接表单独设计cuda的接口函数，单独设计的函数往往无法最大限度的发挥gpu并行计算的能力。</p>
<p><strong>Page 4:</strong>This raises the question whether there is any hope for a next, intermediate step: an architecture that makes use of the extra sparsity, even at filter level, as suggested by the theory, but exploits our current hardware by utilizing computations on dense matrices. The vast literature on sparse matrix computations (e.g. [3]) suggests that clustering sparse matrices into relatively dense submatrices tends to give state of the art practical performance for sparse matrix multiplication.</p>
<p>前面提到ConvNets这样利用稀疏性的方法现在已经很少用了，那还有什么方法能在特征维度上利用稀疏性么？这就引申出了这篇论文的重点：将相关性强的特征汇聚到一起，也就是上一章提到的在多个尺度上卷积再聚合。</p>
<p><strong>Page 6:</strong>The use of average pooling before the classifier is based on [12], although our implementation differs in that we use an extra linear layer.</p>
<p>Network in Network(NIN, <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1312.4400.pdf">https://arxiv.org/pdf/1312.4400.pdf</a>)最早提出了用Global Average Pooling（GAP）层来代替全连接层的方法，具体方法就是对每一个feature上的所有点做平均，有n个feature就输出n个平均值作为最后的softmax的输入。它的好处：1、对数据在整个feature上作正则化，防止了过拟合；2、不再需要全连接层，减少了整个结构参数的数目（一般全连接层是整个结构中参数最多的层），过拟合的可能性降低；3、不用再关注输入图像的尺寸，因为不管是怎样的输入都是一样的平均方法，传统的全连接层要根据尺寸来选择参数数目，不具有通用性。</p>
<p><strong>Page 6:</strong>By adding auxiliary classifiers connected to these intermediate layers, we would expect to encourage discrimination in the lower stages in the classifier, increase the gradient signal that gets propagated back, and provide additional regularization.</p>
<p>inception结构在在某些层级上加了分支分类器，输出的loss乘以个系数再加到总的loss上，作者认为可以防止梯度消失问题（事实上在较低的层级上这样处理基本没作用，作者在后来的inception v3论文中做了澄清）。</p>
<blockquote>
<p>参考：</p>
<p><a href="https://www.bilibili.com/video/BV1B7411L7Qt" target="_blank" rel="noopener">北京大学软件与微电子学院曹健老师的Tensorflow2.0</a><br><a href="https://zhuanlan.zhihu.com/p/32702031" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/32702031</a><br><a href="https://my.oschina.net/u/876354/blog/1637819" target="_blank" rel="noopener">https://my.oschina.net/u/876354/blog/1637819</a></p>
</blockquote>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script></div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Seven</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://hansuyu.com/2020/06/772168442.html">http://hansuyu.com/2020/06/772168442.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://hansuyu.com" target="_blank">愿风载尘</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/han-suyu/cover/61.jpg" data-sites="wechat,weibo,qq,facebook,twitter"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><button class="reward-button"><i class="fas fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="post-qr-code__img" src="/img/wechat.jpg" alt="微信" onclick="window.open('/img/wechat.jpg')"/><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="post-qr-code__img" src="/img/wechat.jpg" alt="支付宝" onclick="window.open('/img/wechat.jpg')"/><div class="post-qr-code__desc">支付宝</div></li></ul></div></button></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2020/06/670302972.html"><img class="next-cover" data-src="https://cdn.jsdelivr.net/gh/han-suyu/cover/13.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">基于LeNet模型实现MNIST手写体数据集的训练</div></div></a></div></nav><hr><div id="post-comment"><div class="comment_headling"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div><div class="vcomment" id="vcomment"></div><script src="https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js"></script><script>var requestSetting = function (from,set) {
  var from = from
  var setting = set.split(',').filter(function(item){
  return from.indexOf(item) > -1
  });
  setting = setting.length == 0 ? from :setting;
  return setting
}

var guestInfo = requestSetting(['nick','mail','link'],'nick,mail')
var requiredFields = requestSetting(['nick','mail'],'nick,mail')

window.valine = new Valine({
  el:'#vcomment',
  appId: 'a9HNNTF9yMcoVFJrKlLyoaAY-gzGzoHsz',
  appKey: 'utzaiW0SY0JMcLNyWSQUhU0o',
  placeholder: '使用QQ号作为昵称会自动加载你的邮箱与头像哦~',
  avatar: 'wavatar',
  meta: guestInfo,
  pageSize: '10',
  lang: 'zh-CN',
  recordIP: true,
  serverURLs: '',
  emojiCDN: '',
  emojiMaps: "",
  enableQQ: true,
  requiredFields: requiredFields
});</script></div></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2020 By Seven</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><button id="readmode" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font_plus" title="放大字体"><i class="fas fa-plus"></i></button><button id="font_minus" title="缩小字体"><i class="fas fa-minus"></i></button><button class="translate_chn_to_cht" id="translateLink" title="简繁转换">简</button><button id="darkmode" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" title="设置"><i class="fas fa-cog"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fas fa-comments"></i></a><button class="close" id="mobile-toc-button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div class="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module" defer></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js" async></script><script src="https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js"></script><script>document.addEventListener('DOMContentLoaded', function() {
  pangu.autoSpacingPage()
})</script><script src="/js/search/local-search.js"></script></body></html>