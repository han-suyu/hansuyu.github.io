<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>卷积：如何成为一个很厉害的神经网络 | 明天又是周六了</title><meta name="robots" content="noindex"><meta name="description" content="什么是卷积神经网络？又为什么很重要？ 卷积神经网络(Convolutional Neural Networks, ConvNets or CNNs)是一种在图像识别与分类领域被证明特别有效的神经网络。卷积网络已经成功地识别人脸、物体、交通标志，应用在机器人和无人车等载具。  在上面的图1当中，卷积网络能够识别场景而系统可以自动推荐相关标签（如一个足球运动员正在踢球）。图2则展示了卷积网络识别日常"><meta name="keywords" content="学习总结"><meta name="author" content="Seven"><meta name="copyright" content="Seven"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://hansuyu.com/2020/06/3272311197.html"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//ta.qq.com"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="preconnect" href="//zz.bdstatic.com"/><meta name="google-site-verification" content="u9AaJlYHNmU4dpUtiWPMA9_vQRU4zjcERKUymU8aEao"/><meta name="baidu-site-verification" content="m7BzC4y6nU"/><meta property="og:type" content="article"><meta property="og:title" content="卷积：如何成为一个很厉害的神经网络"><meta property="og:url" content="http://hansuyu.com/2020/06/3272311197.html"><meta property="og:site_name" content="明天又是周六了"><meta property="og:description" content="什么是卷积神经网络？又为什么很重要？ 卷积神经网络(Convolutional Neural Networks, ConvNets or CNNs)是一种在图像识别与分类领域被证明特别有效的神经网络。卷积网络已经成功地识别人脸、物体、交通标志，应用在机器人和无人车等载具。  在上面的图1当中，卷积网络能够识别场景而系统可以自动推荐相关标签（如一个足球运动员正在踢球）。图2则展示了卷积网络识别日常"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/han-suyu/cover/33.jpg"><meta property="article:published_time" content="2020-06-24T11:31:15.000Z"><meta property="article:modified_time" content="2020-07-03T12:11:12.520Z"><meta name="twitter:card" content="summary"><script>var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#000')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#fff')
  }
}

var getCookies = function (name) {
  const value = `; ${document.cookie}`
  const parts = value.split(`; ${name}=`)
  if (parts.length === 2) return parts.pop().split(';').shift()
}

var autoChangeMode = 'false'
var t = getCookies('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (Cookies.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8a00fdda614f4a870fbc5f2d54aa8666";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script src="https://tajs.qq.com/stats?sId=66574834" charset="UTF-8"></script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  translate: {"defaultEncoding":1,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: {"languages":{"author":"作者: Seven","link":"链接: ","source":"来源: 明天又是周六了","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: {"bookmark":{"message_prev":"按","message_next":"键将本页加入书签"},"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#2d3035","position":"top-center"},
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: true,
  highlightCopy: true,
  highlightLang: true,
  isPhotoFigcaption: true,
  islazyload: true,
  isanchor: false    
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: true,
  isSidebar: true
  }</script><noscript><style>
#nav {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@latest/butterfly/css/flink.min.css"><link rel="stylesheet" href="/css/my.css"><link rel="stylesheet" href="http://at.alicdn.com/t/font_1927020_azxlhjmymca.css"><link href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css" rel="stylesheet" type="text/css"><meta name="generator" content="Hexo 4.2.1"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">160</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">34</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">20</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-calendar"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tag"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/photos/"><i class="fa-fw fa fa-camera"></i><span> 相册</span></a></div><div class="menus_item"><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> 电影</span></a></div><div class="menus_item"><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></div><div class="menus_item"><a class="site-page" href="/artitalk/"><i class="fa-fw fa fa-edit"></i><span> 心情</span></a></div><div class="menus_item"><a class="site-page" href="/toolbox/"><i class="fa-fw fa fa-leaf"></i><span> 小工具</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-institution"></i><span> 实验室</span><i class="fas fa-chevron-down menus-expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/color/"><i class="fa-fw fa fa-magic"></i><span> RGB颜色</span></a></li><li><a class="site-page" href="/hexconvert/"><i class="fa-fw fa fa-calculator"></i><span> 进制转换</span></a></li><li><a class="site-page" href="/diff/"><i class="fa-fw fa fa-clone"></i><span> 文本对比</span></a></li><li><a class="site-page" href="/map/"><i class="fa-fw fa fa-globe"></i><span> 地球图层</span></a></li><li><a class="site-page" href="/dog/"><i class="fa-fw fa fa-heartbeat"></i><span> 舔狗日记</span></a></li></ul></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-game"></i><span> 小游戏</span><i class="fas fa-chevron-down menus-expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/Sudoku/"><span> 数独</span></a></li><li><a class="site-page" href="/jumper/"><span> 跳一跳</span></a></li><li><a class="site-page" href="/puzzleNumber/"><span> 数字拼图</span></a></li><li><a class="site-page" href="/referrence/"><span> referrence</span></a></li></ul></div></div></div></div><i class="fas fa-arrow-right" id="toggle-sidebar"></i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#什么是卷积神经网络又为什么很重要"><span class="toc-text"> 什么是卷积神经网络？又为什么很重要？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lenet架构1990年代"><span class="toc-text"> LeNet架构(1990年代）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#图片是像素值的矩阵"><span class="toc-text"> 图片是像素值的矩阵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#卷积"><span class="toc-text"> 卷积</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#非线性"><span class="toc-text"> 非线性</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#池化"><span class="toc-text"> 池化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#全连接层"><span class="toc-text"> 全连接层</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#联合起来反向传播训练"><span class="toc-text"> 联合起来——反向传播训练</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#可视化卷积神经网络"><span class="toc-text"> 可视化卷积神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#其他卷积网络架构"><span class="toc-text"> 其他卷积网络架构</span></a></li></ol></div></div></div><div class="code-close" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://cdn.jsdelivr.net/gh/han-suyu/cover/33.jpg)"><nav id="nav"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/">明天又是周六了</a></span><span class="pull-right menus"><div id="search_button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-calendar"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tag"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/photos/"><i class="fa-fw fa fa-camera"></i><span> 相册</span></a></div><div class="menus_item"><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> 电影</span></a></div><div class="menus_item"><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></div><div class="menus_item"><a class="site-page" href="/artitalk/"><i class="fa-fw fa fa-edit"></i><span> 心情</span></a></div><div class="menus_item"><a class="site-page" href="/toolbox/"><i class="fa-fw fa fa-leaf"></i><span> 小工具</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-institution"></i><span> 实验室</span><i class="fas fa-chevron-down menus-expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/color/"><i class="fa-fw fa fa-magic"></i><span> RGB颜色</span></a></li><li><a class="site-page" href="/hexconvert/"><i class="fa-fw fa fa-calculator"></i><span> 进制转换</span></a></li><li><a class="site-page" href="/diff/"><i class="fa-fw fa fa-clone"></i><span> 文本对比</span></a></li><li><a class="site-page" href="/map/"><i class="fa-fw fa fa-globe"></i><span> 地球图层</span></a></li><li><a class="site-page" href="/dog/"><i class="fa-fw fa fa-heartbeat"></i><span> 舔狗日记</span></a></li></ul></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-game"></i><span> 小游戏</span><i class="fas fa-chevron-down menus-expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/Sudoku/"><span> 数独</span></a></li><li><a class="site-page" href="/jumper/"><span> 跳一跳</span></a></li><li><a class="site-page" href="/puzzleNumber/"><span> 数字拼图</span></a></li><li><a class="site-page" href="/referrence/"><span> referrence</span></a></li></ul></div></div><span class="toggle-menu close"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">卷积：如何成为一个很厉害的神经网络</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2020-06-24 19:31:15"><i class="far fa-calendar-alt fa-fw"></i> 发表于 2020-06-24</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2020-07-03 20:11:12"><i class="fas fa-history fa-fw"></i> 更新于 2020-07-03</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fas fa-inbox fa-fw post-meta__icon"></i><a class="post-meta__categories" href="/categories/Machine-Learning/">Machine Learning</a></span></div><div class="meta-secondline"> <span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta__icon"></i><span>字数总计:</span><span class="word-count">4.8k</span><span class="post-meta__separator">|</span><i class="far fa-clock fa-fw post-meta__icon"></i><span>阅读时长: 14 分钟</span></span></div><div class="meta-thirdline"><span class="post-meta-pv-cv"><span class="post-meta__separator">|</span><i class="far fa-eye fa-fw post-meta__icon"></i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"><span class="post-meta__separator">|</span><i class="far fa-comments fa-fw post-meta__icon"></i><span>评论数:</span><a href="/2020/06/3272311197.html#post-comment" itemprop="discussionUrl"><span class="valine-comment-count comment-count" data-xid="/2020/06/3272311197.html" itemprop="commentCount"></span></a></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h2 id="什么是卷积神经网络又为什么很重要"><a class="markdownIt-Anchor" href="#什么是卷积神经网络又为什么很重要"></a> 什么是卷积神经网络？又为什么很重要？</h2>
<p>卷积神经网络(Convolutional Neural Networks, ConvNets or CNNs)是一种在图像识别与分类领域被证明特别有效的神经网络。卷积网络已经成功地识别人脸、物体、交通标志，应用在机器人和无人车等载具。</p>
<p><img src= "/img/loading.gif" data-src="https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2017-05-28-at-11-41-55-pm.png?w=1024" alt="图1" /></p>
<p>在上面的<strong>图1</strong>当中，卷积网络能够识别场景而系统可以自动推荐相关标签（如一个足球运动员正在踢球）。<strong>图2</strong>则展示了卷积网络识别日常事物如人、动物的例子。最近，卷积网络也已经在自然语言处理上显示出了威力（比如句子分类）。</p>
<p><img src= "/img/loading.gif" data-src="https://pic2.zhimg.com/80/v2-8404ab90cd524d9cd3e6a1b326763b19_720w.png" alt="图2" /></p>
<p>卷积网络，在今天的绝大多数机器学习应用中都是极重要的工具。但是，理解卷积网络并首次学着使用，这体验有时并不友好。本文的主旨在于帮助读者理解，卷积神经网络是如何作用于图片的。</p>
<p>在本文，多层感知机(Multi-Layer Perceptrons, MLP)也被记作全连接层(Fully Connected Layers)。</p>
<h2 id="lenet架构1990年代"><a class="markdownIt-Anchor" href="#lenet架构1990年代"></a> LeNet架构(1990年代）</h2>
<p>LeNet是最早用于深度学习了领域的卷积神经网络之一。Yann LeCun的这一杰作LeNet5得名于他自1988年以来的系列成功迭代。彼时LeNet架构还主要被用于识别邮政编码等任务。</p>
<p>下面我们将直观地感受一下，LeNet是如何学习识别图像的。近几年已经出现了很多建立在LeNet之上的新架构，但是基本概念还是来自于LeNet，并且理解了LeNet再学其他的也会更简单。</p>
<p><img src= "/img/loading.gif" data-src="https://pic1.zhimg.com/80/v2-38f71f3d4d0baac609d1cc6fe6f22a74_720w.png" alt="图3：简单的ConvNet" /></p>
<p><strong>图3</strong>的卷积神经网络与LeNet的原始架构十分接近，把图片分入四个类别：狗，猫，船，鸟（LeNet最早主要就是用来做这些）。如上图所示，当获得一张船图作为输入的时候，网络正确的给船的分类赋予了最高的概率(0.94)。输出层的各个概率相加应为1.</p>
<p><strong>图3</strong>的卷积神经网络主要执行了四个操作：</p>
<ol>
<li>卷积</li>
<li>非线性(ReLU)</li>
<li>池化或下采样</li>
<li>分类（全连接层）</li>
</ol>
<p>这些操作也是所有卷积神经网络的基石，所以理解好这些工作对于理解整个神经网络至关重要。接下来我们将尝试最直观地理解以上操作。</p>
<h2 id="图片是像素值的矩阵"><a class="markdownIt-Anchor" href="#图片是像素值的矩阵"></a> 图片是像素值的矩阵</h2>
<p>本质上来讲，每个图片都可以表示为像素值组成的矩阵：</p>
<p><img src= "/img/loading.gif" data-src="https://ujwlkarn.files.wordpress.com/2016/08/8-gif.gif?w=192&amp;h=192" alt="图4：像素值矩阵" /></p>
<p><strong>通道</strong>是代指图片特定成分的习语。常见数码相机拍出来的照片有三个通道——红、绿、蓝-可以想象为是三个2d矩阵（每种颜色对应一个）叠在一起，每个矩阵的值都在0-255之间。</p>
<p>另一方面，<strong>灰度</strong>图像只有单通道。本文为简单起见只考虑灰度图像，这样就是一个2d矩阵。矩阵中的每个像素值还是0到255——0表示黑，255表示白。</p>
<h2 id="卷积"><a class="markdownIt-Anchor" href="#卷积"></a> 卷积</h2>
<p>卷积网络是因为**“卷积”操作**而得名的。卷积的根本目的是从输入图片中提取特征。卷积用一个小方阵的数据学习图像特征，可以保留像素之间的空间关系。这里不深入探讨卷积的数学原理，重在理解工作过程。</p>
<p>如上所述，每个图片都是像素值矩阵。考虑一个5x5的图像，其像素值为0和1，下面的绿色矩阵是灰度图的特例（常规灰度图的像素值取值0-255），同时考虑如下的3x3矩阵：</p>
<p><img src= "/img/loading.gif" data-src="https://pic1.zhimg.com/80/v2-add89dece41a5210a24b91f8f2af03e4_720w.png" alt="" /></p>
<p>然后，5x5图像和3x3矩阵之间的卷积计算，可由下图的动画所表示：</p>
<p><img src= "/img/loading.gif" data-src="https://ujwlkarn.files.wordpress.com/2016/07/convolution_schematic.gif?w=268&amp;h=196" alt="图5：卷积操作。输出矩阵叫卷积特征或特征映射" /></p>
<p>想一想以上操作是如何完成的，我们在原始图片（绿色）上1像素、1像素地滑动橙色矩阵（也称’stride’），并且在每个位置上，我们都对两个矩阵的对应元素相乘后求和得到一个整数，这就是输出矩阵（粉色）的元素。注意，3x3矩阵每次只“看见”输入图片的一部分。</p>
<p>3x3矩阵也叫“<strong>滤波器</strong>”、“核”或“特征探测器”，在原图上滑动滤波器、点乘矩阵所得的矩阵称为“卷积特征”、“激励映射”或“<strong>特征映射</strong>”。这里的重点就是，理解滤波器对于原输入图片来说，是个特征探测器。</p>
<p>对于同一张照片，不同的滤波器将会产生不同的特征映射。比如考虑下面这张输入图片：</p>
<p><img src= "/img/loading.gif" data-src="https://pic3.zhimg.com/80/v2-dbba2a167aec7a158d145004f98393b2_720w.jpg" alt="" /></p>
<p>下表可见各种不同卷积核对于上图的效果。只需调整滤波器的数值，我们就可以执行诸如边缘检测、锐化、模糊等效果——这说明不同的滤波器会从图片中探测到不同的特征，比如边缘、曲线等。</p>
<p><img src= "/img/loading.gif" data-src="https://pic1.zhimg.com/80/v2-034c6058037c03c544955111a749c280_720w.png" alt="" /></p>
<p>另一种对卷积操作很好的理解方式就是观察<strong>图6</strong>的动画：</p>
<p><img src= "/img/loading.gif" data-src="https://ujwlkarn.files.wordpress.com/2016/08/giphy.gif?w=748" alt="图6：卷积运算" /></p>
<p>一个滤波器（红框）在图片上滑动（卷积）产生特征映射。在同一个图片上，另一个滤波器（绿框）的卷积产生了不同的特征映射。须知，卷积操作捕捉的是原图的局部依赖性。另外，注意观察两个不同的滤波器怎样产生不同的特征映射。其实不管是图片，还是两个滤波器，本质上都不过是我们刚才看过的数值矩阵而已。</p>
<p>在实践当中，卷积神经网络在训练过程中学习滤波器的值，当然我们还是要在训练之前需要指定一些参数：滤波器的个数，滤波器尺寸、网络架构等等。滤波器越多，从图像中提取的特征就越多，模式识别能力就越强。</p>
<p>特征映射的尺寸由三个参数控制，我们需要在卷积步骤之前就设定好：</p>
<ul>
<li>深度(Depth)： 深度就是卷积操作中用到的滤波器个数。如<strong>图7</strong>所示，我们对原始的船图用了三个不同的滤波器，从而产生了三个特征映射。你可以认为这三个特征映射也是堆叠的2d矩阵，所以这里特征映射的“深度”就是3。</li>
</ul>
<p><img src= "/img/loading.gif" data-src="https://pic2.zhimg.com/80/v2-6388221cc6d20c9c3a1298e5baa8793d_720w.png" alt="图7" /></p>
<ul>
<li>步幅(Stride)：步幅是每次滑过的像素数。当Stride=1的时候就是逐个像素地滑动。当Stride=2的时候每次就会滑过2个像素。步幅越大，特征映射越小。</li>
<li>补零(Zero-padding)：有时候在输入矩阵的边缘填补一圈0会很方便，这样我们就可以对图像矩阵的边缘像素也施加滤波器。补零的好处是让我们可以控制特征映射的尺寸。补零也叫宽卷积，不补零就叫窄卷积。</li>
</ul>
<h2 id="非线性"><a class="markdownIt-Anchor" href="#非线性"></a> 非线性</h2>
<p>如<strong>图3</strong>所示，每个卷积操作之后，都有一个叫<strong>ReLU</strong>的附加操作。ReLU的全称是纠正线性单元(Rectified Linear Unit)，是一种非线性操作，其输出如下：</p>
<p><img src= "/img/loading.gif" data-src="https://pic1.zhimg.com/80/v2-c8afbf19afabcfccb1d0f27ac5f7eed0_720w.png" alt="图8：ReLU" /></p>
<p>ReLU是以像素为单位生效的，其将所有负值像素替换为0。ReLU的目的是向卷积网络中引入非线性，因为真实世界里大多数需要学习的问题都是非线性的（单纯的卷积操作时线性的——矩阵相乘、相加，所以才需要额外的计算引入非线性）。</p>
<p>图9可以帮助我们清晰地理解，ReLU应用在<strong>图6</strong>得到的特征映射上，输出的新特征映射也叫“纠正”特征映射。（黑色被抹成了灰色）</p>
<p><img src= "/img/loading.gif" data-src="https://pic4.zhimg.com/80/v2-9feb833b3e855d9d282fce472429311b_720w.png" alt="图9：ReLU" /></p>
<p>其他非线性方程比如<strong>tanh</strong>或<strong>sigmoid</strong>也可以替代ReLU，但多数情况下ReLU的表现更好。</p>
<h2 id="池化"><a class="markdownIt-Anchor" href="#池化"></a> 池化</h2>
<p>空间池化（也叫亚采样或下采样）降低了每个特征映射的维度，但是保留了最重要的信息。空间池化可以有很多种形式：最大(Max)，平均(Average)，求和(Sum)等等。</p>
<p>以最大池化为例，我们定义了空间上的邻域（2x2的窗）并且从纠正特征映射中取出窗里最大的元素。除了取最大值以额外，我们也可以取平均值（平均池化）或者把窗里所有元素加起来。实际上，最大池化已经显示了最好的成效。</p>
<p><strong>图10</strong>显示了对纠正特征映射的最大池化操作（在卷积+ReLU之后），使用的是2x2的窗。</p>
<p><img src= "/img/loading.gif" data-src="https://pic3.zhimg.com/80/v2-97065f08e3bb34c4e42e223636cc5b0e_720w.png" alt="图10：最大池化" /></p>
<p>我们以2格的步幅(Stride)滑动2x2的窗，并且取每个区域的最大值。<strong>图10</strong>同样显示了池化可以减少特征映射的维度。</p>
<p>在<strong>图11</strong>所示的网络中，池化操作分别应用于每个特征映射（注意正因如此，我们从三个输入映射得到了三个输出映射）。</p>
<p><img src= "/img/loading.gif" data-src="https://pic4.zhimg.com/80/v2-22eebe9b4d2b2070815c7d571cc94e83_720w.png" alt="图11：对纠正特征映射应用池化" /></p>
<p><strong>图12</strong>即为池化操作施加在<strong>图9</strong>所得纠正特征映射上的效果。</p>
<p><img src= "/img/loading.gif" data-src="https://pic2.zhimg.com/80/v2-b8e2a2e05956b1b4191f853c2c65befd_720w.png" alt="图12：池化" /></p>
<p>池化的功能室逐步减少输入表征的空间尺寸。特别地，池化</p>
<ul>
<li>使输入表征（特征维度）更小而易操作</li>
<li>减少网络中的参数与计算数量，从而遏制过拟合</li>
<li>增强网络对输入图像中的小变形、扭曲、平移的鲁棒性（输入里的微小扭曲不会改变池化输出——因为我们在局部邻域已经取了最大值/平均值）。</li>
<li>帮助我们获得不因尺寸而改变的等效图片表征。这非常有用，因为这样我们就可以探测到图片里的物体，不论那个物体在哪。</li>
</ul>
<p>截至目前：</p>
<p><img src= "/img/loading.gif" data-src="https://pic3.zhimg.com/80/v2-cfd915e11fa53fbeb7a41716f3c1a236_720w.png" alt="图13" /></p>
<p>至此我们已经了解了卷积、ReLU和池化是如何运转的，这些层对于所有的卷积神经网络都是最基础的单元。如<strong>图13</strong>所示，我们有两组“卷积+ReLU+池化”层——其中第二组对第一组的输出施加了六个滤波器，产生了六个特征映射。ReLU分别作用域这六个特征映射，再对生成的纠正特征映射使用最大池化。</p>
<p>这些层合力提取出有用的特征，为网络引入了非线性并降低了维度，还使特征对尺寸和平移保持不变性。</p>
<p>第二个池化层的输出相当于全连接层的输入，我们将在下一节继续探讨。</p>
<h2 id="全连接层"><a class="markdownIt-Anchor" href="#全连接层"></a> 全连接层</h2>
<p>全连接层(Fully Connected layer)就是使用了softmax激励函数作为输出层的多层感知机(Multi-Layer Perceptron)，其他很多分类器如支持向量机也使用了softmax。“全连接”表示上一层的每一个神经元，都和下一层的每一个神经元是相互连接的。</p>
<p>卷积层和池化层呢个的输出代表了输入图像的高级特征，全连接层的目的就是用这些特征进行分类，类别基于训练集。比如图14所示的图像分类任务，有四种可能的类别。（注意，图14没有显示出所有的神经元节点）</p>
<p><img src= "/img/loading.gif" data-src="https://pic1.zhimg.com/80/v2-45a9987d6c4838c4c8a24c1b3a4ce7d8_720w.png" alt="图14：全连接层——每个节点都与相邻层的所有节点相连" /></p>
<p>除了分类以外，加入全连接层也是学习特征之间非线性组合的有效办法。卷积层和池化层提取出来的特征很好，但是如果考虑这些特征之间的组合，就更好了。</p>
<p>全连接层的输出概率之和为1，这是由激励函数Softmax保证的。Softmax函数把任意实值的向量转变成元素取之0-1且和为1的向量。</p>
<h2 id="联合起来反向传播训练"><a class="markdownIt-Anchor" href="#联合起来反向传播训练"></a> 联合起来——反向传播训练</h2>
<p>综上，卷积+池化是特征提取器，全连接层是分类器。</p>
<p>注意<strong>图15</strong>，因为输入图片是条船，所以目标概率对船是1，其他类别是0.</p>
<ul>
<li>输入图像 = 船</li>
<li>目标向量 = [0, 0, 1 ,0]</li>
</ul>
<p><img src= "/img/loading.gif" data-src="https://pic3.zhimg.com/80/v2-73cc788cfc81dfe5411c82cd53b007be_720w.png" alt="图15：训练卷积神经网络" /></p>
<p>卷积网络的训练过程可以概括如下：</p>
<p><strong>Step 1:</strong> 用随机数初始化所有的滤波器和参数/权重</p>
<ul>
<li>
<p><strong>Step 2:</strong> 网络将训练图片作为输入，执行前向步骤（卷积，ReLU，池化以及全连接层的前向传播）并计算每个类别的对应输出概率。</p>
<ul>
<li>假设船图的输出概率是[0.2, 0.4, 0.1, 0.3]</li>
<li>因为第一个训练样本的权重都是随机的，所以这个输出概率也跟随机的差不多</li>
</ul>
</li>
<li>
<p><strong>Step 3:</strong> 计算输出层的总误差（4类别之和）</p>
<ul>
<li><strong>总误差=∑12(目标概率−输出概率)2总误差=∑12(目标概率−输出概率)2</strong></li>
</ul>
</li>
<li>
<p><strong>Step 4:</strong> 反向传播算法计算误差相对于所有权重的梯度，并用<em>梯度下降法</em>更新所有的滤波器/权重和参数的值，以使输出误差最小化。</p>
</li>
<li>
<ul>
<li>权重的调整程度与其对总误差的贡献成正比。</li>
<li>当同一图像再次被输入，这次的输出概率可能是[0.1, 0.1, 0.7, 0.1]，与目标[0, 0, 1, 0]更接近了。</li>
<li>这说明我们的神经网络已经学习着分类特定图片了，学习的方式是调整权重/滤波器以降低输出误差。</li>
<li>如滤波器个数、滤波器尺寸、网络架构这些参数，是在Step 1之前就已经固定的，且不会在训练过程中改变——只有滤波矩阵和神经元突触权重会更新。</li>
</ul>
</li>
</ul>
<p>以上步骤<em>训练</em>了卷积网络——本质上就是优化所有的权重和参数，使其能够正确地分类训练集里的图片。</p>
<p>当一个新的（前所未见的）的图片输入至卷积网络，网络会执行前向传播步骤并输出每个类别的概率（对于新图像，输出概率用的也是训练过的权重值）。如果我们的训练集足够大，网络就有望正确分类新图片，获得良好的泛化(generalization)能力。</p>
<p><strong>注意 1:</strong> 以上步骤已被极大简化，且数学细节均以忽略，这是为了让训练过程更直观。</p>
<p><strong>注意 2:</strong> 上例中，我们用了两组卷积+池化层，其实这些操作可以在一个卷积网络内重复无数次。如今有些表现出众的卷积网络，都有数以十计的卷积+池化层！并且，不是每个卷积层后面都要跟个池化层。由<strong>图16</strong>可见，我们可以有连续多组卷积+ReLU层，后面再加一个池化层。</p>
<p><img src= "/img/loading.gif" data-src="https://pic3.zhimg.com/80/v2-36df4a5bf0be915e0ed2ea085f69de32_720w.png" alt="图16" /></p>
<h2 id="可视化卷积神经网络"><a class="markdownIt-Anchor" href="#可视化卷积神经网络"></a> 可视化卷积神经网络</h2>
<p>一般来说，卷积层越多，能学会的特征也就越复杂。比如在图像分类中，一个卷积神经网络的第一层学会了探测像素中的边缘，然后第二层用这些边缘再去探测简单的形状，其他层再用形状去探测高级特征，比如脸型，如<strong>图17</strong>所示——这些特征是<a href="https://web.eecs.umich.edu/~honglak/icml09-ConvolutionalDeepBeliefNetworks.pdf" target="_blank" rel="noopener external nofollow noreferrer">Convolutional Deep Belief Network</a>学得的。这里只是一个简单的例子，实际上卷积滤波器可能会探测出一些没有意义的特征。</p>
<p><img src= "/img/loading.gif" data-src="https://pic2.zhimg.com/80/v2-d9979f93198a3e21e34ba34aaace0a49_720w.png" alt="图17：Convolutional Deep Belief Network学习的特征" /></p>
<p>Adam Harley做了一个非常惊艳的卷积神经网络可视化，这个网络是用MNIST手写数字数据库训练而来的。我强烈推荐大家<a href="https://scs.ryerson.ca/~aharley/vis/conv/flat.html" target="_blank" rel="noopener external nofollow noreferrer">玩一玩</a>，以便更深地理解卷积神经网络的细节。</p>
<p>如下我们将看到网络是如何识别输入数字&quot;8&quot;的。注意，<strong>图18</strong>没有把ReLU过程单独显示出来。</p>
<p><img src= "/img/loading.gif" data-src="https://pic4.zhimg.com/80/v2-adbba7de0c0a0e52fe846c01fbc91ccb_720w.png" alt="图18：可视化卷积神经网络" /></p>
<p>输入图像有1024个像素（32x32图片），第一个卷积层(Convolution Layer 1)有六个不同的5x5滤波器(Stride = 1)。由图可见，六个不同的滤波器产生了深度为6的特征映射。</p>
<p>Convolutional Layer 1 后面跟着Pooling Layer 1, 对六个特征映射分别进行2x2的最大池化（Stride = 2）。你可以在动态网页中的每个像素上活动鼠标指针，观察其在前一个卷积层里对应的4x4网格（如<strong>图19</strong>）。不难发现，每个4x4网格里的最亮的像素（对应最大值）构成了池化层。</p>
<p><img src= "/img/loading.gif" data-src="https://pic1.zhimg.com/80/v2-3eb08067b3bd57996614f1ea12f90798_720w.png" alt="图19：可视化池化操作" /></p>
<p>之后我们有三个全连接(FC)层：</p>
<ul>
<li><strong>FC 1:</strong> 120神经元</li>
<li><strong>FC 2:</strong> 100神经元</li>
<li><strong>FC 3:</strong> 10神经元，对应10个数字——也即输出层</li>
</ul>
<p>在<strong>图20</strong>，输出层10个节点中的每一个，都与第二个全连接层的100个节点相连（所以叫“全连接”）。</p>
<p>注意输出层里的唯一的亮点对应着8——这说明网络正确的识别了手写数字（越亮的节点代表越高的概率，比如这里8就拥有最高的概率）。</p>
<p><img src= "/img/loading.gif" data-src="https://pic4.zhimg.com/80/v2-b6379c3895d6f695c6db7fedfea419b7_720w.png" alt="图20：可视化全连接层" /></p>
<p>该可视化的3D版可见于<a href="http://scs.ryerson.ca/~aharley/vis/conv/" target="_blank" rel="noopener external nofollow noreferrer">这里</a>。</p>
<h2 id="其他卷积网络架构"><a class="markdownIt-Anchor" href="#其他卷积网络架构"></a> 其他卷积网络架构</h2>
<p>卷积神经网络始自1990年代起，我们已经认识了最早的LeNet，其他一些很有影响力的架构列举如下：</p>
<ul>
<li>1990s至2012：从90年代到2010年代早期，卷积神经网络都处于孵化阶段。随着数据量增大和计算能力提高，卷积神经网络能搞定的问题也越来越有意思了。</li>
<li>AlexNet(2012)：2012年，Alex Krizhevsky发布了<a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener external nofollow noreferrer">AlexNet</a>，是LeNet的更深、更宽版本，并且大比分赢得了当年的ImageNet大规模图像识别挑战赛(ILSVRC)。这是一次非常重要的大突破，现在普及的卷积神经网络应用都要感谢这一壮举。</li>
<li>ZF Net(2013)：2013年的ILSVRC赢家是Matthew Zeiler和Rob Fergus的卷积网络，被称作<a href="https://arxiv.org/abs/1311.2901" target="_blank" rel="noopener external nofollow noreferrer">ZF Net</a>，这是调整过架构超参数的AlexNet改进型。</li>
<li>GoogleNet(2014)：2014的ILSVRC胜者是来自Google的<a href="https://arxiv.org/abs/1409.4842" target="_blank" rel="noopener external nofollow noreferrer">Szegedy et al.</a>。其主要贡献是研发了<em>Inception Module</em>，它大幅减少了网络中的参数数量（四百万，相比AlexNet的六千万）。</li>
<li>VGGNet(2014)：当年的ILSVRC亚军是<a href="https://www.robots.ox.ac.uk/~vgg/research/very_deep/" target="_blank" rel="noopener external nofollow noreferrer">VGGNet</a>，突出贡献是展示了网络的深度（层次数量）是良好表现的关键因素。</li>
<li>ResNet(2015)： Kaiming He研发的<a href="https://arxiv.org/abs/1512.03385" target="_blank" rel="noopener external nofollow noreferrer">Residual Network</a>是2015年的ILSVRC冠军，也代表了卷积神经网络的最高水平，同时还是实践的默认选择（2016年5月）。</li>
<li>DenseNet（2016年8月）： 由Gao Huang发表，<a href="https://arxiv.org/abs/1608.06993" target="_blank" rel="noopener external nofollow noreferrer">Densely Connected Convolutional Network</a>的每一层都直接与其他各层前向连接。DenseNet已经在五个高难度的物体识别基础集上，显式出非凡的进步。</li>
</ul>
<p><strong>（翻译部分 完）</strong></p>
<p>经过本文和之前的<a href="https://jizhi.im/blog/post/nn_py_9" target="_blank" rel="noopener external nofollow noreferrer">系列文章</a>，您应该已经掌握了卷积神经网络的基本原理。接下来我们尝试用流行的Python深度学习库<a href="https://keras-cn.readthedocs.io/" target="_blank" rel="noopener external nofollow noreferrer">Keras</a>，动手实地搭建一个LeNet。</p>
<p>实践是神经网络的唯一标准</p>
<p>回顾LeNet的架构，补全第二组卷积+激励+池化，搭建出经典的LeNet网络。</p>
<p>提示：</p>
<ul>
<li>第二组卷积层有16个滤波器，尺寸为8x8。</li>
<li>第二组激励层使用tanh函数</li>
<li>第二组最大池化层的尺寸和步幅均为3x3</li>
</ul>
<p>请在下方的Python开发环境中补全代码，并点击蓝色按钮【运行】检查答案是否正确。</p>
<p><strong>（需访问：<a href="https://jizhi.im/blog/post/intuitive_explanation_cnn" target="_blank" rel="noopener external nofollow noreferrer">卷积：如何成为一个很厉害的神经网络 - 集智专栏</a>）</strong></p>
<p>如下图，第二组卷积+激励+池化层的参数设置有误，就会得到红色提示，并指出具体的错误所在。</p>
<p><img src= "/img/loading.gif" data-src="https://pic3.zhimg.com/80/v2-f85c12d234d526e12c8979288a8b9676_720w.jpg" alt="img" /></p>
<p> </p>
<p> </p>
<p> </p>
<blockquote>
<p>参考：<a href="https://zhuanlan.zhihu.com/p/25754846" target="_blank" rel="noopener external nofollow noreferrer">https://zhuanlan.zhihu.com/p/25754846</a></p>
<p>原文：<a href="https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/" target="_blank" rel="noopener external nofollow noreferrer">https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/</a></p>
</blockquote>
<!-- flag of hidden posts --><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script></div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined" rel="external nofollow noreferrer">Seven</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://hansuyu.com/2020/06/3272311197.html">http://hansuyu.com/2020/06/3272311197.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow noreferrer" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://hansuyu.com" target="_blank">明天又是周六了</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/han-suyu/cover/6.jpg" data-sites="wechat,weibo,qq,facebook,twitter"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><button class="reward-button"><i class="fas fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="post-qr-code__img" src="/img/wechat.jpg" alt="微信" onclick="window.open('/img/wechat.jpg')"/><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="post-qr-code__img" src="/img/wechat.jpg" alt="支付宝" onclick="window.open('/img/wechat.jpg')"/><div class="post-qr-code__desc">支付宝</div></li></ul></div></button></div><nav class="pagination-post" id="pagination"></nav><hr><div id="post-comment"><div class="comment_headling"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div><div class="vcomment" id="vcomment"></div><script src="https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js"></script><script>var requestSetting = function (from,set) {
  var from = from
  var setting = set.split(',').filter(function(item){
  return from.indexOf(item) > -1
  });
  setting = setting.length == 0 ? from :setting;
  return setting
}

var guestInfo = requestSetting(['nick','mail','link'],'nick,mail')
var requiredFields = requestSetting(['nick','mail'],'nick,mail')

window.valine = new Valine({
  el:'#vcomment',
  appId: 'a9HNNTF9yMcoVFJrKlLyoaAY-gzGzoHsz',
  appKey: 'utzaiW0SY0JMcLNyWSQUhU0o',
  placeholder: '使用QQ号作为昵称会自动加载你的邮箱与头像哦~',
  avatar: 'wavatar',
  meta: guestInfo,
  pageSize: '10',
  lang: 'zh-CN',
  recordIP: true,
  serverURLs: '',
  emojiCDN: '',
  emojiMaps: "",
  enableQQ: true,
  requiredFields: requiredFields
});</script></div></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2020 By Seven</div><div class="framework-info"><span>驱动 </span><a href="https://hexo.io" target="_blank" rel="noopener external nofollow noreferrer"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener external nofollow noreferrer"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><button id="readmode" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font_plus" title="放大字体"><i class="fas fa-plus"></i></button><button id="font_minus" title="缩小字体"><i class="fas fa-minus"></i></button><button class="translate_chn_to_cht" id="translateLink" title="简繁转换">简</button><button id="darkmode" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" title="设置"><i class="fas fa-cog"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fas fa-comments"></i></a><button class="close" id="mobile-toc-button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener external nofollow noreferrer" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div class="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module" defer></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js" async></script><script src="https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js"></script><script>document.addEventListener('DOMContentLoaded', function() {
  pangu.autoSpacingPage()
})</script><script src="/js/search/local-search.js"></script><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script></body></html>